{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lib.BasicModel import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from python_lib.saveasfile import *\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialisation \n",
    "\n",
    "Use BlockSave to save all the weights into a `.bin` file\n",
    "\n",
    "Be sure to `load_state_dict` from a `.pt`/`.pth` file before BlockSave\n",
    "\n",
    "It's omitted here as I don't have the weights on hand, so I just use a random initialised weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<python_lib.saveasfile.BlockSave at 0x7ff70dadec20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BasicModel(input_size = 2, input_length=16).to(\"cuda\")\n",
    "\n",
    "BlockSave(model.return_layers(), \"fullbasicmodel\", \"verifyCppVsPy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Feats for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28700072 0.6169604  0.6852525  0.57610816 0.95842755 0.69390893\n",
      "  0.09680605 0.83381253 0.89192003 0.8134774  0.9693227  0.14813513\n",
      "  0.27104497 0.64710045 0.7205885  0.49191618]\n",
      " [0.6322167  0.04847664 0.34838754 0.17704517 0.09914815 0.8611054\n",
      "  0.7872366  0.30172074 0.4570409  0.93936247 0.26015586 0.19969726\n",
      "  0.3091157  0.33220154 0.22918075 0.94229597]]\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,2,16]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (2,16))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"BasicModelWeights\", f\"basicinput_2x16.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model using eval/train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2870, 0.6170, 0.6853, 0.5761, 0.9584, 0.6939, 0.0968, 0.8338,\n",
      "          0.8919, 0.8135, 0.9693, 0.1481, 0.2710, 0.6471, 0.7206, 0.4919],\n",
      "         [0.6322, 0.0485, 0.3484, 0.1770, 0.0991, 0.8611, 0.7872, 0.3017,\n",
      "          0.4570, 0.9394, 0.2602, 0.1997, 0.3091, 0.3322, 0.2292, 0.9423]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1855, 0.1936, 0.1554, 0.1603, 0.1642, 0.1411]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "print(input_feats)\n",
    "model(input_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification Test C++ vs Py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Test Inputs\n",
    "\n",
    "**NOTE:** Change the values of `no_of_inputs, no_of_channel_in, no_of_input_width` accordingly to desired matrix size\n",
    "\n",
    "Randomizes a `no_of_inputs x no_of_channel_in x no_of_input_width` matrix and saves the values into:\n",
    "1. A binary (to feed C++ as input)\n",
    "2. A CSV (to verify input values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8133, 0.8277, 0.3606, 0.5747, 0.1968, 0.5832, 0.6849, 0.6439,\n",
      "          0.4271, 0.5965, 0.1522, 0.4538, 0.5138, 0.9584, 0.2000, 0.4415],\n",
      "         [0.3546, 0.0429, 0.7636, 0.9730, 0.3013, 0.7972, 0.4903, 0.7709,\n",
      "          0.7257, 0.0981, 0.4050, 0.5893, 0.1055, 0.9590, 0.1994, 0.3371]],\n",
      "\n",
      "        [[0.4814, 0.3528, 0.2498, 0.3486, 0.0058, 0.7663, 0.5095, 0.1951,\n",
      "          0.9229, 0.9356, 0.8047, 0.3925, 0.3932, 0.8909, 0.5320, 0.8430],\n",
      "         [0.0116, 0.5949, 0.5425, 0.7190, 0.4351, 0.5252, 0.4236, 0.4051,\n",
      "          0.5414, 0.8874, 0.2214, 0.2265, 0.8808, 0.8040, 0.2536, 0.2125]],\n",
      "\n",
      "        [[0.2000, 0.6315, 0.1979, 0.2110, 0.4822, 0.0650, 0.4383, 0.7137,\n",
      "          0.0827, 0.1014, 0.1613, 0.4584, 0.8579, 0.8029, 0.3671, 0.4466],\n",
      "         [0.9447, 0.7537, 0.6527, 0.0850, 0.8064, 0.6009, 0.6012, 0.0357,\n",
      "          0.2287, 0.3579, 0.7994, 0.2310, 0.0509, 0.8649, 0.1967, 0.5335]],\n",
      "\n",
      "        [[0.5226, 0.9533, 0.0495, 0.0578, 0.1125, 0.8175, 0.2240, 0.0174,\n",
      "          0.6366, 0.0358, 0.5877, 0.7114, 0.6914, 0.4488, 0.3276, 0.9550],\n",
      "         [0.4312, 0.4758, 0.3310, 0.7127, 0.3483, 0.7442, 0.7180, 0.0143,\n",
      "          0.4233, 0.3427, 0.4533, 0.6480, 0.6515, 0.5300, 0.8620, 0.0465]],\n",
      "\n",
      "        [[0.0284, 0.6450, 0.3452, 0.2302, 0.0580, 0.9766, 0.5591, 0.1285,\n",
      "          0.8551, 0.2293, 0.9094, 0.5342, 0.0458, 0.2754, 0.4478, 0.0842],\n",
      "         [0.9213, 0.7378, 0.4255, 0.3260, 0.8933, 0.1479, 0.9770, 0.1912,\n",
      "          0.2394, 0.0686, 0.6994, 0.2485, 0.9638, 0.1911, 0.5740, 0.1002]],\n",
      "\n",
      "        [[0.1386, 0.5474, 0.2113, 0.6795, 0.8971, 0.4733, 0.1030, 0.6660,\n",
      "          0.2976, 0.5191, 0.8812, 0.4448, 0.7455, 0.6847, 0.2810, 0.5953],\n",
      "         [0.4731, 0.6204, 0.2368, 0.0746, 0.2503, 0.6609, 0.1814, 0.1021,\n",
      "          0.1790, 0.1652, 0.6476, 0.5812, 0.1619, 0.4156, 0.9896, 0.6346]],\n",
      "\n",
      "        [[0.7936, 0.8083, 0.3373, 0.8808, 0.7002, 0.2505, 0.4219, 0.0861,\n",
      "          0.9232, 0.1130, 0.5760, 0.6028, 0.3471, 0.9316, 0.2034, 0.8290],\n",
      "         [0.3273, 0.7453, 0.4305, 0.8101, 0.3666, 0.3490, 0.2078, 0.5855,\n",
      "          0.3900, 0.8780, 0.8697, 0.2547, 0.5524, 0.4982, 0.8508, 0.9096]],\n",
      "\n",
      "        [[0.6257, 0.0277, 0.4294, 0.0672, 0.9886, 0.7482, 0.8759, 0.4616,\n",
      "          0.2917, 0.9960, 0.7007, 0.9820, 0.5777, 0.6837, 0.5635, 0.6478],\n",
      "         [0.8792, 0.6728, 0.3696, 0.9064, 0.7018, 0.8454, 0.9052, 0.0360,\n",
      "          0.9851, 0.1771, 0.4927, 0.2026, 0.7771, 0.7498, 0.6057, 0.7252]],\n",
      "\n",
      "        [[0.6935, 0.7382, 0.5701, 0.8003, 0.1929, 0.2355, 0.9024, 0.5344,\n",
      "          0.5443, 0.2437, 0.5114, 0.1933, 0.3813, 0.9965, 0.1631, 0.3179],\n",
      "         [0.3021, 0.2449, 0.1771, 0.6011, 0.5021, 0.3925, 0.1575, 0.4733,\n",
      "          0.5876, 0.8199, 0.0791, 0.1380, 0.4298, 0.5376, 0.1334, 0.4599]],\n",
      "\n",
      "        [[0.7331, 0.6239, 0.5668, 0.1073, 0.8556, 0.2289, 0.3358, 0.4854,\n",
      "          0.4769, 0.3553, 0.2137, 0.5108, 0.6693, 0.5501, 0.3666, 0.0535],\n",
      "         [0.4027, 0.0830, 0.0864, 0.6009, 0.9504, 0.7959, 0.4108, 0.0849,\n",
      "          0.1172, 0.2579, 0.8253, 0.1790, 0.5120, 0.8053, 0.6556, 0.6769]]],\n",
      "       device='cuda:0')\n",
      "(10, 2, 16)\n",
      "[[[0.81327385 0.8276721  0.3605615  0.5746831  0.1967789  0.58315057\n",
      "   0.68489736 0.6439189  0.42705846 0.5964585  0.1521942  0.45375448\n",
      "   0.51382023 0.9584261  0.20002675 0.4414835 ]\n",
      "  [0.3546347  0.04294592 0.7636199  0.9729841  0.3012666  0.7972388\n",
      "   0.49034166 0.77089864 0.7256919  0.09805346 0.40497977 0.5892937\n",
      "   0.1055268  0.9590148  0.19936436 0.33706814]]\n",
      "\n",
      " [[0.4813763  0.3527677  0.2497831  0.3486268  0.00577772 0.7663225\n",
      "   0.509477   0.19509369 0.9229412  0.9356167  0.8047035  0.39245105\n",
      "   0.393247   0.89085996 0.53197986 0.8429983 ]\n",
      "  [0.01163059 0.5949367  0.54250926 0.71903765 0.43506444 0.5252435\n",
      "   0.4236424  0.40509295 0.5414285  0.8874422  0.22143042 0.22653234\n",
      "   0.88081056 0.8039593  0.2535842  0.21248257]]\n",
      "\n",
      " [[0.20001256 0.6315143  0.1978603  0.21096939 0.4821735  0.06502748\n",
      "   0.4382689  0.71368605 0.08272159 0.1013605  0.16130829 0.4584434\n",
      "   0.8578876  0.8028664  0.3671118  0.44655585]\n",
      "  [0.9447191  0.7536513  0.6526746  0.08496416 0.8064342  0.60091597\n",
      "   0.6012041  0.03570223 0.22874254 0.3579089  0.79938805 0.23102349\n",
      "   0.05092359 0.86494565 0.19666457 0.53352827]]\n",
      "\n",
      " [[0.52262044 0.9532888  0.04951239 0.05781776 0.11247051 0.8175192\n",
      "   0.22404647 0.0173794  0.6365739  0.03581297 0.58765286 0.71141833\n",
      "   0.6913818  0.44877577 0.32764375 0.95502377]\n",
      "  [0.4311605  0.47576118 0.3310265  0.7126983  0.3483228  0.7442447\n",
      "   0.7179888  0.01433939 0.42327392 0.3426543  0.45327795 0.64804393\n",
      "   0.65151155 0.5299696  0.86201173 0.04645205]]\n",
      "\n",
      " [[0.02842915 0.64497703 0.3451566  0.2302047  0.05803251 0.9766167\n",
      "   0.55908686 0.12845016 0.85506237 0.22934413 0.90940404 0.5342167\n",
      "   0.04580086 0.27542442 0.44777644 0.08420885]\n",
      "  [0.9213165  0.7378283  0.42547488 0.32599503 0.8933116  0.14786303\n",
      "   0.97702056 0.19116944 0.23942012 0.06858885 0.69938767 0.24851876\n",
      "   0.9637746  0.1910997  0.5739905  0.10018241]]\n",
      "\n",
      " [[0.13860959 0.54743475 0.21131986 0.67954034 0.89705795 0.4732768\n",
      "   0.1030094  0.6660323  0.29760766 0.5191421  0.8812115  0.44484723\n",
      "   0.74554825 0.68465346 0.28101856 0.5953237 ]\n",
      "  [0.47314936 0.62044436 0.23680604 0.07460546 0.25030154 0.66089594\n",
      "   0.18135923 0.10211897 0.17895138 0.16524523 0.6475779  0.5811581\n",
      "   0.16188955 0.41564864 0.9896162  0.6345671 ]]\n",
      "\n",
      " [[0.79357123 0.80832464 0.33725268 0.8808204  0.7002201  0.2505319\n",
      "   0.4218902  0.08612806 0.9231911  0.11304903 0.5759768  0.60283834\n",
      "   0.34707695 0.93161994 0.20343101 0.82899123]\n",
      "  [0.32734442 0.7452784  0.43045485 0.81014603 0.3666079  0.34901983\n",
      "   0.20776749 0.5854557  0.3899787  0.87797636 0.8697365  0.25473964\n",
      "   0.5524253  0.49817795 0.85084903 0.9096399 ]]\n",
      "\n",
      " [[0.6257388  0.0277319  0.42943424 0.06717998 0.9885717  0.74824655\n",
      "   0.87587637 0.46159083 0.29168642 0.9960371  0.7007246  0.9819718\n",
      "   0.57772934 0.68372715 0.56348777 0.6477937 ]\n",
      "  [0.8791605  0.6727899  0.3696329  0.90636504 0.701767   0.845383\n",
      "   0.90517837 0.03601807 0.9850677  0.17713726 0.49269056 0.2026335\n",
      "   0.7770561  0.74983454 0.60571754 0.7251892 ]]\n",
      "\n",
      " [[0.69347656 0.73822063 0.5700924  0.8003323  0.19294053 0.2354824\n",
      "   0.9024199  0.5343828  0.5442611  0.24368906 0.5113765  0.19333458\n",
      "   0.3812666  0.9964581  0.16306019 0.31788045]\n",
      "  [0.30214506 0.24493593 0.17705739 0.6011439  0.5021478  0.39251065\n",
      "   0.15747994 0.47326356 0.5876429  0.8198656  0.07909441 0.13796097\n",
      "   0.42981327 0.5376287  0.13338476 0.45986104]]\n",
      "\n",
      " [[0.733108   0.6238513  0.5667512  0.10732877 0.85556173 0.22892499\n",
      "   0.33582294 0.4853971  0.47692794 0.3552742  0.21367013 0.51084584\n",
      "   0.6692716  0.5500738  0.36661756 0.05350149]\n",
      "  [0.40268058 0.08303893 0.08642203 0.6008632  0.9504206  0.79591304\n",
      "   0.4107948  0.08486754 0.11719853 0.25788826 0.8252994  0.1789884\n",
      "   0.51203376 0.80532175 0.65557283 0.67693716]]]\n"
     ]
    }
   ],
   "source": [
    "no_of_inputs = 10\n",
    "no_of_channel_in = 2\n",
    "no_of_input_width = 16\n",
    "\n",
    "verify_feats = torch.rand([no_of_inputs,no_of_channel_in,no_of_input_width]).to(\"cuda\")\n",
    "print(verify_feats)\n",
    "verify_feats_np = verify_feats.cpu().detach().numpy()\n",
    "\n",
    "## Reshaping\n",
    "# if no_of_inputs == 1:\n",
    "#     verify_feats_np = np.reshape(verify_feats_np, (no_of_channel_in,no_of_input_width))\n",
    "# else:\n",
    "verify_feats_np = np.reshape(verify_feats_np, (no_of_inputs,no_of_channel_in,no_of_input_width)) \n",
    "dim = verify_feats_np.shape\n",
    "print(dim)\n",
    "\n",
    "## Writing verify inputs into binary\n",
    "flatten_verify = verify_feats_np.flatten()\n",
    "with open(os.path.join(\"verifyCppVsPy\", f\"testInput_basicModel_{no_of_inputs}x{no_of_channel_in}x{no_of_input_width}.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_verify.tobytes())\n",
    "            \n",
    "## Extracting verification input values into CSV\n",
    "array_2d = verify_feats_np.reshape(no_of_inputs, -1)\n",
    "output_df = pd.DataFrame(array_2d)\n",
    "output_df.to_csv(f\"verifyCppVsPy/testInput_basicModel_{no_of_inputs}x{no_of_channel_in}x{no_of_input_width}.csv\",\\\n",
    "                 header=False, index=False)\n",
    "print(verify_feats_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyouqun/Git/LegacyCNN.wt/verificationTest/python_lib/BasicModel.py:70: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  z = F.softmax(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1475, 0.2188, 0.1529, 0.1597, 0.1640, 0.1571],\n",
       "        [0.1475, 0.2189, 0.1529, 0.1596, 0.1641, 0.1571],\n",
       "        [0.1474, 0.2191, 0.1529, 0.1595, 0.1640, 0.1571],\n",
       "        [0.1475, 0.2187, 0.1528, 0.1597, 0.1641, 0.1571],\n",
       "        [0.1475, 0.2190, 0.1529, 0.1595, 0.1640, 0.1571],\n",
       "        [0.1475, 0.2191, 0.1530, 0.1596, 0.1638, 0.1570],\n",
       "        [0.1474, 0.2190, 0.1528, 0.1595, 0.1641, 0.1571],\n",
       "        [0.1475, 0.2189, 0.1529, 0.1596, 0.1640, 0.1571],\n",
       "        [0.1475, 0.2189, 0.1528, 0.1596, 0.1642, 0.1571],\n",
       "        [0.1474, 0.2192, 0.1530, 0.1595, 0.1639, 0.1570]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(verify_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14749992, 0.2187969 , 0.15289658, 0.15965511, 0.16404627,\n",
       "        0.15710515],\n",
       "       [0.1474942 , 0.21893455, 0.1528505 , 0.15956768, 0.16407992,\n",
       "        0.15707314],\n",
       "       [0.14742531, 0.21911602, 0.15294908, 0.15949346, 0.16396283,\n",
       "        0.15705332],\n",
       "       [0.14753692, 0.21870603, 0.1528481 , 0.15966213, 0.164131  ,\n",
       "        0.1571158 ],\n",
       "       [0.14752172, 0.21895556, 0.15287286, 0.15954831, 0.16404958,\n",
       "        0.157052  ],\n",
       "       [0.14745808, 0.21914601, 0.15300055, 0.15958494, 0.16381305,\n",
       "        0.15699741],\n",
       "       [0.14744994, 0.21897846, 0.15284084, 0.15954459, 0.16409242,\n",
       "        0.15709376],\n",
       "       [0.1475111 , 0.21891044, 0.15289554, 0.15961672, 0.16400811,\n",
       "        0.15705808],\n",
       "       [0.14747508, 0.21885875, 0.15275142, 0.15956622, 0.16419949,\n",
       "        0.15714899],\n",
       "       [0.14742728, 0.21919176, 0.15297556, 0.15951811, 0.16387963,\n",
       "        0.15700766]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(verify_feats).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
