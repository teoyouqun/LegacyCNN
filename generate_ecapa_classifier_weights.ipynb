{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and dependencies\n",
    "\n",
    "Notice that we import from `ecapa_classifier` instead of `modules`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lib.ecapa_classifier import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from python_lib.saveasfile import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialisation \n",
    "\n",
    "Use BlockSave to save all the weights into a `.bin` file\n",
    "\n",
    "Be sure to `load_state_dict` from a `.pt`/`.pth` file before BlockSave\n",
    "\n",
    "It's omitted here as I don't have the weights on hand, so I just use a random initialised weights.\n",
    "\n",
    "Here, specify the metrics_type you wish to use beforehand: `cosine` , `cdist`, `euclidean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<python_lib.saveasfile.BlockSave at 0x7f5c59df50f0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This out_neurons is after fc. Hence, due to ASP previously, we set out_neuron = 1\n",
    "\n",
    "# metrics_type = cosine / cdist / euclidean\n",
    "\n",
    "model = ECAPA_TDNN(input_size = 2, \n",
    "                   channels=[8,8,8,8,16], \n",
    "                   lin_neurons=6, \n",
    "                   device = \"cuda\", \n",
    "                   out_neurons=1, \n",
    "                   metrics_type=\"euclidean\").to(\"cuda\")\n",
    "\n",
    "BlockSave(model.return_layers(), \"fullecapa_classifier_euclidean\", \"verifyCppVsPy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Feats for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38879645 0.57369834 0.80075717 0.7499905  0.8760568  0.5953407\n",
      "  0.96687865 0.19404864 0.7338831  0.10817343 0.62204343 0.84491163\n",
      "  0.4768408  0.1360389  0.4818855  0.46680504 0.7344077  0.49828732\n",
      "  0.28713876 0.3497867  0.34029698 0.42403388 0.43592697 0.6064776\n",
      "  0.5035775  0.6328213  0.3118136  0.47725874 0.6348506  0.27109456\n",
      "  0.8729037  0.25773013 0.77347034 0.8676893  0.4192561  0.76917815\n",
      "  0.64022374 0.40523994 0.57056236 0.7610243  0.12108201 0.4488796\n",
      "  0.25404388 0.12344974 0.5311209  0.4324385  0.34555    0.49526536\n",
      "  0.2983272  0.01218635 0.2760092  0.9437817  0.98549604 0.8738632\n",
      "  0.17591423 0.43235713 0.90420544 0.7022316  0.3737064  0.17069173\n",
      "  0.11870342 0.01647627 0.63169575 0.6427758 ]\n",
      " [0.62699103 0.43908495 0.22667372 0.20402795 0.994665   0.957396\n",
      "  0.41751254 0.14722061 0.50215703 0.0728212  0.91050375 0.508045\n",
      "  0.01895618 0.63508266 0.9619141  0.92489713 0.76009756 0.20702022\n",
      "  0.4819011  0.8684529  0.4029696  0.6681574  0.46617973 0.11759371\n",
      "  0.2965598  0.073066   0.50541705 0.00486654 0.14762402 0.65535796\n",
      "  0.46097136 0.12850642 0.62477815 0.3652023  0.11447406 0.6666045\n",
      "  0.55315167 0.44929153 0.11041445 0.6685597  0.5035499  0.5755568\n",
      "  0.08543885 0.6160188  0.814615   0.6479491  0.935215   0.7676559\n",
      "  0.77301806 0.8592564  0.18472171 0.9662167  0.08994687 0.7054076\n",
      "  0.3180815  0.9997872  0.5057221  0.47424483 0.41497153 0.61162496\n",
      "  0.16417652 0.16890341 0.01793897 0.5694097 ]]\n",
      "(2, 64)\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,2,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (2,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "print(dim)\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"ecapainput_2x64.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model using eval/train mode\n",
    "\n",
    "You may specify lengths here if necessary\n",
    "\n",
    "Here, lengths = `0.4`\n",
    "\n",
    "where 0 < lengths <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0421, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0945, 0.0170, 0.0450, 0.0000],\n",
      "         [0.1113, 0.1685, 0.2785, 0.2402, 0.0813, 0.0025, 0.1535, 0.4634,\n",
      "          0.0518, 0.1385, 0.1501, 0.0000, 0.2479, 0.1054, 0.0000, 0.0000,\n",
      "          0.0849, 0.1740, 0.1762, 0.0000, 0.0000, 0.2020, 0.1083, 0.2765,\n",
      "          0.3110, 0.1255, 0.2933, 0.0545, 0.2584, 0.1528, 0.0000, 0.3835,\n",
      "          0.2098, 0.0945, 0.3515, 0.1258, 0.0388, 0.2440, 0.1586, 0.0990,\n",
      "          0.0188, 0.0130, 0.0426, 0.1091, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0085, 0.1201, 0.2998, 0.0864, 0.3236, 0.0173, 0.1360,\n",
      "          0.0000, 0.2842, 0.0974, 0.0397, 0.0475, 0.2850, 0.1303, 0.2309],\n",
      "         [0.2805, 0.2133, 0.1147, 0.0543, 0.2470, 0.2278, 0.4782, 0.1294,\n",
      "          0.3447, 0.2027, 0.2297, 0.1272, 0.3667, 0.4133, 0.5486, 0.4733,\n",
      "          0.4578, 0.4042, 0.4063, 0.4391, 0.4683, 0.4027, 0.2425, 0.1777,\n",
      "          0.0015, 0.0908, 0.0745, 0.0979, 0.1569, 0.0124, 0.3128, 0.1447,\n",
      "          0.1054, 0.0825, 0.1368, 0.1690, 0.1947, 0.3106, 0.1670, 0.2432,\n",
      "          0.2891, 0.4605, 0.4035, 0.3919, 0.4432, 0.5347, 0.5861, 0.6222,\n",
      "          0.6826, 0.7285, 0.4802, 0.1301, 0.0000, 0.2630, 0.4137, 0.4254,\n",
      "          0.2419, 0.2503, 0.3575, 0.4097, 0.4481, 0.2154, 0.0400, 0.0000],\n",
      "         [0.5825, 0.4657, 0.3255, 0.3388, 0.5139, 0.4644, 0.4972, 0.7207,\n",
      "          0.4517, 0.3327, 0.6071, 0.0169, 0.4604, 0.6143, 0.2238, 0.3585,\n",
      "          0.4254, 0.3940, 0.6242, 0.3607, 0.2793, 0.5687, 0.3803, 0.4541,\n",
      "          0.4587, 0.3598, 0.6049, 0.2513, 0.3864, 0.4892, 0.2270, 0.5339,\n",
      "          0.5677, 0.1760, 0.5942, 0.4956, 0.3342, 0.6063, 0.3670, 0.3626,\n",
      "          0.4742, 0.4677, 0.2291, 0.5206, 0.0947, 0.2417, 0.4860, 0.2390,\n",
      "          0.4969, 0.5711, 0.4266, 0.3829, 0.0730, 0.6489, 0.5451, 0.6920,\n",
      "          0.0831, 0.4743, 0.5826, 0.5698, 0.4370, 0.4842, 0.1981, 0.2901],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0290, 0.0000, 0.0129],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5755, 0.5248, 0.5073, 0.5409, 0.5043, 0.8246, 0.6919, 0.5662,\n",
      "          0.6213, 0.4618, 0.4471, 0.6651, 0.6473, 0.6568, 0.6584, 0.5963,\n",
      "          0.7074, 0.6959, 0.5681, 0.6678, 0.6258, 0.4318, 0.5550, 0.3947,\n",
      "          0.4799, 0.4165, 0.4167, 0.6409, 0.2733, 0.5111, 0.5944, 0.4244,\n",
      "          0.4892, 0.5152, 0.5756, 0.5580, 0.5356, 0.6591, 0.6046, 0.4607,\n",
      "          0.6678, 0.7197, 0.5328, 0.5213, 0.6731, 0.6291, 0.7482, 0.8313,\n",
      "          0.6151, 0.7370, 0.4277, 0.3330, 0.6026, 0.6650, 0.7279, 0.6209,\n",
      "          0.5988, 0.6118, 0.6805, 0.6659, 0.4648, 0.3983, 0.2097, 0.3591],\n",
      "         [0.2790, 0.2379, 0.2693, 0.1701, 0.2669, 0.2453, 0.1296, 0.0000,\n",
      "          0.4149, 0.0857, 0.2691, 0.2480, 0.0280, 0.2408, 0.3094, 0.0384,\n",
      "          0.1161, 0.0369, 0.0613, 0.3129, 0.0715, 0.0605, 0.2082, 0.0709,\n",
      "          0.2407, 0.1345, 0.2748, 0.3221, 0.1012, 0.2692, 0.3479, 0.0386,\n",
      "          0.2892, 0.2695, 0.1305, 0.2929, 0.1571, 0.2749, 0.1167, 0.1765,\n",
      "          0.1320, 0.2608, 0.0556, 0.1686, 0.2981, 0.0278, 0.1332, 0.0977,\n",
      "          0.0000, 0.2873, 0.0000, 0.2916, 0.0384, 0.2240, 0.1875, 0.3244,\n",
      "          0.1365, 0.0212, 0.0787, 0.1804, 0.1016, 0.2332, 0.1250, 0.2168]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[0.0449, 0.0456, 0.0461, 0.0460, 0.0454, 0.0450, 0.0452, 0.0441,\n",
      "          0.0460, 0.0453, 0.0456, 0.0461, 0.0444, 0.0451, 0.0470, 0.0457,\n",
      "          0.0457, 0.0450, 0.0448, 0.0459, 0.0458, 0.0457, 0.0457, 0.0457,\n",
      "          0.0454, 0.0454, 0.0449, 0.0458, 0.0876, 0.0449, 0.0466, 0.0449,\n",
      "          0.0456, 0.0461, 0.0448, 0.0454, 0.0455, 0.0451, 0.0455, 0.0458,\n",
      "          0.0442, 0.0454, 0.0452, 0.0453, 0.0470, 0.0458, 0.0453, 0.0456,\n",
      "          0.0453, 0.0455, 0.0464, 0.0469, 0.0454, 0.0451, 0.0445, 0.0457,\n",
      "          0.0465, 0.0453, 0.0443, 0.0446, 0.1398, 0.0628, 0.0909, 0.0456],\n",
      "         [0.1113, 0.1685, 0.2785, 0.2402, 0.0813, 0.0025, 0.1535, 0.4634,\n",
      "          0.0518, 0.1385, 0.1501, 0.0000, 0.2479, 0.1054, 0.0000, 0.0000,\n",
      "          0.0849, 0.1740, 0.1762, 0.0000, 0.0000, 0.2020, 0.1083, 0.2765,\n",
      "          0.3110, 0.1255, 0.2933, 0.0545, 0.2584, 0.1528, 0.0000, 0.3835,\n",
      "          0.2098, 0.0945, 0.3515, 0.1258, 0.0388, 0.2440, 0.1586, 0.0990,\n",
      "          0.0188, 0.0130, 0.0426, 0.1091, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0085, 0.1201, 0.2998, 0.0864, 0.3236, 0.0173, 0.1360,\n",
      "          0.0000, 0.2842, 0.0974, 0.0397, 0.0475, 0.2850, 0.1303, 0.2309],\n",
      "         [0.3580, 0.2916, 0.1933, 0.1329, 0.3250, 0.3054, 0.5560, 0.2061,\n",
      "          0.4233, 0.2806, 0.3078, 0.2058, 0.4438, 0.4911, 0.6282, 0.5515,\n",
      "          0.5361, 0.4818, 0.4838, 0.5176, 0.5466, 0.4810, 0.3209, 0.2560,\n",
      "          0.0795, 0.1688, 0.1521, 0.1763, 0.2351, 0.0899, 0.3920, 0.2222,\n",
      "          0.1837, 0.1612, 0.2143, 0.2469, 0.2729, 0.3883, 0.2451, 0.3216,\n",
      "          0.3660, 0.5385, 0.4813, 0.4698, 0.5228, 0.6131, 0.6640, 0.7004,\n",
      "          0.7605, 0.8066, 0.5592, 0.2096, 0.0780, 0.3407, 0.4909, 0.5037,\n",
      "          0.3210, 0.3282, 0.4345, 0.4870, 0.5260, 0.2937, 0.1185, 0.0782],\n",
      "         [0.7263, 0.6089, 0.4683, 0.4817, 0.6572, 0.6081, 0.6408, 0.8651,\n",
      "          0.5946, 0.4762, 0.7503, 0.1598, 0.6046, 0.7579, 0.3660, 0.5017,\n",
      "          0.5685, 0.5377, 0.7680, 0.5036, 0.4224, 0.7118, 0.5234, 0.5972,\n",
      "          0.6021, 0.5032, 0.7487, 0.3943, 0.5296, 0.6329, 0.3694, 0.6776,\n",
      "          0.7109, 0.3189, 0.7380, 0.6390, 0.4775, 0.7499, 0.5102, 0.5057,\n",
      "          0.6184, 0.6111, 0.3726, 0.6641, 0.2368, 0.3848, 0.6295, 0.3822,\n",
      "          0.6403, 0.7144, 0.5692, 0.5251, 0.2164, 0.7925, 0.6891, 0.8352,\n",
      "          0.2256, 0.6178, 0.7268, 0.7138, 0.5804, 0.6273, 0.3411, 0.4333],\n",
      "         [0.1309, 0.1311, 0.1312, 0.1312, 0.1311, 0.1310, 0.1310, 0.1307,\n",
      "          0.1312, 0.1310, 0.1311, 0.1312, 0.1308, 0.1310, 0.1315, 0.1311,\n",
      "          0.1312, 0.1309, 0.1309, 0.1312, 0.1312, 0.1311, 0.1312, 0.1311,\n",
      "          0.1311, 0.1311, 0.1309, 0.1312, 0.1311, 0.1309, 0.1314, 0.1309,\n",
      "          0.1311, 0.1313, 0.1309, 0.1311, 0.1311, 0.1310, 0.1311, 0.1312,\n",
      "          0.1308, 0.1311, 0.1310, 0.1310, 0.1315, 0.1312, 0.1310, 0.1311,\n",
      "          0.1311, 0.1311, 0.1313, 0.1315, 0.1311, 0.1310, 0.1308, 0.1311,\n",
      "          0.1314, 0.1310, 0.1308, 0.1308, 0.1310, 0.1601, 0.1312, 0.1440],\n",
      "         [0.0404, 0.0411, 0.0415, 0.0415, 0.0410, 0.0405, 0.0407, 0.0397,\n",
      "          0.0415, 0.0408, 0.0411, 0.0415, 0.0399, 0.0407, 0.0424, 0.0412,\n",
      "          0.0412, 0.0405, 0.0404, 0.0414, 0.0412, 0.0412, 0.0412, 0.0412,\n",
      "          0.0409, 0.0409, 0.0405, 0.0413, 0.0411, 0.0405, 0.0420, 0.0405,\n",
      "          0.0411, 0.0416, 0.0404, 0.0409, 0.0410, 0.0406, 0.0410, 0.0413,\n",
      "          0.0398, 0.0409, 0.0407, 0.0408, 0.0424, 0.0413, 0.0408, 0.0411,\n",
      "          0.0409, 0.0410, 0.0418, 0.0423, 0.0409, 0.0406, 0.0401, 0.0412,\n",
      "          0.0419, 0.0408, 0.0399, 0.0401, 0.0408, 0.0413, 0.0413, 0.0411],\n",
      "         [0.7200, 0.6685, 0.6506, 0.6842, 0.6482, 0.9690, 0.8360, 0.7115,\n",
      "          0.7646, 0.6058, 0.5909, 0.8083, 0.7922, 0.8010, 0.8007, 0.7400,\n",
      "          0.8510, 0.8402, 0.7126, 0.8112, 0.7694, 0.5754, 0.6986, 0.5384,\n",
      "          0.6239, 0.5604, 0.5611, 0.7844, 0.4171, 0.6555, 0.7372, 0.5688,\n",
      "          0.6330, 0.6585, 0.7201, 0.7019, 0.6794, 0.8033, 0.7485, 0.6042,\n",
      "          0.8130, 0.8637, 0.6769, 0.6654, 0.8154, 0.7726, 0.8923, 0.9751,\n",
      "          0.7591, 0.8808, 0.5707, 0.4754, 0.7465, 0.8092, 0.8727, 0.7645,\n",
      "          0.7416, 0.7559, 0.8255, 0.8107, 0.6089, 0.5418, 0.3532, 0.5028],\n",
      "         [0.4458, 0.4043, 0.4354, 0.3363, 0.4334, 0.4120, 0.2962, 0.1672,\n",
      "          0.5811, 0.2523, 0.4356, 0.4142, 0.1951, 0.4074, 0.4750, 0.2047,\n",
      "          0.2824, 0.2036, 0.2281, 0.4791, 0.2378, 0.2269, 0.3745, 0.2373,\n",
      "          0.4072, 0.3010, 0.4415, 0.4884, 0.2676, 0.4360, 0.5137, 0.2054,\n",
      "          0.4556, 0.4356, 0.2973, 0.4594, 0.3235, 0.4416, 0.2832, 0.3427,\n",
      "          0.2992, 0.4273, 0.2222, 0.3351, 0.4637, 0.1941, 0.2998, 0.2641,\n",
      "          0.1665, 0.4537, 0.1660, 0.4573, 0.2049, 0.3907, 0.3545, 0.4907,\n",
      "          0.3024, 0.1878, 0.2458, 0.3474, 0.2681, 0.3995, 0.2913, 0.3832]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[0.2766, 0.2790, 0.2783, 0.2774, 0.2816, 0.2795, 0.2767, 0.2772,\n",
      "          0.2780, 0.2779, 0.2821, 0.2773, 0.2773, 0.2781, 0.2785, 0.2786,\n",
      "          0.2777, 0.2770, 0.2778, 0.2777, 0.2781, 0.2826, 0.2771, 0.2792,\n",
      "          0.2797, 0.2770, 0.2783, 0.2795, 0.3212, 0.2842, 0.2784, 0.2810,\n",
      "          0.2813, 0.2774, 0.2809, 0.2793, 0.2769, 0.2771, 0.2782, 0.2779,\n",
      "          0.2784, 0.2771, 0.2783, 0.2779, 0.2783, 0.2792, 0.2782, 0.2765,\n",
      "          0.2793, 0.2778, 0.2798, 0.2814, 0.2787, 0.2791, 0.2797, 0.2771,\n",
      "          0.2843, 0.2768, 0.2813, 0.2768, 0.3752, 0.2956, 0.3251, 0.2799],\n",
      "         [0.1113, 0.1685, 0.2785, 0.2402, 0.0813, 0.0025, 0.1535, 0.4634,\n",
      "          0.0518, 0.1385, 0.1501, 0.0000, 0.2479, 0.1054, 0.0000, 0.0000,\n",
      "          0.0849, 0.1740, 0.1762, 0.0000, 0.0000, 0.2020, 0.1083, 0.2765,\n",
      "          0.3110, 0.1255, 0.2933, 0.0545, 0.2584, 0.1528, 0.0000, 0.3835,\n",
      "          0.2098, 0.0945, 0.3515, 0.1258, 0.0388, 0.2440, 0.1586, 0.0990,\n",
      "          0.0188, 0.0130, 0.0426, 0.1091, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0085, 0.1201, 0.2998, 0.0864, 0.3236, 0.0173, 0.1360,\n",
      "          0.0000, 0.2842, 0.0974, 0.0397, 0.0475, 0.2850, 0.1303, 0.2309],\n",
      "         [0.4096, 0.3428, 0.2472, 0.1842, 0.3773, 0.3564, 0.6076, 0.2616,\n",
      "          0.4761, 0.3357, 0.3624, 0.2565, 0.5000, 0.5473, 0.6797, 0.6076,\n",
      "          0.5891, 0.5352, 0.5400, 0.5701, 0.6008, 0.5405, 0.3719, 0.3140,\n",
      "          0.1402, 0.2207, 0.2095, 0.2269, 0.2931, 0.1397, 0.4444, 0.2851,\n",
      "          0.2380, 0.2120, 0.2716, 0.2992, 0.3239, 0.4417, 0.2974, 0.3749,\n",
      "          0.4148, 0.5907, 0.5380, 0.5248, 0.5738, 0.6707, 0.7200, 0.7500,\n",
      "          0.8198, 0.8607, 0.6169, 0.2706, 0.1307, 0.4002, 0.5451, 0.5550,\n",
      "          0.3700, 0.3797, 0.4840, 0.5408, 0.5841, 0.3494, 0.1736, 0.1386],\n",
      "         [0.7263, 0.6089, 0.4683, 0.4817, 0.6572, 0.6081, 0.6408, 0.8651,\n",
      "          0.5946, 0.4762, 0.7503, 0.1598, 0.6046, 0.7579, 0.3660, 0.5017,\n",
      "          0.5685, 0.5377, 0.7680, 0.5036, 0.4224, 0.7118, 0.5234, 0.5972,\n",
      "          0.6021, 0.5032, 0.7487, 0.3943, 0.5296, 0.6329, 0.3694, 0.6776,\n",
      "          0.7109, 0.3189, 0.7380, 0.6390, 0.4775, 0.7499, 0.5102, 0.5057,\n",
      "          0.6184, 0.6111, 0.3726, 0.6641, 0.2368, 0.3848, 0.6295, 0.3822,\n",
      "          0.6403, 0.7144, 0.5692, 0.5251, 0.2164, 0.7925, 0.6891, 0.8352,\n",
      "          0.2256, 0.6178, 0.7268, 0.7138, 0.5804, 0.6273, 0.3411, 0.4333],\n",
      "         [0.2289, 0.2280, 0.2303, 0.2292, 0.2271, 0.2271, 0.2292, 0.2303,\n",
      "          0.2299, 0.2307, 0.2283, 0.2290, 0.2309, 0.2311, 0.2296, 0.2312,\n",
      "          0.2299, 0.2298, 0.2311, 0.2297, 0.2304, 0.2311, 0.2290, 0.2320,\n",
      "          0.2331, 0.2293, 0.2316, 0.2276, 0.2320, 0.2238, 0.2299, 0.2334,\n",
      "          0.2287, 0.2290, 0.2301, 0.2283, 0.2290, 0.2299, 0.2290, 0.2300,\n",
      "          0.2258, 0.2294, 0.2313, 0.2306, 0.2294, 0.2319, 0.2311, 0.2284,\n",
      "          0.2325, 0.2303, 0.2321, 0.2337, 0.2289, 0.2326, 0.2286, 0.2291,\n",
      "          0.2245, 0.2291, 0.2247, 0.2300, 0.2310, 0.2600, 0.2300, 0.2459],\n",
      "         [0.0404, 0.0411, 0.0415, 0.0415, 0.0410, 0.0405, 0.0407, 0.0397,\n",
      "          0.0415, 0.0408, 0.0411, 0.0415, 0.0399, 0.0407, 0.0424, 0.0412,\n",
      "          0.0412, 0.0405, 0.0404, 0.0414, 0.0412, 0.0412, 0.0412, 0.0412,\n",
      "          0.0409, 0.0409, 0.0405, 0.0413, 0.0411, 0.0405, 0.0420, 0.0405,\n",
      "          0.0411, 0.0416, 0.0404, 0.0409, 0.0410, 0.0406, 0.0410, 0.0413,\n",
      "          0.0398, 0.0409, 0.0407, 0.0408, 0.0424, 0.0413, 0.0408, 0.0411,\n",
      "          0.0409, 0.0410, 0.0418, 0.0423, 0.0409, 0.0406, 0.0401, 0.0412,\n",
      "          0.0419, 0.0408, 0.0399, 0.0401, 0.0408, 0.0413, 0.0413, 0.0411],\n",
      "         [0.7850, 0.7328, 0.7138, 0.7496, 0.7102, 1.0328, 0.9011, 0.7731,\n",
      "          0.8287, 0.6680, 0.6512, 0.8742, 0.8535, 0.8623, 0.8659, 0.8014,\n",
      "          0.9150, 0.9039, 0.7738, 0.8756, 0.8323, 0.6323, 0.7642, 0.5982,\n",
      "          0.6815, 0.6253, 0.6214, 0.8489, 0.4768, 0.7174, 0.8016, 0.6239,\n",
      "          0.6939, 0.7243, 0.7788, 0.7652, 0.7450, 0.8670, 0.8125, 0.6679,\n",
      "          0.8784, 0.9284, 0.7379, 0.7277, 0.8810, 0.8328, 0.9537, 1.0419,\n",
      "          0.8178, 0.9438, 0.6307, 0.5327, 0.8099, 0.8677, 0.9340, 0.8299,\n",
      "          0.8049, 0.8210, 0.8889, 0.8739, 0.6675, 0.6035, 0.4144, 0.5606],\n",
      "         [0.4458, 0.4043, 0.4354, 0.3363, 0.4334, 0.4120, 0.2962, 0.1672,\n",
      "          0.5811, 0.2523, 0.4356, 0.4142, 0.1951, 0.4074, 0.4750, 0.2047,\n",
      "          0.2824, 0.2036, 0.2281, 0.4791, 0.2378, 0.2269, 0.3745, 0.2373,\n",
      "          0.4072, 0.3010, 0.4415, 0.4884, 0.2676, 0.4360, 0.5137, 0.2054,\n",
      "          0.4556, 0.4356, 0.2973, 0.4594, 0.3235, 0.4416, 0.2832, 0.3427,\n",
      "          0.2992, 0.4273, 0.2222, 0.3351, 0.4637, 0.1941, 0.2998, 0.2641,\n",
      "          0.1665, 0.4537, 0.1660, 0.4573, 0.2049, 0.3907, 0.3545, 0.4907,\n",
      "          0.3024, 0.1878, 0.2458, 0.3474, 0.2681, 0.3995, 0.2913, 0.3832]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[[0.3737, 0.3765, 0.3762, 0.3749, 0.3808, 0.3787, 0.3744, 0.3724,\n",
      "          0.3756, 0.3765, 0.3803, 0.3845, 0.3752, 0.3730, 0.3795, 0.3745,\n",
      "          0.3777, 0.3766, 0.3725, 0.3734, 0.3775, 0.3800, 0.3763, 0.3758,\n",
      "          0.3731, 0.3768, 0.3737, 0.3787, 0.4210, 0.3807, 0.3805, 0.3753,\n",
      "          0.3774, 0.3771, 0.3740, 0.3792, 0.3788, 0.3700, 0.3808, 0.3778,\n",
      "          0.3756, 0.3793, 0.3786, 0.3746, 0.3783, 0.3797, 0.3734, 0.3765,\n",
      "          0.3758, 0.3703, 0.3780, 0.3753, 0.3793, 0.3742, 0.3758, 0.3734,\n",
      "          0.3818, 0.3778, 0.3796, 0.3779, 0.4707, 0.3936, 0.4273, 0.3789],\n",
      "         [0.1113, 0.1685, 0.2785, 0.2402, 0.0813, 0.0025, 0.1535, 0.4634,\n",
      "          0.0518, 0.1385, 0.1501, 0.0000, 0.2479, 0.1054, 0.0000, 0.0000,\n",
      "          0.0849, 0.1740, 0.1762, 0.0000, 0.0000, 0.2020, 0.1083, 0.2765,\n",
      "          0.3110, 0.1255, 0.2933, 0.0545, 0.2584, 0.1528, 0.0000, 0.3835,\n",
      "          0.2098, 0.0945, 0.3515, 0.1258, 0.0388, 0.2440, 0.1586, 0.0990,\n",
      "          0.0188, 0.0130, 0.0426, 0.1091, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0085, 0.1201, 0.2998, 0.0864, 0.3236, 0.0173, 0.1360,\n",
      "          0.0000, 0.2842, 0.0974, 0.0397, 0.0475, 0.2850, 0.1303, 0.2309],\n",
      "         [0.4096, 0.3428, 0.2472, 0.1842, 0.3773, 0.3564, 0.6076, 0.2616,\n",
      "          0.4761, 0.3357, 0.3624, 0.2565, 0.5000, 0.5473, 0.6797, 0.6076,\n",
      "          0.5891, 0.5352, 0.5400, 0.5701, 0.6008, 0.5405, 0.3719, 0.3140,\n",
      "          0.1402, 0.2207, 0.2095, 0.2269, 0.2931, 0.1397, 0.4444, 0.2851,\n",
      "          0.2380, 0.2120, 0.2716, 0.2992, 0.3239, 0.4417, 0.2974, 0.3749,\n",
      "          0.4148, 0.5907, 0.5380, 0.5248, 0.5738, 0.6707, 0.7200, 0.7500,\n",
      "          0.8198, 0.8607, 0.6169, 0.2706, 0.1307, 0.4002, 0.5451, 0.5550,\n",
      "          0.3700, 0.3797, 0.4840, 0.5408, 0.5841, 0.3494, 0.1736, 0.1386],\n",
      "         [0.7263, 0.6089, 0.4683, 0.4817, 0.6572, 0.6081, 0.6408, 0.8651,\n",
      "          0.5946, 0.4762, 0.7503, 0.1598, 0.6046, 0.7579, 0.3660, 0.5017,\n",
      "          0.5685, 0.5377, 0.7680, 0.5036, 0.4224, 0.7118, 0.5234, 0.5972,\n",
      "          0.6021, 0.5032, 0.7487, 0.3943, 0.5296, 0.6329, 0.3694, 0.6776,\n",
      "          0.7109, 0.3189, 0.7380, 0.6390, 0.4775, 0.7499, 0.5102, 0.5057,\n",
      "          0.6184, 0.6111, 0.3726, 0.6641, 0.2368, 0.3848, 0.6295, 0.3822,\n",
      "          0.6403, 0.7144, 0.5692, 0.5251, 0.2164, 0.7925, 0.6891, 0.8352,\n",
      "          0.2256, 0.6178, 0.7268, 0.7138, 0.5804, 0.6273, 0.3411, 0.4333],\n",
      "         [0.5046, 0.5034, 0.5058, 0.5049, 0.5021, 0.5021, 0.5046, 0.5060,\n",
      "          0.5055, 0.5062, 0.5035, 0.5016, 0.5062, 0.5074, 0.5043, 0.5081,\n",
      "          0.5046, 0.5045, 0.5076, 0.5056, 0.5058, 0.5067, 0.5039, 0.5076,\n",
      "          0.5098, 0.5042, 0.5076, 0.5027, 0.5066, 0.4997, 0.5041, 0.5099,\n",
      "          0.5046, 0.5040, 0.5070, 0.5027, 0.5031, 0.5067, 0.5025, 0.5052,\n",
      "          0.5016, 0.5030, 0.5066, 0.5061, 0.5042, 0.5072, 0.5074, 0.5034,\n",
      "          0.5083, 0.5076, 0.5073, 0.5108, 0.5035, 0.5081, 0.5045, 0.5043,\n",
      "          0.5004, 0.5034, 0.4996, 0.5043, 0.5068, 0.5357, 0.5043, 0.5211],\n",
      "         [0.1513, 0.1512, 0.1514, 0.1521, 0.1495, 0.1489, 0.1508, 0.1510,\n",
      "          0.1519, 0.1506, 0.1503, 0.1421, 0.1495, 0.1534, 0.1497, 0.1553,\n",
      "          0.1488, 0.1481, 0.1539, 0.1531, 0.1507, 0.1516, 0.1495, 0.1517,\n",
      "          0.1552, 0.1490, 0.1525, 0.1501, 0.1483, 0.1520, 0.1479, 0.1540,\n",
      "          0.1527, 0.1499, 0.1552, 0.1478, 0.1467, 0.1553, 0.1451, 0.1499,\n",
      "          0.1509, 0.1452, 0.1497, 0.1522, 0.1503, 0.1502, 0.1537, 0.1493,\n",
      "          0.1521, 0.1570, 0.1511, 0.1565, 0.1479, 0.1516, 0.1518, 0.1512,\n",
      "          0.1531, 0.1471, 0.1484, 0.1466, 0.1524, 0.1517, 0.1474, 0.1502],\n",
      "         [0.8823, 0.8291, 0.8101, 0.8467, 0.8050, 1.1274, 0.9976, 0.8701,\n",
      "          0.9257, 0.7646, 0.7465, 0.9607, 0.9493, 0.9615, 0.9598, 0.9034,\n",
      "          1.0088, 0.9975, 0.8741, 0.9735, 0.9287, 0.7293, 0.8585, 0.6948,\n",
      "          0.7824, 0.7198, 0.7197, 0.9442, 0.5699, 0.8154, 0.8938, 0.7239,\n",
      "          0.7919, 0.8192, 0.8804, 0.8579, 0.8367, 0.9681, 0.9019, 0.7632,\n",
      "          0.9763, 1.0180, 0.8340, 0.8254, 0.9753, 0.9291, 1.0534, 1.1367,\n",
      "          0.9156, 1.0469, 0.7261, 0.6340, 0.9030, 0.9642, 1.0322, 0.9256,\n",
      "          0.9030, 0.9133, 0.9832, 0.9663, 0.7652, 0.7008, 0.5070, 0.6562],\n",
      "         [0.4458, 0.4043, 0.4354, 0.3363, 0.4334, 0.4120, 0.2962, 0.1672,\n",
      "          0.5811, 0.2523, 0.4356, 0.4142, 0.1951, 0.4074, 0.4750, 0.2047,\n",
      "          0.2824, 0.2036, 0.2281, 0.4791, 0.2378, 0.2269, 0.3745, 0.2373,\n",
      "          0.4072, 0.3010, 0.4415, 0.4884, 0.2676, 0.4360, 0.5137, 0.2054,\n",
      "          0.4556, 0.4356, 0.2973, 0.4594, 0.3235, 0.4416, 0.2832, 0.3427,\n",
      "          0.2992, 0.4273, 0.2222, 0.3351, 0.4637, 0.1941, 0.2998, 0.2641,\n",
      "          0.1665, 0.4537, 0.1660, 0.4573, 0.2049, 0.3907, 0.3545, 0.4907,\n",
      "          0.3024, 0.1878, 0.2458, 0.3474, 0.2681, 0.3995, 0.2913, 0.3832]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[0.2855, 0.5902, 0.0347, 0.0000, 0.0772, 0.0000, 0.1573, 0.0000, 0.0000,\n",
      "         0.0264, 0.0000, 0.0000, 0.2285, 0.6378, 0.0000, 0.0000]],\n",
      "       device='cuda:0', grad_fn=<SumBackward1>)\n",
      "tensor([[5.1927e-02, 7.7968e-02, 2.4549e-02, 1.0000e-06, 6.0609e-02, 1.0000e-06,\n",
      "         1.9976e-02, 1.0000e-06, 1.0000e-06, 3.0289e-02, 1.0000e-06, 1.0000e-06,\n",
      "         4.8714e-02, 5.5929e-02, 1.0000e-06, 1.0000e-06]], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1822, 0.1822, 0.1822, 0.0891, 0.1822, 0.1822],\n",
       "         [0.1434, 0.1434, 0.1434, 0.2829, 0.1434, 0.1434],\n",
       "         [0.1287, 0.1287, 0.1287, 0.3564, 0.1287, 0.1287],\n",
       "         [0.1831, 0.1831, 0.1831, 0.0846, 0.1831, 0.1831],\n",
       "         [0.1444, 0.1444, 0.1444, 0.2780, 0.1444, 0.1444],\n",
       "         [0.1304, 0.1304, 0.1304, 0.3481, 0.1304, 0.1304]]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    " \n",
    "# x = model(input_feats, lengths = None)\n",
    "x= model(input_feats, lengths = torch.ones((1)) * 0.4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification Test C++ vs Py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Test Inputs\n",
    "\n",
    "**NOTE:** Change the values of `no_of_inputs, no_of_channel_in, no_of_input_width` accordingly to desired matrix size\n",
    "\n",
    "Randomizes a `no_of_inputs x no_of_channel_in x no_of_input_width` matrix and saves the values into:\n",
    "1. A binary (to feed C++ as input)\n",
    "2. A CSV (to verify input values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5335, 0.4351, 0.2080, 0.5612, 0.4902, 0.2470, 0.6717, 0.7298,\n",
      "          0.9509, 0.9651, 0.4484, 0.1278, 0.5818, 0.8657, 0.3780, 0.5560,\n",
      "          0.5953, 0.0828, 0.1957, 0.2029, 0.6248, 0.9798, 0.9942, 0.3961,\n",
      "          0.0348, 0.9022, 0.2809, 0.1619, 0.5822, 0.8474, 0.3472, 0.8883,\n",
      "          0.3357, 0.0220, 0.9465, 0.7327, 0.8808, 0.8852, 0.8109, 0.7528,\n",
      "          0.6354, 0.6015, 0.1990, 0.4482, 0.0028, 0.6637, 0.0919, 0.9655,\n",
      "          0.8918, 0.4747, 0.2113, 0.2697, 0.5019, 0.5604, 0.5046, 0.1379,\n",
      "          0.5977, 0.8454, 0.5719, 0.4211, 0.0064, 0.8176, 0.8037, 0.6596],\n",
      "         [0.3584, 0.9438, 0.5027, 0.3487, 0.1564, 0.6694, 0.4910, 0.3885,\n",
      "          0.3681, 0.3460, 0.4632, 0.7946, 0.5763, 0.5811, 0.9389, 0.1048,\n",
      "          0.3185, 0.0519, 0.7239, 0.3592, 0.0368, 0.6738, 0.4336, 0.9585,\n",
      "          0.0365, 0.8271, 0.9625, 0.3251, 0.6545, 0.3785, 0.0812, 0.4249,\n",
      "          0.0602, 0.4942, 0.6217, 0.6444, 0.0364, 0.4049, 0.5248, 0.5406,\n",
      "          0.3438, 0.1900, 0.6707, 0.8262, 0.4665, 0.4720, 0.3386, 0.9776,\n",
      "          0.9584, 0.8069, 0.6205, 0.9636, 0.2565, 0.1316, 0.8732, 0.0533,\n",
      "          0.7306, 0.7178, 0.4845, 0.7412, 0.6920, 0.1250, 0.0470, 0.4531]]],\n",
      "       device='cuda:0')\n",
      "(2, 64)\n",
      "[[0.53354317 0.4351232  0.20796442 0.56118673 0.4902225  0.2469607\n",
      "  0.6717166  0.72983265 0.95088124 0.96511954 0.44836664 0.12784314\n",
      "  0.58176243 0.8656508  0.3779748  0.556026   0.5953045  0.08279473\n",
      "  0.19569147 0.20293897 0.62483156 0.9797714  0.99418414 0.39610302\n",
      "  0.03484863 0.9021788  0.28085804 0.16194797 0.58223915 0.84738815\n",
      "  0.34722692 0.88831687 0.3356706  0.02200013 0.946471   0.7327344\n",
      "  0.88080823 0.88519853 0.81085217 0.7527787  0.63539183 0.60152936\n",
      "  0.19900423 0.44816047 0.00275075 0.66369814 0.09188062 0.96551025\n",
      "  0.89181536 0.47468203 0.21131289 0.2697174  0.5018675  0.5604147\n",
      "  0.504553   0.13788557 0.5976834  0.84540087 0.57193285 0.42112786\n",
      "  0.00643367 0.81761175 0.80372953 0.6595773 ]\n",
      " [0.3583519  0.94381547 0.5027057  0.3487488  0.15638644 0.6694285\n",
      "  0.49100327 0.3885426  0.36814302 0.34603012 0.46317536 0.7946108\n",
      "  0.576311   0.58108634 0.9388693  0.10476178 0.31848395 0.0518539\n",
      "  0.72387266 0.359178   0.03678989 0.6737509  0.43362892 0.9584573\n",
      "  0.03649592 0.82705605 0.96252304 0.32512426 0.65453017 0.3784545\n",
      "  0.08119738 0.42485636 0.06019461 0.49417007 0.6216669  0.6444107\n",
      "  0.03637528 0.40488195 0.52482015 0.5405791  0.3437885  0.19003934\n",
      "  0.6706905  0.82624096 0.46654963 0.47201693 0.33864325 0.97757494\n",
      "  0.9583976  0.8069321  0.6204668  0.9636351  0.25646287 0.13164455\n",
      "  0.8732097  0.0533058  0.73060244 0.7178111  0.48452073 0.7412254\n",
      "  0.6920055  0.12497461 0.0470444  0.4530627 ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "no_of_inputs = 1\n",
    "no_of_channel_in = 2\n",
    "no_of_input_width = 64\n",
    "\n",
    "verify_feats = torch.rand([no_of_inputs,no_of_channel_in,no_of_input_width]).to(\"cuda\")\n",
    "print(verify_feats)\n",
    "verify_feats_np = verify_feats.cpu().detach().numpy()\n",
    "\n",
    "## Reshaping\n",
    "if no_of_inputs == 1:\n",
    "    verify_feats_np = np.reshape(verify_feats_np, (no_of_channel_in,no_of_input_width))\n",
    "else:\n",
    "    verify_feats_np = np.reshape(verify_feats_np, (no_of_inputs,no_of_channel_in,no_of_input_width)) \n",
    "dim = verify_feats_np.shape\n",
    "print(dim)\n",
    "\n",
    "## Writing verify inputs into binary\n",
    "flatten_verify = verify_feats_np.flatten()\n",
    "with open(os.path.join(\"verifyCppVsPy\", f\"testInput_ecapaClassifier_euclidean_{no_of_inputs}x{no_of_channel_in}x{no_of_input_width}.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_verify.tobytes())\n",
    "            \n",
    "## Extracting verification input values into CSV\n",
    "array_2d = verify_feats_np.reshape(no_of_inputs, -1)\n",
    "output_df = pd.DataFrame(array_2d)\n",
    "output_df.to_csv(f\"verifyCppVsPy/testInput_ecapaClassifier_euclidean_{no_of_inputs}x{no_of_channel_in}x{no_of_input_width}.csv\",\\\n",
    "                 header=False, index=False)\n",
    "print(verify_feats_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2000, 0.0949, 0.0572, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1129, 0.0000, 0.0053,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.1968, 0.0000, 0.0350, 0.1725, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0266, 0.0000, 0.3487, 0.0000, 0.0000, 0.0000,\n",
      "          0.0546, 0.0108, 0.2588, 0.2178, 0.0000, 0.1623, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0240, 0.0000, 0.0052, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3906, 0.2661, 0.3574, 0.1465, 0.3819, 0.3388, 0.4486, 0.3220,\n",
      "          0.0620, 0.0000, 0.1901, 0.3827, 0.3094, 0.4143, 0.0976, 0.1904,\n",
      "          0.0000, 0.3050, 0.4277, 0.4545, 0.5535, 0.0426, 0.1411, 0.0123,\n",
      "          0.3279, 0.3374, 0.2130, 0.5194, 0.3045, 0.2605, 0.1690, 0.0000,\n",
      "          0.3388, 0.3753, 0.5653, 0.1538, 0.1863, 0.1157, 0.1506, 0.1327,\n",
      "          0.0000, 0.1813, 0.1882, 0.3995, 0.2940, 0.4033, 0.5112, 0.3382,\n",
      "          0.1388, 0.0330, 0.4372, 0.3533, 0.2530, 0.3182, 0.0871, 0.5008,\n",
      "          0.3691, 0.1941, 0.0638, 0.3981, 0.3935, 0.3120, 0.3008, 0.1134],\n",
      "         [0.2992, 0.6449, 0.1231, 0.3310, 0.4858, 0.3786, 0.2787, 0.6071,\n",
      "          0.4328, 0.4146, 0.3846, 0.2029, 0.1786, 0.7377, 0.4680, 0.0249,\n",
      "          0.5288, 0.1045, 0.3103, 0.1532, 0.4835, 0.6139, 0.3894, 0.5073,\n",
      "          0.0000, 0.6825, 0.4302, 0.1313, 0.5212, 0.5089, 0.3344, 0.2703,\n",
      "          0.3759, 0.1764, 0.4109, 0.6668, 0.3217, 0.6361, 0.3506, 0.3855,\n",
      "          0.2407, 0.3421, 0.2750, 0.2498, 0.1901, 0.4553, 0.4436, 0.4500,\n",
      "          0.5938, 0.3590, 0.3152, 0.3937, 0.2087, 0.5464, 0.4549, 0.0398,\n",
      "          0.5525, 0.4107, 0.3708, 0.4976, 0.1961, 0.2704, 0.7706, 0.4003],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1899, 0.0000, 0.1072, 0.0000, 0.1666, 0.0340, 0.1361, 0.2095,\n",
      "          0.0051, 0.0000, 0.0688, 0.1428, 0.1847, 0.0207, 0.0000, 0.0084,\n",
      "          0.0000, 0.0819, 0.0000, 0.2684, 0.3577, 0.0000, 0.0000, 0.0000,\n",
      "          0.4876, 0.0000, 0.0319, 0.3626, 0.0000, 0.0505, 0.1127, 0.0000,\n",
      "          0.2572, 0.1984, 0.0000, 0.1049, 0.2628, 0.0488, 0.0000, 0.0000,\n",
      "          0.0000, 0.1109, 0.0000, 0.0000, 0.1339, 0.1305, 0.5563, 0.0000,\n",
      "          0.0014, 0.1078, 0.1533, 0.0000, 0.2398, 0.0127, 0.0000, 0.4929,\n",
      "          0.0000, 0.0127, 0.0585, 0.0000, 0.1161, 0.1177, 0.0973, 0.0000],\n",
      "         [0.5676, 0.4901, 0.3903, 0.4300, 0.4048, 0.2450, 0.2280, 0.3767,\n",
      "          0.6349, 0.7490, 0.6675, 0.2515, 0.2558, 0.7185, 0.4117, 0.8026,\n",
      "          0.4946, 0.4822, 0.2547, 0.0000, 0.2924, 0.2952, 1.0069, 0.3754,\n",
      "          0.4384, 0.7062, 0.1187, 0.4759, 0.4920, 0.2883, 0.6836, 0.6171,\n",
      "          0.2663, 0.1958, 0.3315, 0.2606, 0.6792, 0.6229, 0.6079, 0.6811,\n",
      "          0.6081, 0.5866, 0.5423, 0.2710, 0.3791, 0.1657, 0.0481, 0.4408,\n",
      "          0.6043, 0.7339, 0.7375, 0.3396, 0.1950, 0.8167, 0.1713, 0.2182,\n",
      "          0.4086, 0.2961, 0.7702, 0.6383, 0.2061, 0.3489, 0.5552, 0.4310],\n",
      "         [0.1864, 0.0000, 0.2074, 0.1248, 0.1192, 0.1011, 0.0213, 0.1760,\n",
      "          0.1361, 0.0086, 0.0000, 0.0000, 0.0640, 0.1088, 0.0563, 0.2890,\n",
      "          0.0450, 0.2418, 0.0288, 0.0857, 0.2483, 0.0166, 0.1248, 0.0000,\n",
      "          0.2835, 0.0000, 0.0000, 0.1667, 0.2438, 0.0000, 0.4265, 0.0000,\n",
      "          0.0260, 0.1682, 0.0038, 0.1239, 0.1295, 0.0610, 0.0322, 0.0656,\n",
      "          0.1086, 0.0013, 0.1608, 0.0000, 0.3700, 0.0000, 0.2503, 0.0000,\n",
      "          0.0000, 0.0000, 0.1203, 0.0901, 0.1100, 0.3572, 0.0000, 0.1724,\n",
      "          0.0911, 0.0000, 0.1368, 0.0000, 0.2346, 0.1459, 0.2781, 0.0904],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0248,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[2.0339e-01, 1.0719e-01, 6.6354e-02, 8.9652e-03, 2.6714e-02,\n",
      "          2.9822e-02, 3.0210e-02, 2.4908e-02, 9.0054e-03, 0.0000e+00,\n",
      "          3.1000e-03, 2.2347e-02, 1.2321e-02, 1.3108e-01, 1.6532e-02,\n",
      "          5.2944e-03, 6.2054e-03, 9.3543e-03, 2.5591e-02, 2.5623e-02,\n",
      "          3.3169e-02, 2.7825e-02, 0.0000e+00, 1.8509e-02, 0.0000e+00,\n",
      "          2.0387e-01, 3.7289e-02, 4.1251e-02, 1.8579e-01, 3.3401e-02,\n",
      "          0.0000e+00, 0.0000e+00, 2.7909e-02, 1.3638e-02, 4.0043e-02,\n",
      "          2.6599e-02, 0.0000e+00, 1.3774e-02, 6.7997e-03, 3.6141e-03,\n",
      "          0.0000e+00, 8.3391e-04, 3.2545e-02, 2.1919e-02, 3.4871e-01,\n",
      "          3.3085e-02, 2.9182e-02, 3.2965e-02, 8.0700e-02, 1.0755e-02,\n",
      "          2.5877e-01, 2.2681e-01, 6.8465e-03, 1.6226e-01, 3.0150e-02,\n",
      "          1.3368e-02, 3.6548e-02, 3.5643e-02, 2.3963e-02, 2.4640e-02,\n",
      "          2.1075e-02, 1.5994e-02, 2.1231e-02, 1.5457e-02],\n",
      "         [3.9058e-01, 2.6613e-01, 3.5743e-01, 1.4655e-01, 3.8193e-01,\n",
      "          3.3877e-01, 4.4859e-01, 3.2199e-01, 6.1972e-02, 0.0000e+00,\n",
      "          1.9005e-01, 3.8275e-01, 3.0936e-01, 4.1432e-01, 9.7613e-02,\n",
      "          1.9044e-01, 0.0000e+00, 3.0497e-01, 4.2772e-01, 4.5455e-01,\n",
      "          5.5354e-01, 4.2641e-02, 1.4110e-01, 1.2307e-02, 3.2795e-01,\n",
      "          3.3737e-01, 2.1299e-01, 5.1937e-01, 3.0455e-01, 2.6053e-01,\n",
      "          1.6900e-01, 0.0000e+00, 3.3877e-01, 3.7532e-01, 5.6534e-01,\n",
      "          1.5385e-01, 1.8627e-01, 1.1575e-01, 1.5058e-01, 1.3266e-01,\n",
      "          0.0000e+00, 1.8127e-01, 1.8817e-01, 3.9953e-01, 2.9396e-01,\n",
      "          4.0332e-01, 5.1116e-01, 3.3816e-01, 1.3880e-01, 3.2988e-02,\n",
      "          4.3721e-01, 3.5327e-01, 2.5298e-01, 3.1815e-01, 8.7116e-02,\n",
      "          5.0081e-01, 3.6906e-01, 1.9412e-01, 6.3830e-02, 3.9808e-01,\n",
      "          3.9351e-01, 3.1196e-01, 3.0081e-01, 1.1341e-01],\n",
      "         [3.7437e-01, 7.2517e-01, 1.9128e-01, 4.0776e-01, 5.5269e-01,\n",
      "          4.4533e-01, 3.4741e-01, 6.8521e-01, 5.1392e-01, 4.9856e-01,\n",
      "          4.6386e-01, 2.6623e-01, 2.4722e-01, 8.1872e-01, 5.4112e-01,\n",
      "          1.0826e-01, 6.0847e-01, 1.7332e-01, 3.8028e-01, 2.1467e-01,\n",
      "          5.5609e-01, 6.8525e-01, 4.7967e-01, 5.8613e-01, 6.9945e-02,\n",
      "          7.6836e-01, 4.8826e-01, 1.9927e-01, 6.0259e-01, 5.7654e-01,\n",
      "          4.1927e-01, 3.5280e-01, 4.3772e-01, 2.4094e-01, 4.8134e-01,\n",
      "          7.3916e-01, 4.0546e-01, 7.1964e-01, 4.2706e-01, 4.6873e-01,\n",
      "          3.2137e-01, 4.1774e-01, 3.5449e-01, 3.1549e-01, 2.7285e-01,\n",
      "          5.2282e-01, 5.0554e-01, 5.2500e-01, 6.7149e-01, 4.4240e-01,\n",
      "          3.9806e-01, 4.6689e-01, 2.7545e-01, 6.3702e-01, 5.1954e-01,\n",
      "          1.0454e-01, 6.2688e-01, 4.7111e-01, 4.5784e-01, 5.6975e-01,\n",
      "          2.6117e-01, 3.4331e-01, 8.4302e-01, 4.7576e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "         [1.8987e-01, 0.0000e+00, 1.0719e-01, 0.0000e+00, 1.6665e-01,\n",
      "          3.4015e-02, 1.3607e-01, 2.0954e-01, 5.0978e-03, 0.0000e+00,\n",
      "          6.8765e-02, 1.4277e-01, 1.8465e-01, 2.0733e-02, 0.0000e+00,\n",
      "          8.4004e-03, 0.0000e+00, 8.1866e-02, 0.0000e+00, 2.6841e-01,\n",
      "          3.5771e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8758e-01,\n",
      "          0.0000e+00, 3.1907e-02, 3.6257e-01, 0.0000e+00, 5.0468e-02,\n",
      "          1.1267e-01, 0.0000e+00, 2.5723e-01, 1.9844e-01, 0.0000e+00,\n",
      "          1.0488e-01, 2.6285e-01, 4.8765e-02, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.1090e-01, 0.0000e+00, 0.0000e+00, 1.3390e-01,\n",
      "          1.3051e-01, 5.5629e-01, 0.0000e+00, 1.4432e-03, 1.0777e-01,\n",
      "          1.5334e-01, 0.0000e+00, 2.3978e-01, 1.2694e-02, 0.0000e+00,\n",
      "          4.9289e-01, 0.0000e+00, 1.2671e-02, 5.8474e-02, 0.0000e+00,\n",
      "          1.1607e-01, 1.1771e-01, 9.7310e-02, 0.0000e+00],\n",
      "         [6.4645e-01, 5.6875e-01, 4.8059e-01, 5.1106e-01, 4.9212e-01,\n",
      "          3.2952e-01, 3.1666e-01, 4.5785e-01, 7.0477e-01, 8.1934e-01,\n",
      "          7.4381e-01, 3.4036e-01, 3.4642e-01, 7.9204e-01, 4.8979e-01,\n",
      "          8.7778e-01, 5.6902e-01, 5.6902e-01, 3.3755e-01, 9.3072e-02,\n",
      "          3.7918e-01, 3.7222e-01, 1.0703e+00, 4.4680e-01, 5.2822e-01,\n",
      "          7.7449e-01, 2.0836e-01, 5.6788e-01, 5.6297e-01, 3.7620e-01,\n",
      "          7.5922e-01, 6.8676e-01, 3.5898e-01, 2.8784e-01, 4.1338e-01,\n",
      "          3.4025e-01, 7.5152e-01, 6.9459e-01, 6.8725e-01, 7.5520e-01,\n",
      "          6.7887e-01, 6.6760e-01, 6.1537e-01, 3.6115e-01, 4.5319e-01,\n",
      "          2.5215e-01, 1.4658e-01, 5.2163e-01, 6.7465e-01, 8.0042e-01,\n",
      "          8.1304e-01, 4.1945e-01, 2.9025e-01, 8.8490e-01, 2.5470e-01,\n",
      "          3.1876e-01, 4.8934e-01, 3.8334e-01, 8.3815e-01, 7.1811e-01,\n",
      "          2.9763e-01, 4.3479e-01, 6.3114e-01, 5.0855e-01],\n",
      "         [2.0599e-01, 1.6280e-02, 2.2948e-01, 1.4385e-01, 1.4283e-01,\n",
      "          1.1113e-01, 3.8413e-02, 1.9539e-01, 1.5188e-01, 3.1404e-02,\n",
      "          1.5295e-02, 1.4332e-02, 8.2595e-02, 1.2130e-01, 7.1369e-02,\n",
      "          3.0709e-01, 6.7174e-02, 2.5785e-01, 3.2848e-02, 1.0800e-01,\n",
      "          2.6862e-01, 3.5691e-02, 1.3004e-01, 1.3951e-02, 3.1619e-01,\n",
      "          4.5268e-03, 1.9847e-02, 1.9632e-01, 2.4977e-01, 2.2262e-02,\n",
      "          4.4897e-01, 8.3939e-03, 6.3286e-02, 1.8319e-01, 8.6785e-03,\n",
      "          1.4343e-01, 1.4923e-01, 8.2620e-02, 5.2319e-02, 8.0942e-02,\n",
      "          1.2447e-01, 2.3540e-02, 1.6084e-01, 1.5114e-02, 3.7823e-01,\n",
      "          1.7859e-02, 2.9319e-01, 9.1314e-03, 1.4421e-02, 1.3626e-02,\n",
      "          1.3631e-01, 1.0102e-01, 1.3880e-01, 3.6690e-01, 2.1934e-02,\n",
      "          2.0808e-01, 9.8139e-02, 2.5757e-02, 1.5157e-01, 9.7352e-03,\n",
      "          2.4839e-01, 1.6285e-01, 2.9220e-01, 1.0567e-01],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 2.4816e-02, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[2.0339e-01, 1.0719e-01, 6.6354e-02, 8.9652e-03, 2.6714e-02,\n",
      "          2.9822e-02, 3.0210e-02, 2.4908e-02, 9.0054e-03, 0.0000e+00,\n",
      "          3.1000e-03, 2.2347e-02, 1.2321e-02, 1.3108e-01, 1.6532e-02,\n",
      "          5.2944e-03, 6.2054e-03, 9.3543e-03, 2.5591e-02, 2.5623e-02,\n",
      "          3.3169e-02, 2.7825e-02, 0.0000e+00, 1.8509e-02, 0.0000e+00,\n",
      "          2.0387e-01, 3.7289e-02, 4.1251e-02, 1.8579e-01, 3.3401e-02,\n",
      "          0.0000e+00, 0.0000e+00, 2.7909e-02, 1.3638e-02, 4.0043e-02,\n",
      "          2.6599e-02, 0.0000e+00, 1.3774e-02, 6.7997e-03, 3.6141e-03,\n",
      "          0.0000e+00, 8.3391e-04, 3.2545e-02, 2.1919e-02, 3.4871e-01,\n",
      "          3.3085e-02, 2.9182e-02, 3.2965e-02, 8.0700e-02, 1.0755e-02,\n",
      "          2.5877e-01, 2.2681e-01, 6.8465e-03, 1.6226e-01, 3.0150e-02,\n",
      "          1.3368e-02, 3.6548e-02, 3.5643e-02, 2.3963e-02, 2.4640e-02,\n",
      "          2.1075e-02, 1.5994e-02, 2.1231e-02, 1.5457e-02],\n",
      "         [3.9058e-01, 2.6613e-01, 3.5743e-01, 1.4655e-01, 3.8193e-01,\n",
      "          3.3877e-01, 4.4859e-01, 3.2199e-01, 6.1972e-02, 0.0000e+00,\n",
      "          1.9005e-01, 3.8275e-01, 3.0936e-01, 4.1432e-01, 9.7613e-02,\n",
      "          1.9044e-01, 0.0000e+00, 3.0497e-01, 4.2772e-01, 4.5455e-01,\n",
      "          5.5354e-01, 4.2641e-02, 1.4110e-01, 1.2307e-02, 3.2795e-01,\n",
      "          3.3737e-01, 2.1299e-01, 5.1937e-01, 3.0455e-01, 2.6053e-01,\n",
      "          1.6900e-01, 0.0000e+00, 3.3877e-01, 3.7532e-01, 5.6534e-01,\n",
      "          1.5385e-01, 1.8627e-01, 1.1575e-01, 1.5058e-01, 1.3266e-01,\n",
      "          0.0000e+00, 1.8127e-01, 1.8817e-01, 3.9953e-01, 2.9396e-01,\n",
      "          4.0332e-01, 5.1116e-01, 3.3816e-01, 1.3880e-01, 3.2988e-02,\n",
      "          4.3721e-01, 3.5327e-01, 2.5298e-01, 3.1815e-01, 8.7116e-02,\n",
      "          5.0081e-01, 3.6906e-01, 1.9412e-01, 6.3830e-02, 3.9808e-01,\n",
      "          3.9351e-01, 3.1196e-01, 3.0081e-01, 1.1341e-01],\n",
      "         [3.7437e-01, 7.2517e-01, 1.9128e-01, 4.0776e-01, 5.5269e-01,\n",
      "          4.4533e-01, 3.4741e-01, 6.8521e-01, 5.1392e-01, 4.9856e-01,\n",
      "          4.6386e-01, 2.6623e-01, 2.4722e-01, 8.1872e-01, 5.4112e-01,\n",
      "          1.0826e-01, 6.0847e-01, 1.7332e-01, 3.8028e-01, 2.1467e-01,\n",
      "          5.5609e-01, 6.8525e-01, 4.7967e-01, 5.8613e-01, 6.9945e-02,\n",
      "          7.6836e-01, 4.8826e-01, 1.9927e-01, 6.0259e-01, 5.7654e-01,\n",
      "          4.1927e-01, 3.5280e-01, 4.3772e-01, 2.4094e-01, 4.8134e-01,\n",
      "          7.3916e-01, 4.0546e-01, 7.1964e-01, 4.2706e-01, 4.6873e-01,\n",
      "          3.2137e-01, 4.1774e-01, 3.5449e-01, 3.1549e-01, 2.7285e-01,\n",
      "          5.2282e-01, 5.0554e-01, 5.2500e-01, 6.7149e-01, 4.4240e-01,\n",
      "          3.9806e-01, 4.6689e-01, 2.7545e-01, 6.3702e-01, 5.1954e-01,\n",
      "          1.0454e-01, 6.2688e-01, 4.7111e-01, 4.5784e-01, 5.6975e-01,\n",
      "          2.6117e-01, 3.4331e-01, 8.4302e-01, 4.7576e-01],\n",
      "         [2.9817e-02, 2.8351e-02, 2.8897e-02, 3.3178e-02, 2.5725e-02,\n",
      "          3.3290e-02, 3.2428e-02, 2.8014e-02, 3.3231e-02, 3.4287e-02,\n",
      "          2.4297e-02, 3.4545e-02, 3.1829e-02, 2.6775e-02, 3.2748e-02,\n",
      "          2.7126e-02, 3.3159e-02, 2.4397e-02, 3.5234e-02, 2.9413e-02,\n",
      "          3.0197e-02, 3.3906e-02, 2.3666e-02, 3.3570e-02, 2.6005e-02,\n",
      "          2.5794e-02, 3.5018e-02, 2.3477e-02, 3.3102e-02, 3.1315e-02,\n",
      "          2.8285e-02, 3.3650e-02, 3.1828e-02, 3.2885e-02, 2.5329e-02,\n",
      "          3.2933e-02, 3.1344e-02, 3.4233e-02, 3.2331e-02, 3.1845e-02,\n",
      "          3.4876e-02, 3.2907e-02, 3.1560e-02, 2.8349e-02, 2.9679e-02,\n",
      "          3.2020e-02, 3.0385e-02, 2.8455e-02, 2.9937e-02, 3.2570e-02,\n",
      "          2.1103e-02, 3.4873e-02, 3.2231e-02, 2.4675e-02, 3.6577e-02,\n",
      "          2.9112e-02, 2.5620e-02, 3.2208e-02, 3.0642e-02, 2.1690e-02,\n",
      "          3.1571e-02, 2.7637e-02, 2.5479e-02, 3.3526e-02],\n",
      "         [1.8987e-01, 0.0000e+00, 1.0719e-01, 0.0000e+00, 1.6665e-01,\n",
      "          3.4015e-02, 1.3607e-01, 2.0954e-01, 5.0978e-03, 0.0000e+00,\n",
      "          6.8765e-02, 1.4277e-01, 1.8465e-01, 2.0733e-02, 0.0000e+00,\n",
      "          8.4004e-03, 0.0000e+00, 8.1866e-02, 0.0000e+00, 2.6841e-01,\n",
      "          3.5771e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.8758e-01,\n",
      "          0.0000e+00, 3.1907e-02, 3.6257e-01, 0.0000e+00, 5.0468e-02,\n",
      "          1.1267e-01, 0.0000e+00, 2.5723e-01, 1.9844e-01, 0.0000e+00,\n",
      "          1.0488e-01, 2.6285e-01, 4.8765e-02, 0.0000e+00, 0.0000e+00,\n",
      "          0.0000e+00, 1.1090e-01, 0.0000e+00, 0.0000e+00, 1.3390e-01,\n",
      "          1.3051e-01, 5.5629e-01, 0.0000e+00, 1.4432e-03, 1.0777e-01,\n",
      "          1.5334e-01, 0.0000e+00, 2.3978e-01, 1.2694e-02, 0.0000e+00,\n",
      "          4.9289e-01, 0.0000e+00, 1.2671e-02, 5.8474e-02, 0.0000e+00,\n",
      "          1.1607e-01, 1.1771e-01, 9.7310e-02, 0.0000e+00],\n",
      "         [6.7501e-01, 5.8743e-01, 5.0364e-01, 5.3625e-01, 5.0451e-01,\n",
      "          3.5744e-01, 3.4227e-01, 4.7229e-01, 7.3117e-01, 8.4546e-01,\n",
      "          7.5756e-01, 3.6797e-01, 3.7697e-01, 8.1179e-01, 5.1755e-01,\n",
      "          9.0369e-01, 5.9182e-01, 5.8718e-01, 3.6645e-01, 1.1629e-01,\n",
      "          3.9753e-01, 3.9722e-01, 1.0887e+00, 4.7081e-01, 5.4534e-01,\n",
      "          7.9666e-01, 2.3663e-01, 5.8380e-01, 5.9295e-01, 3.9642e-01,\n",
      "          7.8046e-01, 7.1376e-01, 3.7786e-01, 3.1225e-01, 4.3163e-01,\n",
      "          3.6358e-01, 7.7504e-01, 7.2055e-01, 7.1348e-01, 7.8351e-01,\n",
      "          7.1007e-01, 6.9998e-01, 6.4074e-01, 3.7930e-01, 4.8369e-01,\n",
      "          2.7459e-01, 1.6123e-01, 5.4732e-01, 6.9807e-01, 8.2149e-01,\n",
      "          8.3200e-01, 4.5103e-01, 3.1153e-01, 9.0456e-01, 2.8756e-01,\n",
      "          3.3839e-01, 5.0471e-01, 4.1165e-01, 8.6143e-01, 7.2806e-01,\n",
      "          3.2520e-01, 4.5618e-01, 6.4518e-01, 5.3661e-01],\n",
      "         [2.0599e-01, 1.6280e-02, 2.2948e-01, 1.4385e-01, 1.4283e-01,\n",
      "          1.1113e-01, 3.8413e-02, 1.9539e-01, 1.5188e-01, 3.1404e-02,\n",
      "          1.5295e-02, 1.4332e-02, 8.2595e-02, 1.2130e-01, 7.1369e-02,\n",
      "          3.0709e-01, 6.7174e-02, 2.5785e-01, 3.2848e-02, 1.0800e-01,\n",
      "          2.6862e-01, 3.5691e-02, 1.3004e-01, 1.3951e-02, 3.1619e-01,\n",
      "          4.5268e-03, 1.9847e-02, 1.9632e-01, 2.4977e-01, 2.2262e-02,\n",
      "          4.4897e-01, 8.3939e-03, 6.3286e-02, 1.8319e-01, 8.6785e-03,\n",
      "          1.4343e-01, 1.4923e-01, 8.2620e-02, 5.2319e-02, 8.0942e-02,\n",
      "          1.2447e-01, 2.3540e-02, 1.6084e-01, 1.5114e-02, 3.7823e-01,\n",
      "          1.7859e-02, 2.9319e-01, 9.1314e-03, 1.4421e-02, 1.3626e-02,\n",
      "          1.3631e-01, 1.0102e-01, 1.3880e-01, 3.6690e-01, 2.1934e-02,\n",
      "          2.0808e-01, 9.8139e-02, 2.5757e-02, 1.5157e-01, 9.7352e-03,\n",
      "          2.4839e-01, 1.6285e-01, 2.9220e-01, 1.0567e-01],\n",
      "         [1.9022e-01, 2.0144e-01, 1.9642e-01, 1.9621e-01, 2.0764e-01,\n",
      "          1.9295e-01, 1.9529e-01, 2.0642e-01, 1.9477e-01, 1.9570e-01,\n",
      "          2.0518e-01, 1.9403e-01, 1.8893e-01, 1.9926e-01, 1.9284e-01,\n",
      "          1.9194e-01, 1.9911e-01, 1.9986e-01, 1.9284e-01, 1.9650e-01,\n",
      "          2.0288e-01, 1.9685e-01, 1.9916e-01, 1.9787e-01, 2.0202e-01,\n",
      "          1.9575e-01, 1.9349e-01, 2.0207e-01, 1.9033e-01, 2.0122e-01,\n",
      "          1.9828e-01, 1.9427e-01, 2.0313e-01, 1.9700e-01, 2.0027e-01,\n",
      "          1.9834e-01, 1.9721e-01, 1.9586e-01, 1.9447e-01, 1.9166e-01,\n",
      "          1.8984e-01, 1.8730e-01, 1.9508e-01, 2.0210e-01, 1.8778e-01,\n",
      "          1.9892e-01, 2.0750e-01, 2.1777e-01, 1.9655e-01, 2.0089e-01,\n",
      "          1.9704e-01, 1.8937e-01, 2.0044e-01, 1.9819e-01, 1.8877e-01,\n",
      "          2.0071e-01, 2.0394e-01, 1.9186e-01, 1.9712e-01, 2.0835e-01,\n",
      "          1.9241e-01, 1.9773e-01, 2.0549e-01, 1.9291e-01]]], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n",
      "tensor([[[0.2479, 0.1436, 0.1056, 0.0498, 0.0622, 0.0659, 0.0728, 0.0595,\n",
      "          0.0458, 0.0411, 0.0361, 0.0647, 0.0498, 0.1685, 0.0531, 0.0426,\n",
      "          0.0517, 0.0421, 0.0695, 0.0664, 0.0780, 0.0665, 0.0329, 0.0632,\n",
      "          0.0359, 0.2423, 0.0795, 0.0813, 0.2235, 0.0723, 0.0362, 0.0373,\n",
      "          0.0711, 0.0535, 0.0812, 0.0619, 0.0318, 0.0490, 0.0417, 0.0382,\n",
      "          0.0370, 0.0375, 0.0785, 0.0643, 0.3874, 0.0730, 0.0712, 0.0697,\n",
      "          0.1177, 0.0512, 0.2973, 0.2759, 0.0457, 0.1946, 0.0681, 0.0583,\n",
      "          0.0740, 0.0739, 0.0646, 0.0595, 0.0638, 0.0541, 0.0563, 0.0557],\n",
      "         [0.5414, 0.4225, 0.5110, 0.3076, 0.5342, 0.4922, 0.5962, 0.4790,\n",
      "          0.2192, 0.1607, 0.3457, 0.5309, 0.4596, 0.5697, 0.2551, 0.3489,\n",
      "          0.1638, 0.4594, 0.5794, 0.5985, 0.7066, 0.2010, 0.2967, 0.1746,\n",
      "          0.4780, 0.4897, 0.3717, 0.6624, 0.4625, 0.4175, 0.3273, 0.1569,\n",
      "          0.4918, 0.5274, 0.7099, 0.3114, 0.3410, 0.2732, 0.3076, 0.2896,\n",
      "          0.1567, 0.3391, 0.3524, 0.5498, 0.4462, 0.5527, 0.6600, 0.4904,\n",
      "          0.2973, 0.1932, 0.5800, 0.5083, 0.4082, 0.4733, 0.2446, 0.6456,\n",
      "          0.5254, 0.3517, 0.2255, 0.5481, 0.5504, 0.4682, 0.4582, 0.2722],\n",
      "         [0.3744, 0.7252, 0.1913, 0.4078, 0.5527, 0.4453, 0.3474, 0.6852,\n",
      "          0.5139, 0.4986, 0.4639, 0.2662, 0.2472, 0.8187, 0.5411, 0.1083,\n",
      "          0.6085, 0.1733, 0.3803, 0.2147, 0.5561, 0.6852, 0.4797, 0.5861,\n",
      "          0.0699, 0.7684, 0.4883, 0.1993, 0.6026, 0.5765, 0.4193, 0.3528,\n",
      "          0.4377, 0.2409, 0.4813, 0.7392, 0.4055, 0.7196, 0.4271, 0.4687,\n",
      "          0.3214, 0.4177, 0.3545, 0.3155, 0.2729, 0.5228, 0.5055, 0.5250,\n",
      "          0.6715, 0.4424, 0.3981, 0.4669, 0.2755, 0.6370, 0.5195, 0.1045,\n",
      "          0.6269, 0.4711, 0.4578, 0.5697, 0.2612, 0.3433, 0.8430, 0.4758],\n",
      "         [0.0298, 0.0284, 0.0289, 0.0332, 0.0257, 0.0333, 0.0324, 0.0280,\n",
      "          0.0332, 0.0343, 0.0243, 0.0345, 0.0318, 0.0268, 0.0327, 0.0271,\n",
      "          0.0332, 0.0244, 0.0352, 0.0294, 0.0302, 0.0339, 0.0237, 0.0336,\n",
      "          0.0260, 0.0258, 0.0350, 0.0235, 0.0331, 0.0313, 0.0283, 0.0336,\n",
      "          0.0318, 0.0329, 0.0253, 0.0329, 0.0313, 0.0342, 0.0323, 0.0318,\n",
      "          0.0349, 0.0329, 0.0316, 0.0283, 0.0297, 0.0320, 0.0304, 0.0285,\n",
      "          0.0299, 0.0326, 0.0211, 0.0349, 0.0322, 0.0247, 0.0366, 0.0291,\n",
      "          0.0256, 0.0322, 0.0306, 0.0217, 0.0316, 0.0276, 0.0255, 0.0335],\n",
      "         [0.2136, 0.0195, 0.1283, 0.0163, 0.1892, 0.0556, 0.1610, 0.2289,\n",
      "          0.0251, 0.0170, 0.0892, 0.1676, 0.2083, 0.0407, 0.0196, 0.0269,\n",
      "          0.0146, 0.1033, 0.0224, 0.2960, 0.3783, 0.0194, 0.0205, 0.0164,\n",
      "          0.5116, 0.0221, 0.0504, 0.3910, 0.0194, 0.0697, 0.1308, 0.0208,\n",
      "          0.2786, 0.2205, 0.0271, 0.1237, 0.2842, 0.0677, 0.0195, 0.0194,\n",
      "          0.0210, 0.1297, 0.0141, 0.0237, 0.1560, 0.1544, 0.5803, 0.0223,\n",
      "          0.0197, 0.1251, 0.1821, 0.0202, 0.2597, 0.0337, 0.0203, 0.5193,\n",
      "          0.0194, 0.0324, 0.0737, 0.0242, 0.1347, 0.1370, 0.1163, 0.0194],\n",
      "         [0.7086, 0.6215, 0.5366, 0.5726, 0.5373, 0.3905, 0.3731, 0.5067,\n",
      "          0.7672, 0.8823, 0.7917, 0.3993, 0.4089, 0.8454, 0.5532, 0.9392,\n",
      "          0.6298, 0.6209, 0.3992, 0.1458, 0.4296, 0.4340, 1.1228, 0.5093,\n",
      "          0.5774, 0.8292, 0.2731, 0.6131, 0.6292, 0.4312, 0.8152, 0.7505,\n",
      "          0.4109, 0.3445, 0.4613, 0.3981, 0.8090, 0.7551, 0.7482, 0.8180,\n",
      "          0.7468, 0.7351, 0.6787, 0.4118, 0.5161, 0.3060, 0.1922, 0.5800,\n",
      "          0.7333, 0.8581, 0.8614, 0.4857, 0.3450, 0.9386, 0.3243, 0.3678,\n",
      "          0.5386, 0.4479, 0.8970, 0.7602, 0.3595, 0.4900, 0.6797, 0.5742],\n",
      "         [0.2398, 0.0385, 0.2574, 0.1616, 0.1701, 0.1372, 0.0770, 0.2154,\n",
      "          0.1716, 0.0492, 0.0360, 0.0517, 0.1142, 0.1455, 0.0910, 0.3262,\n",
      "          0.0833, 0.2801, 0.0661, 0.1507, 0.3014, 0.0548, 0.1508, 0.0308,\n",
      "          0.3468, 0.0338, 0.0409, 0.2397, 0.2691, 0.0447, 0.4683, 0.0282,\n",
      "          0.0942, 0.2138, 0.0507, 0.1631, 0.1704, 0.1024, 0.0723, 0.1009,\n",
      "          0.1444, 0.0432, 0.1768, 0.0492, 0.4078, 0.0524, 0.3299, 0.0373,\n",
      "          0.0335, 0.0317, 0.1789, 0.1321, 0.1643, 0.3879, 0.0415, 0.2525,\n",
      "          0.1210, 0.0458, 0.1690, 0.0396, 0.2736, 0.1864, 0.3120, 0.1244],\n",
      "         [0.1902, 0.2014, 0.1964, 0.1962, 0.2076, 0.1930, 0.1953, 0.2064,\n",
      "          0.1948, 0.1957, 0.2052, 0.1940, 0.1889, 0.1993, 0.1928, 0.1919,\n",
      "          0.1991, 0.1999, 0.1928, 0.1965, 0.2029, 0.1969, 0.1992, 0.1979,\n",
      "          0.2020, 0.1958, 0.1935, 0.2021, 0.1903, 0.2012, 0.1983, 0.1943,\n",
      "          0.2031, 0.1970, 0.2003, 0.1983, 0.1972, 0.1959, 0.1945, 0.1917,\n",
      "          0.1898, 0.1873, 0.1951, 0.2021, 0.1878, 0.1989, 0.2075, 0.2178,\n",
      "          0.1966, 0.2009, 0.1970, 0.1894, 0.2004, 0.1982, 0.1888, 0.2007,\n",
      "          0.2039, 0.1919, 0.1971, 0.2084, 0.1924, 0.1977, 0.2055, 0.1929]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([[3.3935e-02, 6.2851e-02, 4.0401e-02, 5.4048e-02, 1.5707e-02, 0.0000e+00,\n",
      "         9.5885e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9172e-01, 6.7937e-02,\n",
      "         2.9414e-01, 0.0000e+00, 0.0000e+00, 1.0782e-02]], device='cuda:0',\n",
      "       grad_fn=<SumBackward1>)\n",
      "tensor([[4.7565e-02, 5.2909e-02, 4.3924e-02, 7.8256e-02, 3.2561e-02, 1.0000e-06,\n",
      "         5.3619e-04, 1.0000e-06, 1.0000e-06, 1.0000e-06, 4.0379e-02, 7.0169e-02,\n",
      "         6.1626e-02, 1.0000e-06, 1.0000e-06, 2.8128e-02]], device='cuda:0',\n",
      "       grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    " \n",
    "# x = model(input_feats, lengths = None)\n",
    "# y = model(verify_feats, lengths = torch.ones((1)) * 0.4)\n",
    "y = model(verify_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.]]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "[[[1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]\n",
      "  [1.]]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "print(y.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.rand([2,3,4]).to(\"cuda\")\n",
    "h = h * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[8.4011, 1.1172, 4.1824, 7.0907],\n",
      "         [8.1731, 3.3377, 6.7031, 1.9289],\n",
      "         [1.1986, 7.2020, 4.3505, 7.0309]],\n",
      "\n",
      "        [[3.4503, 3.7960, 3.7190, 3.6708],\n",
      "         [8.5701, 1.4724, 4.0164, 8.0232],\n",
      "         [6.7687, 5.2350, 1.8173, 0.4282]]], device='cuda:0')\n",
      "tensor([[[2.8985, 1.0570, 2.0451, 2.6628],\n",
      "         [2.8589, 1.8269, 2.5890, 1.3888],\n",
      "         [1.0948, 2.6837, 2.0858, 2.6516]],\n",
      "\n",
      "        [[1.8575, 1.9483, 1.9285, 1.9159],\n",
      "         [2.9275, 1.2134, 2.0041, 2.8325],\n",
      "         [2.6017, 2.2880, 1.3481, 0.6544]]], device='cuda:0')\n",
      "tensor([[20.7913, 20.1428, 19.7820],\n",
      "        [14.6360, 22.0821, 14.2492]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(h)\n",
    "print(h.sqrt())\n",
    "print(h.sum(-1)) # Sum 1 = vertical sum, Sum -1 = horizontal sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
