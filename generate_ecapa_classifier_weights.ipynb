{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lib.ecapa_classifier import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from python_lib.saveasfile import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<python_lib.saveasfile.BlockSave at 0x13f10ebfd90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This out_neurons is after fc. Hence, due to ASP previously, we set out_neuron = 1\n",
    "\n",
    "# metrics_type = cosine / cdist\n",
    "model = ECAPA_TDNN(input_size = 2, \n",
    "                   channels=[8,8,8,8,16], \n",
    "                   lin_neurons=6, \n",
    "                   device = \"cuda\", \n",
    "                   out_neurons=1, \n",
    "                   metrics_type=\"cdist\").to(\"cuda\")\n",
    "\n",
    "BlockSave(model.return_layers(), \"fullecapa_classifier\", \"ECAPAweights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Feats for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4629162  0.56466305 0.5285809  0.48221552 0.24570459 0.7500036\n",
      "  0.5816848  0.32972914 0.4449641  0.7065414  0.8695886  0.23195964\n",
      "  0.695755   0.51410794 0.87433195 0.65152377 0.1355058  0.7814683\n",
      "  0.5267974  0.71288145 0.0426414  0.12902594 0.19542998 0.35988194\n",
      "  0.5098279  0.80921704 0.487055   0.14214939 0.31164324 0.25947946\n",
      "  0.36546785 0.33451957 0.8040535  0.01970893 0.6230692  0.8192368\n",
      "  0.04617286 0.86011034 0.5483832  0.6165986  0.28876096 0.04636413\n",
      "  0.78321767 0.4081024  0.10723877 0.4208662  0.6869501  0.20394701\n",
      "  0.60636896 0.6213251  0.6397216  0.4335339  0.20355624 0.5869981\n",
      "  0.7846082  0.6921419  0.6975281  0.78266644 0.27591783 0.10952723\n",
      "  0.42120606 0.9172891  0.69875014 0.75759137]\n",
      " [0.80645907 0.36684024 0.61927027 0.9136504  0.9291265  0.7362941\n",
      "  0.46269137 0.76140994 0.83184    0.32902944 0.7145785  0.1944775\n",
      "  0.38395917 0.6068464  0.22478127 0.7263193  0.6628643  0.2677577\n",
      "  0.72656363 0.725866   0.94075525 0.38793957 0.59775656 0.10375166\n",
      "  0.35801375 0.7232222  0.23250711 0.1805492  0.07879674 0.12321824\n",
      "  0.19168639 0.30072695 0.95254797 0.6697149  0.07431316 0.13152713\n",
      "  0.96141076 0.8636348  0.6128057  0.6670323  0.2719099  0.4612987\n",
      "  0.4890858  0.7013235  0.25107658 0.06478262 0.5766739  0.68073535\n",
      "  0.05298442 0.8955513  0.54203767 0.17153555 0.36773443 0.0781368\n",
      "  0.41314423 0.5312036  0.49527907 0.23445415 0.54084325 0.66645277\n",
      "  0.02872723 0.8305015  0.23601651 0.85094523]]\n",
      "(2, 64)\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,2,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (2,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "print(dim)\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"ecapainput_2x64.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model using eval/train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2085, 0.1154, 0.2787, 0.1152, 0.1449, 0.1373],\n",
       "         [0.2053, 0.1137, 0.2897, 0.1134, 0.1427, 0.1352],\n",
       "         [0.2081, 0.1152, 0.2800, 0.1150, 0.1447, 0.1370],\n",
       "         [0.2092, 0.1158, 0.2763, 0.1156, 0.1454, 0.1377],\n",
       "         [0.2141, 0.1186, 0.2592, 0.1183, 0.1488, 0.1410],\n",
       "         [0.1807, 0.1254, 0.3235, 0.1257, 0.1256, 0.1190]]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "x = model(input_feats)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
