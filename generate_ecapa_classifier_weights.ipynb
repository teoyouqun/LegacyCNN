{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lib.ecapa_classifier import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from python_lib.saveasfile import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<python_lib.saveasfile.BlockSave at 0x25170c70a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This out_neurons is after fc. Hence, due to ASP previously, we set out_neuron = 1\n",
    "model = ECAPA_TDNN(input_size = 2, \n",
    "                   channels=[8,8,8,8,16], \n",
    "                   lin_neurons=6, \n",
    "                   device = \"cuda\", \n",
    "                   out_neurons=1, \n",
    "                   metrics_type=\"cdist\").to(\"cuda\")\n",
    "\n",
    "BlockSave(model.return_layers(), \"fullecapa_classifier\", \"ECAPAweights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Feats for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95923495 0.21667826 0.5621671  0.23706234 0.3033359  0.03694999\n",
      "  0.37740964 0.224235   0.74950147 0.34869236 0.23700398 0.3429194\n",
      "  0.69733185 0.76776385 0.6667493  0.6746645  0.24459851 0.6610178\n",
      "  0.132263   0.85048324 0.17307138 0.04997939 0.16205359 0.9854669\n",
      "  0.0634675  0.20138973 0.99175113 0.07696563 0.31288052 0.06345773\n",
      "  0.6634577  0.71371037 0.12364846 0.820283   0.40758258 0.19352037\n",
      "  0.14435536 0.818656   0.81908137 0.73158455 0.75863516 0.16345179\n",
      "  0.7630889  0.9177353  0.06382704 0.5803384  0.9070647  0.4460439\n",
      "  0.27536666 0.9459219  0.05003589 0.03561199 0.73767644 0.5012399\n",
      "  0.23439986 0.32825732 0.7250442  0.9164342  0.09606677 0.3285752\n",
      "  0.26643097 0.6534477  0.21034431 0.6264224 ]\n",
      " [0.7381788  0.34922636 0.86058354 0.40361333 0.9443654  0.8810609\n",
      "  0.4562248  0.73306334 0.72970337 0.77645373 0.93702585 0.3894133\n",
      "  0.0290125  0.20063627 0.53522515 0.876028   0.65593505 0.2561506\n",
      "  0.69880456 0.30984724 0.40795594 0.24303263 0.888235   0.005032\n",
      "  0.20976043 0.23264349 0.5709934  0.4616533  0.5557147  0.47235924\n",
      "  0.39906383 0.6431023  0.49213648 0.9811159  0.02523625 0.6566606\n",
      "  0.3469404  0.6678447  0.13236475 0.7036455  0.26831168 0.17834038\n",
      "  0.2652369  0.36717016 0.39647895 0.02533191 0.7919613  0.68503696\n",
      "  0.22525632 0.7688943  0.341928   0.99300796 0.9801295  0.67571497\n",
      "  0.92961746 0.55231637 0.853075   0.49218273 0.6278269  0.9415096\n",
      "  0.8034098  0.63854545 0.79049295 0.5502212 ]]\n",
      "(2, 64)\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,2,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (2,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "print(dim)\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"ecapainput_2x64.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model using eval/train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0566, 0.2217, 0.2217, 0.2217, 0.0566, 0.2217],\n",
       "         [0.0746, 0.2127, 0.2127, 0.2127, 0.0746, 0.2127],\n",
       "         [0.2317, 0.1342, 0.1342, 0.1342, 0.2317, 0.1342],\n",
       "         [0.1892, 0.1554, 0.1554, 0.1554, 0.1892, 0.1554],\n",
       "         [0.1080, 0.1960, 0.1960, 0.1960, 0.1080, 0.1960],\n",
       "         [0.2366, 0.1317, 0.1317, 0.1317, 0.2366, 0.1317]]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "x = model(input_feats)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
