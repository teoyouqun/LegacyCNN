{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "torchvision is not available - cannot save figures\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "from python_lib.modules import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from python_lib.saveasfile import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model initialisation \n",
    "\n",
    "Use BlockSave to save all the weights into a `.bin` file\n",
    "\n",
    "Be sure to `load_state_dict` from a `.pt`/`.pth` file before BlockSave\n",
    "\n",
    "It's omitted here as I don't have the weights on hand, so I just use a random initialised weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<python_lib.saveasfile.BlockSave at 0x7fe93d5f76d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ECAPA_TDNN(input_size = 2, channels=[8,8,8,8,16], lin_neurons=6, device = \"cuda\").to(\"cuda\")\n",
    "\n",
    "BlockSave(model.return_layers(), \"fullecapa\", \"verifyCppVsPy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Input Feats for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.13175988 0.83884805 0.18142343 ... 0.03749532 0.9003383  0.71930987]\n",
      "  [0.07325369 0.23795128 0.22634566 ... 0.49048    0.2460568  0.5732361 ]]\n",
      "\n",
      " [[0.9554553  0.72399485 0.04407668 ... 0.4900689  0.16904444 0.03300488]\n",
      "  [0.676814   0.36807913 0.9845918  ... 0.10286719 0.968257   0.07335418]]\n",
      "\n",
      " [[0.03088188 0.36878616 0.0039925  ... 0.08633441 0.27036703 0.0772416 ]\n",
      "  [0.78553414 0.67571807 0.88156545 ... 0.665303   0.21483499 0.41274375]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.731148   0.36628282 0.24018592 ... 0.47873044 0.08777386 0.61594766]\n",
      "  [0.9290078  0.33120102 0.05099201 ... 0.6845378  0.9484555  0.8847231 ]]\n",
      "\n",
      " [[0.8790486  0.74943656 0.5798448  ... 0.57165754 0.8633431  0.40699255]\n",
      "  [0.80669284 0.44744015 0.24166703 ... 0.2780884  0.9402747  0.19634408]]\n",
      "\n",
      " [[0.06906515 0.6387082  0.38524663 ... 0.47731018 0.9629268  0.57335514]\n",
      "  [0.52897197 0.09806246 0.5458225  ... 0.12157243 0.49805576 0.940619  ]]]\n",
      "(100, 2, 64)\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([100,2,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (100,2,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "print(dim)\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"ecapainput_2x64_100.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model using eval/train mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1886, 0.1417, 0.1833, 0.1605, 0.1608, 0.1652],\n",
       "        [0.1889, 0.1416, 0.1829, 0.1611, 0.1604, 0.1651],\n",
       "        [0.1888, 0.1418, 0.1827, 0.1610, 0.1604, 0.1653],\n",
       "        [0.1890, 0.1416, 0.1833, 0.1606, 0.1603, 0.1653],\n",
       "        [0.1888, 0.1414, 0.1832, 0.1605, 0.1606, 0.1655],\n",
       "        [0.1892, 0.1416, 0.1832, 0.1609, 0.1602, 0.1650],\n",
       "        [0.1894, 0.1413, 0.1829, 0.1608, 0.1601, 0.1654],\n",
       "        [0.1892, 0.1415, 0.1833, 0.1610, 0.1600, 0.1650],\n",
       "        [0.1891, 0.1418, 0.1832, 0.1611, 0.1598, 0.1650],\n",
       "        [0.1893, 0.1413, 0.1828, 0.1608, 0.1604, 0.1654],\n",
       "        [0.1890, 0.1415, 0.1832, 0.1607, 0.1603, 0.1652],\n",
       "        [0.1894, 0.1415, 0.1832, 0.1610, 0.1598, 0.1651],\n",
       "        [0.1888, 0.1416, 0.1830, 0.1608, 0.1605, 0.1653],\n",
       "        [0.1893, 0.1413, 0.1829, 0.1609, 0.1602, 0.1653],\n",
       "        [0.1895, 0.1411, 0.1826, 0.1611, 0.1603, 0.1654],\n",
       "        [0.1889, 0.1416, 0.1834, 0.1606, 0.1602, 0.1652],\n",
       "        [0.1893, 0.1415, 0.1833, 0.1609, 0.1599, 0.1652],\n",
       "        [0.1891, 0.1414, 0.1832, 0.1608, 0.1603, 0.1653],\n",
       "        [0.1890, 0.1416, 0.1831, 0.1608, 0.1603, 0.1653],\n",
       "        [0.1889, 0.1416, 0.1832, 0.1611, 0.1601, 0.1651],\n",
       "        [0.1891, 0.1413, 0.1830, 0.1607, 0.1604, 0.1655],\n",
       "        [0.1894, 0.1414, 0.1828, 0.1612, 0.1600, 0.1652],\n",
       "        [0.1889, 0.1413, 0.1828, 0.1608, 0.1606, 0.1655],\n",
       "        [0.1890, 0.1416, 0.1830, 0.1610, 0.1603, 0.1651],\n",
       "        [0.1893, 0.1411, 0.1828, 0.1608, 0.1605, 0.1654],\n",
       "        [0.1889, 0.1415, 0.1832, 0.1609, 0.1602, 0.1653],\n",
       "        [0.1890, 0.1416, 0.1832, 0.1609, 0.1603, 0.1651],\n",
       "        [0.1892, 0.1414, 0.1829, 0.1609, 0.1604, 0.1654],\n",
       "        [0.1896, 0.1412, 0.1828, 0.1610, 0.1601, 0.1654],\n",
       "        [0.1890, 0.1414, 0.1828, 0.1607, 0.1605, 0.1656],\n",
       "        [0.1888, 0.1419, 0.1834, 0.1606, 0.1601, 0.1653],\n",
       "        [0.1891, 0.1412, 0.1828, 0.1609, 0.1605, 0.1655],\n",
       "        [0.1890, 0.1414, 0.1830, 0.1607, 0.1606, 0.1654],\n",
       "        [0.1892, 0.1412, 0.1830, 0.1611, 0.1604, 0.1651],\n",
       "        [0.1892, 0.1414, 0.1824, 0.1612, 0.1604, 0.1654],\n",
       "        [0.1897, 0.1411, 0.1829, 0.1607, 0.1601, 0.1656],\n",
       "        [0.1891, 0.1416, 0.1831, 0.1609, 0.1601, 0.1652],\n",
       "        [0.1889, 0.1415, 0.1833, 0.1608, 0.1603, 0.1652],\n",
       "        [0.1892, 0.1418, 0.1832, 0.1608, 0.1598, 0.1651],\n",
       "        [0.1892, 0.1415, 0.1832, 0.1605, 0.1602, 0.1654],\n",
       "        [0.1895, 0.1414, 0.1828, 0.1612, 0.1599, 0.1652],\n",
       "        [0.1893, 0.1413, 0.1830, 0.1609, 0.1600, 0.1654],\n",
       "        [0.1891, 0.1415, 0.1826, 0.1609, 0.1604, 0.1655],\n",
       "        [0.1889, 0.1415, 0.1833, 0.1608, 0.1602, 0.1653],\n",
       "        [0.1894, 0.1414, 0.1831, 0.1609, 0.1600, 0.1652],\n",
       "        [0.1892, 0.1413, 0.1830, 0.1609, 0.1602, 0.1654],\n",
       "        [0.1890, 0.1414, 0.1832, 0.1607, 0.1605, 0.1653],\n",
       "        [0.1888, 0.1416, 0.1833, 0.1606, 0.1605, 0.1653],\n",
       "        [0.1894, 0.1412, 0.1832, 0.1610, 0.1601, 0.1651],\n",
       "        [0.1890, 0.1414, 0.1828, 0.1609, 0.1604, 0.1655],\n",
       "        [0.1888, 0.1416, 0.1831, 0.1604, 0.1607, 0.1654],\n",
       "        [0.1893, 0.1413, 0.1832, 0.1610, 0.1602, 0.1650],\n",
       "        [0.1892, 0.1414, 0.1828, 0.1606, 0.1605, 0.1655],\n",
       "        [0.1894, 0.1411, 0.1830, 0.1609, 0.1603, 0.1653],\n",
       "        [0.1891, 0.1413, 0.1832, 0.1607, 0.1604, 0.1653],\n",
       "        [0.1891, 0.1414, 0.1829, 0.1607, 0.1604, 0.1656],\n",
       "        [0.1890, 0.1415, 0.1828, 0.1605, 0.1606, 0.1656],\n",
       "        [0.1891, 0.1416, 0.1830, 0.1609, 0.1602, 0.1652],\n",
       "        [0.1887, 0.1415, 0.1831, 0.1609, 0.1605, 0.1653],\n",
       "        [0.1892, 0.1413, 0.1831, 0.1610, 0.1603, 0.1651],\n",
       "        [0.1894, 0.1415, 0.1834, 0.1607, 0.1598, 0.1651],\n",
       "        [0.1894, 0.1412, 0.1825, 0.1609, 0.1604, 0.1656],\n",
       "        [0.1890, 0.1415, 0.1829, 0.1609, 0.1603, 0.1654],\n",
       "        [0.1892, 0.1412, 0.1828, 0.1608, 0.1604, 0.1655],\n",
       "        [0.1890, 0.1417, 0.1827, 0.1609, 0.1603, 0.1654],\n",
       "        [0.1888, 0.1415, 0.1827, 0.1609, 0.1607, 0.1654],\n",
       "        [0.1892, 0.1414, 0.1830, 0.1610, 0.1600, 0.1653],\n",
       "        [0.1894, 0.1414, 0.1828, 0.1611, 0.1601, 0.1652],\n",
       "        [0.1891, 0.1416, 0.1825, 0.1609, 0.1603, 0.1654],\n",
       "        [0.1894, 0.1414, 0.1830, 0.1611, 0.1599, 0.1652],\n",
       "        [0.1889, 0.1416, 0.1829, 0.1609, 0.1604, 0.1652],\n",
       "        [0.1890, 0.1414, 0.1831, 0.1604, 0.1606, 0.1654],\n",
       "        [0.1890, 0.1416, 0.1833, 0.1610, 0.1599, 0.1651],\n",
       "        [0.1890, 0.1414, 0.1829, 0.1605, 0.1606, 0.1656],\n",
       "        [0.1894, 0.1411, 0.1825, 0.1610, 0.1605, 0.1654],\n",
       "        [0.1889, 0.1414, 0.1833, 0.1608, 0.1604, 0.1651],\n",
       "        [0.1895, 0.1412, 0.1829, 0.1609, 0.1601, 0.1654],\n",
       "        [0.1891, 0.1417, 0.1830, 0.1607, 0.1602, 0.1653],\n",
       "        [0.1892, 0.1415, 0.1829, 0.1608, 0.1601, 0.1654],\n",
       "        [0.1887, 0.1414, 0.1831, 0.1606, 0.1608, 0.1654],\n",
       "        [0.1894, 0.1414, 0.1834, 0.1608, 0.1599, 0.1651],\n",
       "        [0.1892, 0.1412, 0.1828, 0.1610, 0.1604, 0.1653],\n",
       "        [0.1889, 0.1416, 0.1836, 0.1609, 0.1600, 0.1649],\n",
       "        [0.1889, 0.1415, 0.1833, 0.1606, 0.1604, 0.1653],\n",
       "        [0.1889, 0.1414, 0.1833, 0.1606, 0.1604, 0.1655],\n",
       "        [0.1890, 0.1418, 0.1832, 0.1608, 0.1599, 0.1653],\n",
       "        [0.1895, 0.1411, 0.1824, 0.1611, 0.1603, 0.1656],\n",
       "        [0.1893, 0.1412, 0.1830, 0.1608, 0.1603, 0.1654],\n",
       "        [0.1892, 0.1414, 0.1829, 0.1607, 0.1603, 0.1655],\n",
       "        [0.1892, 0.1415, 0.1828, 0.1609, 0.1604, 0.1652],\n",
       "        [0.1890, 0.1415, 0.1826, 0.1611, 0.1602, 0.1655],\n",
       "        [0.1890, 0.1415, 0.1831, 0.1605, 0.1608, 0.1651],\n",
       "        [0.1889, 0.1415, 0.1832, 0.1606, 0.1604, 0.1653],\n",
       "        [0.1893, 0.1415, 0.1832, 0.1610, 0.1600, 0.1650],\n",
       "        [0.1891, 0.1414, 0.1831, 0.1609, 0.1602, 0.1653],\n",
       "        [0.1889, 0.1415, 0.1831, 0.1609, 0.1605, 0.1652],\n",
       "        [0.1893, 0.1413, 0.1826, 0.1609, 0.1605, 0.1655],\n",
       "        [0.1890, 0.1414, 0.1834, 0.1610, 0.1602, 0.1650],\n",
       "        [0.1893, 0.1413, 0.1831, 0.1607, 0.1602, 0.1653],\n",
       "        [0.1895, 0.1411, 0.1827, 0.1610, 0.1604, 0.1655]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "model(input_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification Test C++ vs Py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Test Inputs\n",
    "\n",
    "**NOTE:** Change the values of `no_of_inputs, no_of_channel_in, no_of_input_width` accordingly to desired matrix size\n",
    "\n",
    "Randomizes a `no_of_inputs x no_of_channel_in x no_of_input_width` matrix and saves the values into:\n",
    "1. A binary (to feed C++ as input)\n",
    "2. A CSV (to verify input values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4920, 0.8966, 0.0585,  ..., 0.7164, 0.3834, 0.1841],\n",
      "         [0.1231, 0.0703, 0.8068,  ..., 0.8878, 0.7321, 0.7190]],\n",
      "\n",
      "        [[0.9525, 0.2039, 0.8994,  ..., 0.4834, 0.5234, 0.5332],\n",
      "         [0.4071, 0.7934, 0.8092,  ..., 0.2100, 0.8403, 0.7279]],\n",
      "\n",
      "        [[0.7715, 0.1092, 0.6154,  ..., 0.6676, 0.5152, 0.8531],\n",
      "         [0.7656, 0.1406, 0.3228,  ..., 0.8070, 0.3755, 0.6697]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.6021, 0.5138, 0.3099,  ..., 0.0966, 0.7463, 0.0050],\n",
      "         [0.3141, 0.0088, 0.1833,  ..., 0.7778, 0.7463, 0.5540]],\n",
      "\n",
      "        [[0.1909, 0.8926, 0.3834,  ..., 0.5524, 0.6472, 0.2927],\n",
      "         [0.7910, 0.8581, 0.2341,  ..., 0.8999, 0.3114, 0.3387]],\n",
      "\n",
      "        [[0.6611, 0.0896, 0.9388,  ..., 0.1348, 0.5562, 0.5656],\n",
      "         [0.2774, 0.2872, 0.0718,  ..., 0.3750, 0.4221, 0.3494]]],\n",
      "       device='cuda:0')\n",
      "(100, 2, 64)\n",
      "[[[0.49201256 0.89657307 0.05845124 ... 0.7164457  0.38338268 0.18413639]\n",
      "  [0.12307018 0.07034361 0.80682284 ... 0.8877535  0.7320817  0.719034  ]]\n",
      "\n",
      " [[0.9525231  0.20386183 0.8994193  ... 0.48335338 0.5234215  0.5332478 ]\n",
      "  [0.40707064 0.7934262  0.80924475 ... 0.21000981 0.8403181  0.72793597]]\n",
      "\n",
      " [[0.77149355 0.10916138 0.6153976  ... 0.66762906 0.51515716 0.853052  ]\n",
      "  [0.76558906 0.14056087 0.32276857 ... 0.807014   0.37549973 0.6696783 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.6021018  0.51383376 0.30989772 ... 0.09658569 0.7462538  0.00496244]\n",
      "  [0.3141371  0.00880849 0.18331409 ... 0.7777512  0.74631315 0.5540059 ]]\n",
      "\n",
      " [[0.19092107 0.8926143  0.38342667 ... 0.5523681  0.6471978  0.2927096 ]\n",
      "  [0.79096067 0.85805696 0.23409092 ... 0.8998523  0.31138605 0.33868855]]\n",
      "\n",
      " [[0.6611117  0.08956575 0.9388204  ... 0.1347959  0.55620486 0.56559926]\n",
      "  [0.2774436  0.28715003 0.07175463 ... 0.37501365 0.42213058 0.34939486]]]\n"
     ]
    }
   ],
   "source": [
    "no_of_inputs = 100\n",
    "no_of_channel_in = 2\n",
    "no_of_input_width = 64\n",
    "\n",
    "verify_feats = torch.rand([no_of_inputs,no_of_channel_in,no_of_input_width]).to(\"cuda\")\n",
    "print(verify_feats)\n",
    "verify_feats_np = verify_feats.cpu().detach().numpy()\n",
    "\n",
    "## Reshaping\n",
    "if no_of_inputs == 1:\n",
    "    verify_feats_np = np.reshape(verify_feats_np, (no_of_channel_in,no_of_input_width))\n",
    "else:\n",
    "    verify_feats_np = np.reshape(verify_feats_np, (no_of_inputs,no_of_channel_in,no_of_input_width)) \n",
    "dim = verify_feats_np.shape\n",
    "print(dim)\n",
    "\n",
    "## Writing verify inputs into binary\n",
    "flatten_verify = verify_feats_np.flatten()\n",
    "with open(os.path.join(\"verifyCppVsPy\", f\"testInput_ecapaModel_{no_of_inputs}x{no_of_channel_in}x{no_of_input_width}.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_verify.tobytes())\n",
    "            \n",
    "## Extracting verification input values into CSV\n",
    "array_2d = verify_feats_np.reshape(no_of_inputs, -1)\n",
    "output_df = pd.DataFrame(array_2d)\n",
    "output_df.to_csv(f\"verifyCppVsPy/testInput_ecapaModel_{no_of_inputs}x{no_of_channel_in}x{no_of_input_width}.csv\",\\\n",
    "                 header=False, index=False)\n",
    "print(verify_feats_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2048, 0.1356, 0.1430, 0.2038, 0.1498, 0.1630],\n",
       "        [0.2051, 0.1360, 0.1426, 0.2029, 0.1501, 0.1632],\n",
       "        [0.2052, 0.1358, 0.1428, 0.2033, 0.1502, 0.1628],\n",
       "        [0.2051, 0.1359, 0.1426, 0.2028, 0.1504, 0.1632],\n",
       "        [0.2057, 0.1357, 0.1424, 0.2029, 0.1502, 0.1632],\n",
       "        [0.2049, 0.1358, 0.1424, 0.2032, 0.1505, 0.1632],\n",
       "        [0.2057, 0.1359, 0.1423, 0.2030, 0.1501, 0.1631],\n",
       "        [0.2055, 0.1363, 0.1424, 0.2028, 0.1500, 0.1630],\n",
       "        [0.2057, 0.1356, 0.1426, 0.2027, 0.1504, 0.1631],\n",
       "        [0.2055, 0.1353, 0.1426, 0.2035, 0.1502, 0.1629],\n",
       "        [0.2059, 0.1355, 0.1427, 0.2032, 0.1501, 0.1626],\n",
       "        [0.2056, 0.1362, 0.1428, 0.2026, 0.1500, 0.1627],\n",
       "        [0.2062, 0.1359, 0.1424, 0.2031, 0.1500, 0.1623],\n",
       "        [0.2058, 0.1351, 0.1429, 0.2034, 0.1503, 0.1626],\n",
       "        [0.2061, 0.1364, 0.1414, 0.2023, 0.1510, 0.1628],\n",
       "        [0.2056, 0.1360, 0.1421, 0.2029, 0.1505, 0.1630],\n",
       "        [0.2052, 0.1363, 0.1430, 0.2028, 0.1501, 0.1627],\n",
       "        [0.2058, 0.1358, 0.1426, 0.2029, 0.1502, 0.1627],\n",
       "        [0.2049, 0.1356, 0.1432, 0.2030, 0.1500, 0.1633],\n",
       "        [0.2053, 0.1361, 0.1424, 0.2030, 0.1500, 0.1632],\n",
       "        [0.2049, 0.1355, 0.1433, 0.2033, 0.1498, 0.1632],\n",
       "        [0.2056, 0.1359, 0.1427, 0.2029, 0.1503, 0.1627],\n",
       "        [0.2054, 0.1354, 0.1427, 0.2035, 0.1499, 0.1630],\n",
       "        [0.2060, 0.1355, 0.1421, 0.2031, 0.1507, 0.1626],\n",
       "        [0.2049, 0.1363, 0.1431, 0.2025, 0.1501, 0.1631],\n",
       "        [0.2056, 0.1362, 0.1426, 0.2036, 0.1496, 0.1624],\n",
       "        [0.2055, 0.1358, 0.1421, 0.2033, 0.1504, 0.1628],\n",
       "        [0.2058, 0.1358, 0.1422, 0.2032, 0.1502, 0.1628],\n",
       "        [0.2054, 0.1361, 0.1427, 0.2031, 0.1500, 0.1628],\n",
       "        [0.2057, 0.1360, 0.1425, 0.2028, 0.1502, 0.1628],\n",
       "        [0.2057, 0.1363, 0.1422, 0.2033, 0.1498, 0.1627],\n",
       "        [0.2054, 0.1357, 0.1425, 0.2027, 0.1506, 0.1631],\n",
       "        [0.2049, 0.1355, 0.1428, 0.2040, 0.1496, 0.1632],\n",
       "        [0.2048, 0.1363, 0.1431, 0.2033, 0.1496, 0.1630],\n",
       "        [0.2041, 0.1358, 0.1433, 0.2031, 0.1501, 0.1637],\n",
       "        [0.2039, 0.1354, 0.1438, 0.2032, 0.1500, 0.1637],\n",
       "        [0.2063, 0.1359, 0.1420, 0.2025, 0.1507, 0.1626],\n",
       "        [0.2049, 0.1357, 0.1435, 0.2031, 0.1498, 0.1631],\n",
       "        [0.2060, 0.1359, 0.1422, 0.2027, 0.1506, 0.1626],\n",
       "        [0.2052, 0.1359, 0.1424, 0.2020, 0.1510, 0.1634],\n",
       "        [0.2061, 0.1361, 0.1422, 0.2027, 0.1505, 0.1624],\n",
       "        [0.2051, 0.1365, 0.1425, 0.2028, 0.1503, 0.1628],\n",
       "        [0.2048, 0.1353, 0.1428, 0.2035, 0.1504, 0.1632],\n",
       "        [0.2058, 0.1359, 0.1426, 0.2029, 0.1501, 0.1627],\n",
       "        [0.2049, 0.1368, 0.1430, 0.2022, 0.1500, 0.1631],\n",
       "        [0.2058, 0.1356, 0.1425, 0.2031, 0.1500, 0.1629],\n",
       "        [0.2054, 0.1357, 0.1428, 0.2033, 0.1500, 0.1626],\n",
       "        [0.2048, 0.1356, 0.1432, 0.2034, 0.1500, 0.1629],\n",
       "        [0.2055, 0.1352, 0.1425, 0.2033, 0.1505, 0.1630],\n",
       "        [0.2054, 0.1352, 0.1432, 0.2034, 0.1498, 0.1629],\n",
       "        [0.2057, 0.1361, 0.1426, 0.2031, 0.1497, 0.1628],\n",
       "        [0.2045, 0.1360, 0.1432, 0.2033, 0.1499, 0.1631],\n",
       "        [0.2056, 0.1363, 0.1427, 0.2030, 0.1500, 0.1625],\n",
       "        [0.2060, 0.1354, 0.1424, 0.2029, 0.1505, 0.1628],\n",
       "        [0.2057, 0.1354, 0.1426, 0.2030, 0.1503, 0.1630],\n",
       "        [0.2057, 0.1359, 0.1424, 0.2033, 0.1501, 0.1626],\n",
       "        [0.2045, 0.1357, 0.1431, 0.2033, 0.1501, 0.1632],\n",
       "        [0.2052, 0.1355, 0.1438, 0.2030, 0.1495, 0.1630],\n",
       "        [0.2052, 0.1354, 0.1432, 0.2033, 0.1498, 0.1630],\n",
       "        [0.2052, 0.1362, 0.1426, 0.2030, 0.1500, 0.1631],\n",
       "        [0.2050, 0.1363, 0.1427, 0.2032, 0.1498, 0.1630],\n",
       "        [0.2057, 0.1350, 0.1426, 0.2032, 0.1504, 0.1632],\n",
       "        [0.2049, 0.1362, 0.1427, 0.2031, 0.1503, 0.1629],\n",
       "        [0.2055, 0.1361, 0.1429, 0.2031, 0.1498, 0.1626],\n",
       "        [0.2047, 0.1353, 0.1428, 0.2031, 0.1506, 0.1634],\n",
       "        [0.2055, 0.1358, 0.1426, 0.2029, 0.1504, 0.1628],\n",
       "        [0.2046, 0.1360, 0.1432, 0.2036, 0.1495, 0.1632],\n",
       "        [0.2060, 0.1357, 0.1425, 0.2032, 0.1499, 0.1627],\n",
       "        [0.2055, 0.1357, 0.1422, 0.2025, 0.1508, 0.1633],\n",
       "        [0.2041, 0.1358, 0.1438, 0.2031, 0.1497, 0.1635],\n",
       "        [0.2060, 0.1355, 0.1422, 0.2033, 0.1501, 0.1628],\n",
       "        [0.2057, 0.1359, 0.1423, 0.2027, 0.1503, 0.1630],\n",
       "        [0.2042, 0.1359, 0.1433, 0.2031, 0.1501, 0.1633],\n",
       "        [0.2049, 0.1349, 0.1430, 0.2038, 0.1504, 0.1630],\n",
       "        [0.2044, 0.1356, 0.1434, 0.2028, 0.1503, 0.1635],\n",
       "        [0.2047, 0.1357, 0.1431, 0.2030, 0.1503, 0.1632],\n",
       "        [0.2059, 0.1352, 0.1427, 0.2033, 0.1498, 0.1631],\n",
       "        [0.2046, 0.1361, 0.1433, 0.2032, 0.1495, 0.1633],\n",
       "        [0.2049, 0.1364, 0.1431, 0.2027, 0.1502, 0.1627],\n",
       "        [0.2048, 0.1360, 0.1426, 0.2024, 0.1506, 0.1637],\n",
       "        [0.2052, 0.1362, 0.1426, 0.2029, 0.1501, 0.1629],\n",
       "        [0.2056, 0.1360, 0.1426, 0.2033, 0.1499, 0.1625],\n",
       "        [0.2047, 0.1365, 0.1430, 0.2030, 0.1500, 0.1629],\n",
       "        [0.2056, 0.1352, 0.1428, 0.2037, 0.1498, 0.1628],\n",
       "        [0.2053, 0.1357, 0.1428, 0.2031, 0.1502, 0.1629],\n",
       "        [0.2048, 0.1356, 0.1435, 0.2030, 0.1498, 0.1633],\n",
       "        [0.2056, 0.1354, 0.1422, 0.2030, 0.1507, 0.1631],\n",
       "        [0.2054, 0.1367, 0.1426, 0.2034, 0.1496, 0.1623],\n",
       "        [0.2055, 0.1355, 0.1423, 0.2031, 0.1506, 0.1630],\n",
       "        [0.2048, 0.1361, 0.1426, 0.2027, 0.1504, 0.1633],\n",
       "        [0.2052, 0.1360, 0.1435, 0.2030, 0.1494, 0.1630],\n",
       "        [0.2040, 0.1362, 0.1439, 0.2030, 0.1493, 0.1635],\n",
       "        [0.2049, 0.1356, 0.1421, 0.2032, 0.1508, 0.1633],\n",
       "        [0.2051, 0.1360, 0.1426, 0.2024, 0.1510, 0.1629],\n",
       "        [0.2047, 0.1363, 0.1431, 0.2031, 0.1496, 0.1631],\n",
       "        [0.2055, 0.1357, 0.1430, 0.2034, 0.1498, 0.1625],\n",
       "        [0.2042, 0.1357, 0.1429, 0.2034, 0.1505, 0.1632],\n",
       "        [0.2054, 0.1362, 0.1425, 0.2032, 0.1497, 0.1630],\n",
       "        [0.2051, 0.1362, 0.1425, 0.2038, 0.1497, 0.1627],\n",
       "        [0.2058, 0.1352, 0.1419, 0.2031, 0.1509, 0.1631]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(verify_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.204813  , 0.1356151 , 0.14296354, 0.20381366, 0.14983083,\n",
       "       0.16296394], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(verify_feats).cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
