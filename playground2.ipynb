{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from python_lib.modules import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ECAPA_TDNN(input_size = 2, channels=[8,8,8,8,16], lin_neurons=6, device = \"cuda\").to(\"cuda\")\n",
    "input_feats = torch.rand([10,2,64]).to(\"cuda\")\n",
    "output = model(input_feats)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire ECAPA-TDNN Model overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial out:  torch.Size([10, 8, 64])\n",
      "SERes2_1 out:  torch.Size([10, 8, 64])\n",
      "SERes2_2 out:  torch.Size([10, 8, 64])\n",
      "SERes2_3 out:  torch.Size([10, 8, 64])\n",
      "mfa out:  torch.Size([10, 8, 64])\n",
      "asp out:  torch.Size([10, 32, 1])\n",
      "final out:  torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "# Default Activation fn = Relu and group = 1\n",
    "\n",
    "initialblock = TDNNBlock(in_channels=2,\n",
    "                        out_channels=8,\n",
    "                        kernel_size=5,\n",
    "                        dilation= 1).to(\"cuda\")\n",
    "\n",
    "x0 = initialblock(input_feats)\n",
    "print(\"Initial out: \",x0.shape)\n",
    "\n",
    "seres2_1 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=2).to(\"cuda\")\n",
    "\n",
    "x1 = seres2_1(x0)\n",
    "print(\"SERes2_1 out: \",x1.shape)\n",
    "\n",
    "seres2_2 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=3).to(\"cuda\")\n",
    "\n",
    "x2 = seres2_2(x1)\n",
    "print(\"SERes2_2 out: \",x2.shape)\n",
    "\n",
    "seres2_3 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=4).to(\"cuda\")\n",
    "\n",
    "x3 = seres2_3(x2)\n",
    "print(\"SERes2_3 out: \",x3.shape)\n",
    "\n",
    "mfa = TDNNBlock(in_channels=(8 * 3),\n",
    "                out_channels=16,\n",
    "                kernel_size=1,\n",
    "                dilation= 1).to(\"cuda\")\n",
    "\n",
    "x4 = mfa(torch.cat([x1,x2,x3], dim=1))\n",
    "print(\"mfa out: \",x3.shape)\n",
    "\n",
    "asp = AttentiveStatisticsPooling(16, 128, True).to(\"cuda\")\n",
    "x5 = asp(x4)\n",
    "x6 = nn.BatchNorm1d(16 * 2).to(\"cuda\")(x5)\n",
    "print(\"asp out: \",x6.shape)\n",
    "\n",
    "# Remember to x2 to account for the mean & std in asp\n",
    "final = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16 * 2, out_features=6),\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "y = final(x6)\n",
    "print(\"final out: \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disecting SERes2NetBlock\n",
    "\n",
    "Since in_channel == out_channel, shortcut is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "tdnn1 = TDNNBlock(in_channels=8, \n",
    "                  out_channels=8, \n",
    "                  kernel_size=1, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "z0 = tdnn1(x0)\n",
    "print(z0.shape)\n",
    "res2net = Res2NetBlock(in_channels=8, \n",
    "                       out_channels=8, \n",
    "                       scale=8, \n",
    "                       kernel_size=3, \n",
    "                       dilation=1).to(\"cuda\")\n",
    "\n",
    "z1 = res2net(z0)\n",
    "print(z1.shape)\n",
    "\n",
    "tdnn2 = TDNNBlock(in_channels=8, \n",
    "                  out_channels=8, \n",
    "                  kernel_size=1, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "z2 = tdnn2(z1)\n",
    "print(z2.shape)\n",
    "\n",
    "se_block = SEBlock(in_channels=8, \n",
    "                   se_channels=128, \n",
    "                   out_channels=8).to(\"cuda\")\n",
    "\n",
    "z3 = se_block(z2)\n",
    "print((z3 + x0).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disecting Res2NetBlock\n",
    "\n",
    "Here Scale = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64])\n",
      "torch.Size([10, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "scale = 8\n",
    "in_channel = 8//scale # 1\n",
    "hidden_channel = 8//scale # 1\n",
    "\n",
    "block1 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block2 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block3 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block4 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block5 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block6 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block7 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "chunks = torch.chunk(z0, 8, 1)\n",
    "# for i in chunks:\n",
    "#     print(i.shape)\n",
    "\n",
    "b7 = block7(chunks[0])\n",
    "print(chunks[0].shape)\n",
    "print(b7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64])\n",
      "torch.Size([10, 1, 62])\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.nnet.CNN import Conv1d as _Conv1d\n",
    "\n",
    "class Conv1d(_Conv1d):\n",
    "    \"\"\"1D convolution. Skip transpose is used to improve efficiency.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(skip_transpose=True, *args, **kwargs)\n",
    "\n",
    "c1 = Conv1d(in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            dilation=1,\n",
    "            groups=1).to(\"cuda\")\n",
    "\n",
    "c2 = nn.Conv1d(1,1,3,1,0,1).to(\"cuda\")\n",
    "\n",
    "print(c1(chunks[0]).shape)\n",
    "print(c2(chunks[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.4432, -0.0911,  0.3460]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26740795 0.8178966  0.12961799 0.00493336 0.3306914  0.5511803\n",
      "  0.62650675 0.27641416 0.7658161  0.4181484  0.32229787 0.48441684\n",
      "  0.1843239  0.52775484 0.6218187  0.4034167  0.20479006 0.46894705\n",
      "  0.7366815  0.6694186  0.05417478 0.2161662  0.9805711  0.29606843\n",
      "  0.95383537 0.23102427 0.08317649 0.980294   0.82970244 0.6477569\n",
      "  0.581959   0.0185324  0.7994169  0.37473667 0.24644166 0.19074416\n",
      "  0.24360108 0.5712252  0.05087298 0.76147324 0.7151757  0.598813\n",
      "  0.2791242  0.71931446 0.29900938 0.37861872 0.17825103 0.0577479\n",
      "  0.6748667  0.23486334 0.6465089  0.1445471  0.3669144  0.7481721\n",
      "  0.9296756  0.04023647 0.45330197 0.7755589  0.52666116 0.6326515\n",
      "  0.9938532  0.01646823 0.10812438 0.52814806]]\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,1,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (1,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"inputseres2_1.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.2674, 0.8179, 0.1296, 0.0049, 0.3307, 0.5512,\n",
       "          0.6265, 0.2764, 0.7658, 0.4181, 0.3223, 0.4844, 0.1843, 0.5278,\n",
       "          0.6218, 0.4034, 0.2048, 0.4689, 0.7367, 0.6694, 0.0542, 0.2162,\n",
       "          0.9806, 0.2961, 0.9538, 0.2310, 0.0832, 0.9803, 0.8297, 0.6478,\n",
       "          0.5820, 0.0185, 0.7994, 0.3747, 0.2464, 0.1907, 0.2436, 0.5712,\n",
       "          0.0509, 0.7615, 0.7152, 0.5988, 0.2791, 0.7193, 0.2990, 0.3786,\n",
       "          0.1783, 0.0577, 0.6749, 0.2349, 0.6465, 0.1445, 0.3669, 0.7482,\n",
       "          0.9297, 0.0402, 0.4533, 0.7756, 0.5267, 0.6327, 0.9939, 0.0165,\n",
       "          0.1081, 0.5281]]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "input1 = F.pad(input_feats, (2,0))\n",
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_layer = torch.nn.Conv1d(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.1354, -0.0436,  0.3382]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3302], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(random_layer.weight)\n",
    "print(random_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lib.saveasfile import SaveAsByte\n",
    "\n",
    "_ = SaveAsByte(random_layer, \"test\", \"ECAPAweights\")\n",
    "_.saveBoth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banana(x):\n",
    "    random_layer.to(\"cuda\")\n",
    "    y = random_layer(x)\n",
    "    y = torch.nn.ReLU().to(\"cuda\")(y)\n",
    "    return torch.nn.BatchNorm1d(1).to(\"cuda\")(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4206, 0.5951, 0.3745, 0.4369, 0.4593, 0.5028, 0.5627, 0.4709,\n",
       "          0.6619, 0.4756, 0.5246, 0.5365, 0.4150, 0.5662, 0.5424, 0.5109,\n",
       "          0.4660, 0.5344, 0.5865, 0.5879, 0.4190, 0.4915, 0.6597, 0.4167,\n",
       "          0.7725, 0.4067, 0.4773, 0.6893, 0.5792, 0.6457, 0.6110, 0.3987,\n",
       "          0.6785, 0.4245, 0.5054, 0.4346, 0.4376, 0.5385, 0.3554, 0.6628,\n",
       "          0.5457, 0.6045, 0.4952, 0.6423, 0.4377, 0.5425, 0.4144, 0.3932,\n",
       "          0.5800, 0.3879, 0.6299, 0.3826, 0.5354, 0.5867, 0.6616, 0.4045,\n",
       "          0.6075, 0.5781, 0.5358, 0.6261, 0.7099, 0.3780, 0.5005, 0.5063]]],\n",
       "       device='cuda:0', grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = random_layer.to(\"cuda\")(input1.to(\"cuda\"))\n",
    "print(y)\n",
    "y = random_layer.to(\"cuda\")(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = random_layer.to(\"cuda\")(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = random_layer.to(\"cuda\")(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = random_layer.to(\"cuda\")(y.to(\"cuda\"))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
