{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from python_lib.modules import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ECAPA_TDNN(input_size = 2, channels=[8,8,8,8,16], lin_neurons=6, device = \"cuda\").to(\"cuda\")\n",
    "input_feats = torch.rand([10,2,64]).to(\"cuda\")\n",
    "output = model(input_feats)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire ECAPA-TDNN Model overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial out:  torch.Size([10, 8, 64])\n",
      "SERes2_1 out:  torch.Size([10, 8, 64])\n",
      "SERes2_2 out:  torch.Size([10, 8, 64])\n",
      "SERes2_3 out:  torch.Size([10, 8, 64])\n",
      "mfa out:  torch.Size([10, 16, 64])\n",
      "asp out:  torch.Size([10, 32, 1])\n",
      "final out:  torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "# Default Activation fn = Relu and group = 1\n",
    "\n",
    "initialblock = TDNNBlock(in_channels=2,\n",
    "                        out_channels=8,\n",
    "                        kernel_size=5,\n",
    "                        dilation= 1).to(\"cuda\")\n",
    "\n",
    "x0 = initialblock(input_feats)\n",
    "print(\"Initial out: \",x0.shape)\n",
    "\n",
    "seres2_1 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=2).to(\"cuda\")\n",
    "\n",
    "x1 = seres2_1(x0)\n",
    "print(\"SERes2_1 out: \",x1.shape)\n",
    "\n",
    "seres2_2 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=3).to(\"cuda\")\n",
    "\n",
    "x2 = seres2_2(x1)\n",
    "print(\"SERes2_2 out: \",x2.shape)\n",
    "\n",
    "seres2_3 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=4).to(\"cuda\")\n",
    "\n",
    "x3 = seres2_3(x2)\n",
    "print(\"SERes2_3 out: \",x3.shape)\n",
    "\n",
    "mfa = TDNNBlock(in_channels=(8 * 3),\n",
    "                out_channels=16,\n",
    "                kernel_size=1,\n",
    "                dilation= 1).to(\"cuda\")\n",
    "\n",
    "x4 = mfa(torch.cat([x1,x2,x3], dim=1))\n",
    "print(\"mfa out: \",x4.shape)\n",
    "\n",
    "asp = AttentiveStatisticsPooling(16, 128, True).to(\"cuda\")\n",
    "x5 = asp(x4)\n",
    "x6 = nn.BatchNorm1d(16 * 2).to(\"cuda\")(x5)\n",
    "print(\"asp out: \",x6.shape)\n",
    "\n",
    "# Remember to x2 to account for the mean & std in asp\n",
    "final = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16 * 2, out_features=6),\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "y = final(x6)\n",
    "print(\"final out: \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.4033e-01, -1.2670e-01,  1.7172e-01,  5.4900e-02,  1.0922e-01,\n",
       "          9.3102e-02,  7.8937e-02, -1.1522e-01,  4.2454e-02,  4.5778e-03,\n",
       "          5.0761e-02,  1.0475e-01,  1.4638e-01,  2.4510e-02,  3.5282e-02,\n",
       "         -5.4543e-02,  5.0777e-02,  1.1076e-02, -1.3098e-01, -4.9563e-02,\n",
       "         -1.3543e-01, -1.0652e-01, -5.3257e-02, -1.7073e-01,  1.6139e-01,\n",
       "         -1.1455e-01, -8.2617e-02,  1.4518e-01,  5.0413e-02, -3.8235e-03,\n",
       "          9.2700e-05,  1.2762e-02],\n",
       "        [ 1.1888e-01, -1.3906e-03, -2.0703e-02, -2.1914e-02, -3.9449e-02,\n",
       "         -2.1847e-02,  1.1271e-01,  6.3061e-02,  5.7661e-02,  1.0696e-02,\n",
       "         -6.0790e-02, -1.5986e-01, -1.6143e-01, -9.8007e-03, -9.7754e-02,\n",
       "         -1.4597e-01, -3.4645e-02, -7.8234e-03, -1.5442e-01, -2.6707e-02,\n",
       "         -1.4591e-01, -1.9762e-02, -1.3433e-01, -1.0067e-01,  1.0565e-01,\n",
       "          3.1718e-02,  4.8090e-03,  1.1344e-01,  1.1498e-01, -1.3357e-02,\n",
       "          1.0456e-01, -7.8233e-02],\n",
       "        [ 1.3027e-01,  3.1094e-02,  1.2761e-01,  3.3592e-02,  1.7130e-01,\n",
       "          7.8311e-02, -1.1784e-01,  4.9167e-02, -9.8704e-02,  1.1322e-01,\n",
       "          6.2534e-02,  1.1137e-01,  3.4013e-02,  1.4321e-01,  1.0218e-01,\n",
       "          5.6783e-02, -5.6056e-02,  4.6912e-02,  9.5170e-02,  1.7101e-01,\n",
       "         -8.6166e-02,  1.4866e-01,  5.4285e-02, -7.2354e-02, -3.6035e-02,\n",
       "         -1.5786e-01,  7.4984e-03,  1.5428e-01, -8.2346e-02, -1.2783e-01,\n",
       "          1.5214e-02,  9.4608e-02],\n",
       "        [ 1.9278e-02,  8.7509e-02,  2.1023e-03,  1.0767e-01, -1.4229e-01,\n",
       "          1.2574e-01,  9.5500e-03, -1.6858e-01,  2.5977e-02,  6.5483e-02,\n",
       "          7.5514e-02,  8.2159e-02,  1.1635e-01,  1.4954e-01,  1.3718e-01,\n",
       "          1.3935e-01,  1.7576e-01, -1.3394e-01, -1.4681e-01, -7.0733e-02,\n",
       "         -6.4034e-02,  3.6898e-02, -1.1649e-01,  9.3644e-02,  1.1825e-01,\n",
       "          2.7430e-02,  2.2738e-02,  6.4984e-02, -8.6983e-04,  1.0769e-01,\n",
       "          4.7556e-02,  1.2039e-01],\n",
       "        [ 3.5231e-03, -6.9340e-02,  1.1719e-01, -1.7935e-02, -4.0892e-02,\n",
       "          1.4359e-02,  5.5561e-02, -9.0283e-02,  4.0504e-02, -5.5493e-02,\n",
       "          5.5023e-02, -1.0953e-01, -7.8815e-02,  1.7573e-01, -7.6925e-02,\n",
       "         -8.6087e-03,  8.6753e-02, -1.3397e-01, -9.0106e-04, -5.4958e-03,\n",
       "          1.4239e-01, -3.3895e-02,  9.6304e-02, -1.2974e-02,  1.5483e-01,\n",
       "         -1.0274e-01, -2.7721e-02,  1.3492e-01,  1.5365e-01, -1.5471e-01,\n",
       "          1.5539e-01, -8.0346e-02],\n",
       "        [-2.8478e-02, -2.8136e-02,  9.7725e-02, -2.0978e-02,  1.9646e-02,\n",
       "          9.6851e-02,  6.8545e-02,  8.8870e-02, -1.5159e-01,  1.6244e-01,\n",
       "         -4.9049e-02, -1.4386e-01, -1.6396e-01,  1.6287e-01,  4.0086e-02,\n",
       "         -1.2101e-01, -2.5314e-03,  1.0141e-01, -2.9955e-02, -1.2400e-01,\n",
       "         -1.3272e-01, -1.5843e-02, -2.2372e-02, -1.5632e-02, -2.5874e-02,\n",
       "         -1.2257e-01, -1.4702e-01,  1.7082e-01, -7.0220e-02, -5.8779e-02,\n",
       "          4.5082e-02, -2.0234e-02]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disecting SERes2NetBlock\n",
    "\n",
    "Since in_channel == out_channel, shortcut is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "tdnn1 = TDNNBlock(in_channels=8, \n",
    "                  out_channels=8, \n",
    "                  kernel_size=1, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "z0 = tdnn1(x0)\n",
    "print(z0.shape)\n",
    "res2net = Res2NetBlock(in_channels=8, \n",
    "                       out_channels=8, \n",
    "                       scale=8, \n",
    "                       kernel_size=3, \n",
    "                       dilation=1).to(\"cuda\")\n",
    "\n",
    "z1 = res2net(z0)\n",
    "print(z1.shape)\n",
    "\n",
    "tdnn2 = TDNNBlock(in_channels=8, \n",
    "                  out_channels=8, \n",
    "                  kernel_size=1, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "z2 = tdnn2(z1)\n",
    "print(z2.shape)\n",
    "\n",
    "se_block = SEBlock(in_channels=8, \n",
    "                   se_channels=128, \n",
    "                   out_channels=8).to(\"cuda\")\n",
    "\n",
    "z3 = se_block(z2)\n",
    "print((z3 + x0).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecting Res2NetBlock\n",
    "\n",
    "Here Scale = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64])\n",
      "torch.Size([10, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "scale = 8\n",
    "in_channel = 8//scale # 1\n",
    "hidden_channel = 8//scale # 1\n",
    "\n",
    "block1 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block2 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block3 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block4 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block5 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block6 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block7 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "chunks = torch.chunk(z0, 8, 1)\n",
    "# for i in chunks:\n",
    "#     print(i.shape)\n",
    "\n",
    "b7 = block7(chunks[0])\n",
    "print(chunks[0].shape)\n",
    "print(b7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64])\n",
      "torch.Size([10, 1, 62])\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.nnet.CNN import Conv1d as _Conv1d\n",
    "\n",
    "class Conv1d(_Conv1d):\n",
    "    \"\"\"1D convolution. Skip transpose is used to improve efficiency.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(skip_transpose=True, *args, **kwargs)\n",
    "\n",
    "c1 = Conv1d(in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            dilation=1,\n",
    "            groups=1).to(\"cuda\")\n",
    "\n",
    "c2 = nn.Conv1d(1,1,3,1,0,1).to(\"cuda\")\n",
    "\n",
    "print(c1(chunks[0]).shape)\n",
    "print(c2(chunks[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-0.2839,  0.4532,  0.0050]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.4579635e-03 8.5556924e-02 1.6787881e-01 5.9979117e-01 7.0609242e-01\n",
      "  2.0156753e-01 3.1571430e-01 4.6073532e-01 1.6631895e-01 6.2462986e-02\n",
      "  6.8170667e-02 8.8588482e-01 8.7375546e-01 7.9144663e-01 1.6559595e-01\n",
      "  8.1799096e-01 9.0489054e-01 7.4740523e-01 8.4028590e-01 1.6255111e-01\n",
      "  9.8915315e-01 8.0721277e-01 8.1081057e-01 1.3551807e-01 3.8094282e-02\n",
      "  3.1013268e-01 6.4457613e-01 8.7095791e-01 4.8005295e-01 1.8205297e-01\n",
      "  4.7799712e-01 6.2338644e-01 6.7343855e-01 3.7089330e-01 6.1123955e-01\n",
      "  1.5339512e-01 2.6910949e-01 7.6813310e-01 9.4713753e-01 4.9810529e-01\n",
      "  6.8790269e-01 4.8629427e-01 8.7077218e-01 7.3044378e-01 3.5490030e-01\n",
      "  6.8805087e-01 1.7553443e-01 1.7682391e-01 9.0975273e-01 5.5467367e-01\n",
      "  8.3731526e-01 3.2127082e-01 7.5149983e-01 3.1764024e-01 2.2891271e-01\n",
      "  3.0719811e-01 9.0164089e-01 1.4639950e-01 9.5907748e-02 8.7761879e-04\n",
      "  8.9419293e-01 4.7473061e-01 3.4011954e-01 8.2355344e-01]\n",
      " [8.8763207e-01 7.0542216e-01 9.7182018e-01 2.3045540e-03 4.4270915e-01\n",
      "  2.6762366e-02 6.0770398e-01 7.4756449e-01 9.8942757e-02 6.3543528e-01\n",
      "  5.7876277e-01 4.8923790e-02 2.0486599e-01 9.7361010e-01 5.1355243e-01\n",
      "  1.4707839e-01 6.2371933e-01 2.2772366e-01 7.3282284e-01 2.5325537e-02\n",
      "  8.3658040e-01 8.9537424e-01 3.6052203e-01 2.0719802e-01 9.3023854e-01\n",
      "  9.1165489e-01 2.3756790e-01 4.8174542e-01 3.1745744e-01 3.8776153e-01\n",
      "  4.8037410e-01 3.0708390e-01 2.9873073e-01 6.2169576e-01 1.5470749e-01\n",
      "  5.2438837e-01 6.0167140e-01 3.9017493e-01 1.8209082e-01 9.7965002e-02\n",
      "  7.0570350e-02 2.9870850e-01 7.9294062e-01 7.9927504e-01 4.2601138e-01\n",
      "  2.1361601e-01 8.4336323e-01 9.6575552e-01 3.4674102e-01 8.7061816e-01\n",
      "  6.0308880e-01 1.1030632e-01 2.3172289e-01 5.4524285e-01 9.4176215e-01\n",
      "  5.2455294e-01 6.3331765e-01 9.1926324e-01 1.9287282e-01 5.2820861e-01\n",
      "  3.6662948e-01 6.5858722e-01 7.1587503e-02 8.9959705e-01]]\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,2,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (2,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"inputseres2_2.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.5059, 0.7251, 0.0422, 0.2820, 0.7079, 0.3893,\n",
       "          0.4327, 0.0163, 0.9783, 0.5213, 0.3836, 0.2455, 0.3622, 0.9073,\n",
       "          0.1888, 0.7879, 0.5953, 0.0281, 0.5460, 0.7562, 0.2448, 0.1017,\n",
       "          0.6493, 0.8896, 0.4739, 0.4148, 0.8231, 0.7806, 0.2423, 0.5868,\n",
       "          0.5298, 0.3119, 0.1783, 0.4328, 0.7425, 0.7565, 0.5043, 0.0366,\n",
       "          0.7798, 0.2880, 0.3286, 0.2891, 0.1854, 0.6603, 0.0292, 0.1024,\n",
       "          0.9626, 0.4886, 0.7328, 0.0838, 0.8248, 0.9938, 0.0393, 0.2485,\n",
       "          0.8241, 0.5243, 0.8722, 0.0646, 0.7489, 0.3588, 0.5249, 0.1047,\n",
       "          0.8592, 0.5598]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "input1 = F.pad(input_feats, (2,0))\n",
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_layer = torch.nn.Conv1d(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.2464,  0.5169, -0.0164]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1522], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(random_layer.weight)\n",
    "print(random_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lib.saveasfile import SaveAsBin\n",
    "\n",
    "_ = SaveAsBin(random_layer, \"test\", \"ECAPAweights\")\n",
    "_.saveBoth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banana(x):\n",
    "    random_layer.to(\"cuda\")\n",
    "    y = random_layer(x)\n",
    "    y = torch.nn.ReLU().to(\"cuda\")(y)\n",
    "    return torch.nn.BatchNorm1d(1).to(\"cuda\")(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7001,  0.3609,  0.3586, -0.7001, -0.7001,  0.8007, -0.7001,\n",
      "          -0.7001, -0.7001,  3.0109, -0.7001, -0.7001, -0.7001, -0.7001,\n",
      "           1.7434, -0.7001,  1.4639, -0.7001, -0.7001,  0.5053,  0.3905,\n",
      "          -0.7001, -0.7001,  0.8653,  0.8230, -0.7001, -0.7001,  1.0232,\n",
      "          -0.2154, -0.7001,  0.2010, -0.7001, -0.7001, -0.7001, -0.5319,\n",
      "           0.5259, -0.1815, -0.7001, -0.7001,  1.8815, -0.7001, -0.7001,\n",
      "          -0.7001, -0.7001,  0.8562, -0.7001, -0.7001,  2.6975, -0.7001,\n",
      "           0.4409, -0.7001,  1.8822,  1.0156, -0.7001, -0.7001,  1.5201,\n",
      "          -0.7001,  1.1328, -0.7001,  1.6197, -0.7001, -0.3841, -0.7001,\n",
      "           2.0972]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-0.5141, -0.5141,  0.0305, -0.5141, -0.5141, -0.5141,  0.6934,\n",
      "          -0.5141, -0.5141, -0.5141,  3.7888, -0.5141, -0.5141, -0.5141,\n",
      "          -0.5141,  2.0136, -0.5141,  1.6222, -0.5141, -0.5141,  0.2313,\n",
      "          -0.5141, -0.5141, -0.5141,  0.7163, -0.3204, -0.5141, -0.5141,\n",
      "           0.9834, -0.5141, -0.5141, -0.1464, -0.5141, -0.5141, -0.5141,\n",
      "          -0.5141,  0.1732, -0.5141, -0.5141, -0.5141,  2.2071, -0.5141,\n",
      "          -0.5141, -0.5141, -0.5141,  0.7710, -0.5141, -0.5141,  3.3499,\n",
      "          -0.5141,  0.1895, -0.5141,  2.1320, -0.5141, -0.5141, -0.5141,\n",
      "           1.7009, -0.5141,  1.1585, -0.5141,  1.8403, -0.5141, -0.5141,\n",
      "          -0.5141]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-0.4436, -0.4436, -0.4436, -0.4436, -0.4436, -0.4436, -0.4436,\n",
      "           0.3703, -0.4436, -0.4436, -0.4436,  4.1850, -0.4436, -0.4436,\n",
      "          -0.4436, -0.4436,  1.9972, -0.4436,  1.5149, -0.4436, -0.4436,\n",
      "          -0.1993, -0.4436, -0.4436, -0.4436,  0.3909, -0.4436, -0.4436,\n",
      "          -0.4436,  0.7277, -0.4436, -0.4436, -0.4436, -0.4436, -0.4436,\n",
      "          -0.4436, -0.4436, -0.2708, -0.4436, -0.4436, -0.4436,  2.2357,\n",
      "          -0.4436, -0.4436, -0.4436, -0.4436,  0.4659, -0.4436, -0.4436,\n",
      "           3.6441, -0.4436, -0.2508, -0.4436,  2.1431, -0.4436, -0.4436,\n",
      "          -0.4436,  1.6119, -0.4436,  0.9434, -0.4436,  1.7837, -0.4436,\n",
      "          -0.4436]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.3960,\n",
      "          -0.3960, -0.0343, -0.3960, -0.3960, -0.3960,  4.5437, -0.3960,\n",
      "          -0.3960, -0.3960, -0.3960,  1.9182, -0.3960,  1.3393, -0.3960,\n",
      "          -0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.0095, -0.3960,\n",
      "          -0.3960, -0.3960,  0.3946, -0.3960, -0.3960, -0.3960, -0.3960,\n",
      "          -0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.3960,\n",
      "           2.2044, -0.3960, -0.3960, -0.3960, -0.3960,  0.0805, -0.3960,\n",
      "          -0.3960,  3.8946, -0.3960, -0.3960, -0.3960,  2.0933, -0.3960,\n",
      "          -0.3960, -0.3960,  1.4558, -0.3960,  0.6535, -0.3960,  1.6619,\n",
      "          -0.3960]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01,  4.8662e+00, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01,  1.7877e+00, -3.5228e-01,\n",
      "           1.1090e+00, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01,  1.2353e-03, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01,  2.1233e+00, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01,  4.1052e+00, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "           1.9930e+00, -3.5228e-01, -3.5228e-01, -3.5228e-01,  1.2455e+00,\n",
      "          -3.5228e-01,  3.0482e-01, -3.5228e-01,  1.4873e+00]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = banana(input1.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5])\n",
      "tensor([[[0.3755, 0.9186, 0.4761, 0.2098, 0.5713],\n",
      "         [0.1765, 0.3669, 0.0833, 0.1605, 0.6393],\n",
      "         [0.0220, 0.9102, 0.5144, 0.4811, 0.7107]]], device='cuda:0')\n",
      "tensor([[[0.5103],\n",
      "         [0.2853],\n",
      "         [0.5277]]], device='cuda:0')\n",
      "torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.rand([1,3,5]).to(\"cuda\")\n",
    "print(x2.shape)\n",
    "print(x2)\n",
    "s = x2.mean(dim=2, keepdim=True)\n",
    "print(s)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.016274999999999984"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.3841+0.6320+0.4254-0.7384)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_block1 = SEBlock(in_channels=8, \n",
    "                   se_channels=128, \n",
    "                   out_channels=8).to(\"cuda\")\n",
    "\n",
    "x3 = torch.rand([1,8,5]).to(\"cuda\")\n",
    "se_block1(x3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2641, 0.4466, 0.0216, 0.3931, 0.1652],\n",
       "         [0.3530, 0.3197, 0.3505, 0.3932, 0.1869],\n",
       "         [0.2142, 0.0886, 0.0234, 0.3666, 0.3522],\n",
       "         [0.1420, 0.3263, 0.3068, 0.2395, 0.0289],\n",
       "         [0.1203, 0.2312, 0.1836, 0.2095, 0.1761],\n",
       "         [0.0196, 0.4021, 0.0178, 0.4719, 0.1155],\n",
       "         [0.2742, 0.3863, 0.4023, 0.1400, 0.4170],\n",
       "         [0.2794, 0.0644, 0.1290, 0.3499, 0.1249]]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_block1(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = x3.mean(dim=2, keepdim=True)\n",
    "s = se_block1.conv1(s)\n",
    "s = se_block1.relu(s)\n",
    "s = se_block1.conv2(s)\n",
    "s = se_block1.sigmoid(s)\n",
    "\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5151, 0.8709, 0.0421, 0.7665, 0.3221],\n",
      "         [0.6589, 0.5966, 0.6542, 0.7338, 0.3489],\n",
      "         [0.4766, 0.1971, 0.0521, 0.8158, 0.7837],\n",
      "         [0.2599, 0.5971, 0.5614, 0.4382, 0.0529],\n",
      "         [0.2607, 0.5012, 0.3981, 0.4541, 0.3816],\n",
      "         [0.0371, 0.7623, 0.0338, 0.8945, 0.2190],\n",
      "         [0.5132, 0.7229, 0.7530, 0.2621, 0.7804],\n",
      "         [0.5181, 0.1195, 0.2392, 0.6490, 0.2316]]], device='cuda:0')\n",
      "tensor([[[0.5128],\n",
      "         [0.5358],\n",
      "         [0.4494],\n",
      "         [0.5464],\n",
      "         [0.4613],\n",
      "         [0.5275],\n",
      "         [0.5343],\n",
      "         [0.5392]]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2641, 0.4466, 0.0216, 0.3931, 0.1652],\n",
       "         [0.3530, 0.3197, 0.3505, 0.3932, 0.1869],\n",
       "         [0.2142, 0.0886, 0.0234, 0.3666, 0.3522],\n",
       "         [0.1420, 0.3263, 0.3068, 0.2395, 0.0289],\n",
       "         [0.1203, 0.2312, 0.1836, 0.2095, 0.1761],\n",
       "         [0.0196, 0.4021, 0.0178, 0.4719, 0.1155],\n",
       "         [0.2742, 0.3863, 0.4023, 0.1400, 0.4170],\n",
       "         [0.2794, 0.0644, 0.1290, 0.3499, 0.1249]]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s * x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2859, -0.0566,  2.4425],\n",
       "        [-0.5133, -1.8580,  2.0893]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = torch.randn((2,1))\n",
    "a2 = torch.randn((2,3))\n",
    "\n",
    "a1*a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecting ASP\n",
    "\n",
    "Here global_context = True\n",
    "\n",
    "lengths (in forward) = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_to_mask(length, max_len=None, dtype=None, device=None):\n",
    "    \"\"\"Creates a binary mask for each sequence.\n",
    "\n",
    "    Reference: https://discuss.pytorch.org/t/how-to-generate-variable-length-mask/23397/3\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    length : torch.LongTensor\n",
    "        Containing the length of each sequence in the batch. Must be 1D.\n",
    "    max_len : int\n",
    "        Max length for the mask, also the size of the second dimension.\n",
    "    dtype : torch.dtype, default: None\n",
    "        The dtype of the generated mask.\n",
    "    device: torch.device, default: None\n",
    "        The device to put the mask variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask : tensor\n",
    "        The binary mask.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> length=torch.Tensor([1,2,3])\n",
    "    >>> mask=length_to_mask(length)\n",
    "    >>> mask\n",
    "    tensor([[1., 0., 0.],\n",
    "            [1., 1., 0.],\n",
    "            [1., 1., 1.]])\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1\n",
    "\n",
    "    if max_len is None:\n",
    "        max_len = length.max().long().item()  # using arange to generate mask\n",
    "    mask = torch.arange(\n",
    "        max_len, device=length.device, dtype=length.dtype\n",
    "    ).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "\n",
    "    if dtype is None:\n",
    "        dtype = length.dtype\n",
    "\n",
    "    if device is None:\n",
    "        device = length.device\n",
    "\n",
    "    mask = torch.as_tensor(mask, dtype=dtype, device=device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_statistics(x, m, dim=2, eps=1e-12):\n",
    "            mean = (m * x).sum(dim)\n",
    "            std = torch.sqrt((m * (x - mean.unsqueeze(dim)).pow(2)).sum(dim).clamp(eps))\n",
    "            return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x4 -> torch.Size([10, 16, 64])\n",
    "\n",
    "L = x4.shape[-1]\n",
    "\n",
    "# Lengths is for batch no\n",
    "# so in this case it's 10\n",
    "lengths = torch.ones(x4.shape[0], device = x4.device)\n",
    "\n",
    "mask = length_to_mask(lengths * L, max_len=L, device=x4.device)\n",
    "mask = mask.unsqueeze(1)\n",
    "mask.shape # 10,1,64 of all ones\n",
    "\n",
    "# global context\n",
    "total = mask.sum(dim=2, keepdim=True).float()\n",
    "mean, std = _compute_statistics(x4, mask / total, eps = 1e-12)\n",
    "mean = mean.unsqueeze(2).repeat(1, 1, L)\n",
    "std = std.unsqueeze(2).repeat(1, 1, L)\n",
    "attn = torch.cat([x4, mean, std], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdnn = TDNNBlock(16*3, 128, 1,1).to(\"cuda\")\n",
    "tanh = nn.Tanh().to(\"cuda\")\n",
    "conv = Conv1d(in_channels=128, out_channels=16, kernel_size=1).to(\"cuda\")\n",
    "attn1 = conv(tanh(tdnn(attn)))\n",
    "attn1 = F.softmax(attn1, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = _compute_statistics(x4, attn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 16])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
