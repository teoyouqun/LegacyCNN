{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from python_lib.modules import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ECAPA_TDNN(input_size = 2, channels=[8,8,8,8,16], lin_neurons=6, device = \"cuda\").to(\"cuda\")\n",
    "input_feats = torch.rand([10,2,64]).to(\"cuda\")\n",
    "output = model(input_feats)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire ECAPA-TDNN Model overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial out:  torch.Size([10, 8, 64])\n",
      "SERes2_1 out:  torch.Size([10, 8, 64])\n",
      "SERes2_2 out:  torch.Size([10, 8, 64])\n",
      "SERes2_3 out:  torch.Size([10, 8, 64])\n",
      "mfa out:  torch.Size([10, 16, 64])\n",
      "asp out:  torch.Size([10, 32, 1])\n",
      "final out:  torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "# Default Activation fn = Relu and group = 1\n",
    "\n",
    "initialblock = TDNNBlock(in_channels=2,\n",
    "                        out_channels=8,\n",
    "                        kernel_size=5,\n",
    "                        dilation= 1).to(\"cuda\")\n",
    "\n",
    "x0 = initialblock(input_feats)\n",
    "print(\"Initial out: \",x0.shape)\n",
    "\n",
    "seres2_1 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=2).to(\"cuda\")\n",
    "\n",
    "x1 = seres2_1(x0)\n",
    "print(\"SERes2_1 out: \",x1.shape)\n",
    "\n",
    "seres2_2 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=3).to(\"cuda\")\n",
    "\n",
    "x2 = seres2_2(x1)\n",
    "print(\"SERes2_2 out: \",x2.shape)\n",
    "\n",
    "seres2_3 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=4).to(\"cuda\")\n",
    "\n",
    "x3 = seres2_3(x2)\n",
    "print(\"SERes2_3 out: \",x3.shape)\n",
    "\n",
    "mfa = TDNNBlock(in_channels=(8 * 3),\n",
    "                out_channels=16,\n",
    "                kernel_size=1,\n",
    "                dilation= 1).to(\"cuda\")\n",
    "\n",
    "x4 = mfa(torch.cat([x1,x2,x3], dim=1))\n",
    "print(\"mfa out: \",x4.shape)\n",
    "\n",
    "asp = AttentiveStatisticsPooling(16, 128, True).to(\"cuda\")\n",
    "x5 = asp(x4)\n",
    "x6 = nn.BatchNorm1d(16 * 2).to(\"cuda\")(x5)\n",
    "print(\"asp out: \",x6.shape)\n",
    "\n",
    "# Remember to x2 to account for the mean & std in asp\n",
    "final = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16 * 2, out_features=6),\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "y = final(x6)\n",
    "print(\"final out: \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disecting SERes2NetBlock\n",
    "\n",
    "Since in_channel == out_channel, shortcut is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "tdnn1 = TDNNBlock(in_channels=8, \n",
    "                  out_channels=8, \n",
    "                  kernel_size=1, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "z0 = tdnn1(x0)\n",
    "print(z0.shape)\n",
    "res2net = Res2NetBlock(in_channels=8, \n",
    "                       out_channels=8, \n",
    "                       scale=8, \n",
    "                       kernel_size=3, \n",
    "                       dilation=1).to(\"cuda\")\n",
    "\n",
    "z1 = res2net(z0)\n",
    "print(z1.shape)\n",
    "\n",
    "tdnn2 = TDNNBlock(in_channels=8, \n",
    "                  out_channels=8, \n",
    "                  kernel_size=1, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "z2 = tdnn2(z1)\n",
    "print(z2.shape)\n",
    "\n",
    "se_block = SEBlock(in_channels=8, \n",
    "                   se_channels=128, \n",
    "                   out_channels=8).to(\"cuda\")\n",
    "\n",
    "z3 = se_block(z2)\n",
    "print((z3 + x0).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecting Res2NetBlock\n",
    "\n",
    "Here Scale = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64])\n",
      "torch.Size([10, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "scale = 8\n",
    "in_channel = 8//scale # 1\n",
    "hidden_channel = 8//scale # 1\n",
    "\n",
    "block1 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block2 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block3 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block4 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block5 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block6 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block7 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "chunks = torch.chunk(z0, 8, 1)\n",
    "# for i in chunks:\n",
    "#     print(i.shape)\n",
    "\n",
    "b7 = block7(chunks[0])\n",
    "print(chunks[0].shape)\n",
    "print(b7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64])\n",
      "torch.Size([10, 1, 62])\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.nnet.CNN import Conv1d as _Conv1d\n",
    "\n",
    "class Conv1d(_Conv1d):\n",
    "    \"\"\"1D convolution. Skip transpose is used to improve efficiency.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(skip_transpose=True, *args, **kwargs)\n",
    "\n",
    "c1 = Conv1d(in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            dilation=1,\n",
    "            groups=1).to(\"cuda\")\n",
    "\n",
    "c2 = nn.Conv1d(1,1,3,1,0,1).to(\"cuda\")\n",
    "\n",
    "print(c1(chunks[0]).shape)\n",
    "print(c2(chunks[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[-0.2839,  0.4532,  0.0050]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50594366 0.7250772  0.04219651 0.2820202  0.7079151  0.38932866\n",
      "  0.43266457 0.0163129  0.9782909  0.5212845  0.38362598 0.24546897\n",
      "  0.36218983 0.9073295  0.18877524 0.7878695  0.5953017  0.02808833\n",
      "  0.5459746  0.75624037 0.24481273 0.10174829 0.6493096  0.88962936\n",
      "  0.4739467  0.41475552 0.82310957 0.78056484 0.24232155 0.58684677\n",
      "  0.5298198  0.31187832 0.17825067 0.43275493 0.74253494 0.7564738\n",
      "  0.5042966  0.03658837 0.77982795 0.2880451  0.32856953 0.28907228\n",
      "  0.18535358 0.66028607 0.02920556 0.10243958 0.96261185 0.4886195\n",
      "  0.7327595  0.08383131 0.82481503 0.9937503  0.03927499 0.24850917\n",
      "  0.82408917 0.52434564 0.8721648  0.06455863 0.74885297 0.3587603\n",
      "  0.5248795  0.10469019 0.8592372  0.55976254]]\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,1,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (1,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"inputseres2_1.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.5059, 0.7251, 0.0422, 0.2820, 0.7079, 0.3893,\n",
       "          0.4327, 0.0163, 0.9783, 0.5213, 0.3836, 0.2455, 0.3622, 0.9073,\n",
       "          0.1888, 0.7879, 0.5953, 0.0281, 0.5460, 0.7562, 0.2448, 0.1017,\n",
       "          0.6493, 0.8896, 0.4739, 0.4148, 0.8231, 0.7806, 0.2423, 0.5868,\n",
       "          0.5298, 0.3119, 0.1783, 0.4328, 0.7425, 0.7565, 0.5043, 0.0366,\n",
       "          0.7798, 0.2880, 0.3286, 0.2891, 0.1854, 0.6603, 0.0292, 0.1024,\n",
       "          0.9626, 0.4886, 0.7328, 0.0838, 0.8248, 0.9938, 0.0393, 0.2485,\n",
       "          0.8241, 0.5243, 0.8722, 0.0646, 0.7489, 0.3588, 0.5249, 0.1047,\n",
       "          0.8592, 0.5598]]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "input1 = F.pad(input_feats, (2,0))\n",
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_layer = torch.nn.Conv1d(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.2464,  0.5169, -0.0164]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1522], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(random_layer.weight)\n",
    "print(random_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lib.saveasfile import SaveAsByte\n",
    "\n",
    "_ = SaveAsByte(random_layer, \"test\", \"ECAPAweights\")\n",
    "_.saveBoth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banana(x):\n",
    "    random_layer.to(\"cuda\")\n",
    "    y = random_layer(x)\n",
    "    y = torch.nn.ReLU().to(\"cuda\")(y)\n",
    "    return torch.nn.BatchNorm1d(1).to(\"cuda\")(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7001,  0.3609,  0.3586, -0.7001, -0.7001,  0.8007, -0.7001,\n",
      "          -0.7001, -0.7001,  3.0109, -0.7001, -0.7001, -0.7001, -0.7001,\n",
      "           1.7434, -0.7001,  1.4639, -0.7001, -0.7001,  0.5053,  0.3905,\n",
      "          -0.7001, -0.7001,  0.8653,  0.8230, -0.7001, -0.7001,  1.0232,\n",
      "          -0.2154, -0.7001,  0.2010, -0.7001, -0.7001, -0.7001, -0.5319,\n",
      "           0.5259, -0.1815, -0.7001, -0.7001,  1.8815, -0.7001, -0.7001,\n",
      "          -0.7001, -0.7001,  0.8562, -0.7001, -0.7001,  2.6975, -0.7001,\n",
      "           0.4409, -0.7001,  1.8822,  1.0156, -0.7001, -0.7001,  1.5201,\n",
      "          -0.7001,  1.1328, -0.7001,  1.6197, -0.7001, -0.3841, -0.7001,\n",
      "           2.0972]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-0.5141, -0.5141,  0.0305, -0.5141, -0.5141, -0.5141,  0.6934,\n",
      "          -0.5141, -0.5141, -0.5141,  3.7888, -0.5141, -0.5141, -0.5141,\n",
      "          -0.5141,  2.0136, -0.5141,  1.6222, -0.5141, -0.5141,  0.2313,\n",
      "          -0.5141, -0.5141, -0.5141,  0.7163, -0.3204, -0.5141, -0.5141,\n",
      "           0.9834, -0.5141, -0.5141, -0.1464, -0.5141, -0.5141, -0.5141,\n",
      "          -0.5141,  0.1732, -0.5141, -0.5141, -0.5141,  2.2071, -0.5141,\n",
      "          -0.5141, -0.5141, -0.5141,  0.7710, -0.5141, -0.5141,  3.3499,\n",
      "          -0.5141,  0.1895, -0.5141,  2.1320, -0.5141, -0.5141, -0.5141,\n",
      "           1.7009, -0.5141,  1.1585, -0.5141,  1.8403, -0.5141, -0.5141,\n",
      "          -0.5141]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-0.4436, -0.4436, -0.4436, -0.4436, -0.4436, -0.4436, -0.4436,\n",
      "           0.3703, -0.4436, -0.4436, -0.4436,  4.1850, -0.4436, -0.4436,\n",
      "          -0.4436, -0.4436,  1.9972, -0.4436,  1.5149, -0.4436, -0.4436,\n",
      "          -0.1993, -0.4436, -0.4436, -0.4436,  0.3909, -0.4436, -0.4436,\n",
      "          -0.4436,  0.7277, -0.4436, -0.4436, -0.4436, -0.4436, -0.4436,\n",
      "          -0.4436, -0.4436, -0.2708, -0.4436, -0.4436, -0.4436,  2.2357,\n",
      "          -0.4436, -0.4436, -0.4436, -0.4436,  0.4659, -0.4436, -0.4436,\n",
      "           3.6441, -0.4436, -0.2508, -0.4436,  2.1431, -0.4436, -0.4436,\n",
      "          -0.4436,  1.6119, -0.4436,  0.9434, -0.4436,  1.7837, -0.4436,\n",
      "          -0.4436]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.3960,\n",
      "          -0.3960, -0.0343, -0.3960, -0.3960, -0.3960,  4.5437, -0.3960,\n",
      "          -0.3960, -0.3960, -0.3960,  1.9182, -0.3960,  1.3393, -0.3960,\n",
      "          -0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.0095, -0.3960,\n",
      "          -0.3960, -0.3960,  0.3946, -0.3960, -0.3960, -0.3960, -0.3960,\n",
      "          -0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.3960, -0.3960,\n",
      "           2.2044, -0.3960, -0.3960, -0.3960, -0.3960,  0.0805, -0.3960,\n",
      "          -0.3960,  3.8946, -0.3960, -0.3960, -0.3960,  2.0933, -0.3960,\n",
      "          -0.3960, -0.3960,  1.4558, -0.3960,  0.6535, -0.3960,  1.6619,\n",
      "          -0.3960]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01,  4.8662e+00, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01,  1.7877e+00, -3.5228e-01,\n",
      "           1.1090e+00, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01,  1.2353e-03, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01,  2.1233e+00, -3.5228e-01,\n",
      "          -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "          -3.5228e-01,  4.1052e+00, -3.5228e-01, -3.5228e-01, -3.5228e-01,\n",
      "           1.9930e+00, -3.5228e-01, -3.5228e-01, -3.5228e-01,  1.2455e+00,\n",
      "          -3.5228e-01,  3.0482e-01, -3.5228e-01,  1.4873e+00]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = banana(input1.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5])\n",
      "tensor([[[0.3755, 0.9186, 0.4761, 0.2098, 0.5713],\n",
      "         [0.1765, 0.3669, 0.0833, 0.1605, 0.6393],\n",
      "         [0.0220, 0.9102, 0.5144, 0.4811, 0.7107]]], device='cuda:0')\n",
      "tensor([[[0.5103],\n",
      "         [0.2853],\n",
      "         [0.5277]]], device='cuda:0')\n",
      "torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.rand([1,3,5]).to(\"cuda\")\n",
    "print(x2.shape)\n",
    "print(x2)\n",
    "s = x2.mean(dim=2, keepdim=True)\n",
    "print(s)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.016274999999999984"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.3841+0.6320+0.4254-0.7384)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_block1 = SEBlock(in_channels=8, \n",
    "                   se_channels=128, \n",
    "                   out_channels=8).to(\"cuda\")\n",
    "\n",
    "x3 = torch.rand([1,8,5]).to(\"cuda\")\n",
    "se_block1(x3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2641, 0.4466, 0.0216, 0.3931, 0.1652],\n",
       "         [0.3530, 0.3197, 0.3505, 0.3932, 0.1869],\n",
       "         [0.2142, 0.0886, 0.0234, 0.3666, 0.3522],\n",
       "         [0.1420, 0.3263, 0.3068, 0.2395, 0.0289],\n",
       "         [0.1203, 0.2312, 0.1836, 0.2095, 0.1761],\n",
       "         [0.0196, 0.4021, 0.0178, 0.4719, 0.1155],\n",
       "         [0.2742, 0.3863, 0.4023, 0.1400, 0.4170],\n",
       "         [0.2794, 0.0644, 0.1290, 0.3499, 0.1249]]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_block1(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = x3.mean(dim=2, keepdim=True)\n",
    "s = se_block1.conv1(s)\n",
    "s = se_block1.relu(s)\n",
    "s = se_block1.conv2(s)\n",
    "s = se_block1.sigmoid(s)\n",
    "\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5151, 0.8709, 0.0421, 0.7665, 0.3221],\n",
      "         [0.6589, 0.5966, 0.6542, 0.7338, 0.3489],\n",
      "         [0.4766, 0.1971, 0.0521, 0.8158, 0.7837],\n",
      "         [0.2599, 0.5971, 0.5614, 0.4382, 0.0529],\n",
      "         [0.2607, 0.5012, 0.3981, 0.4541, 0.3816],\n",
      "         [0.0371, 0.7623, 0.0338, 0.8945, 0.2190],\n",
      "         [0.5132, 0.7229, 0.7530, 0.2621, 0.7804],\n",
      "         [0.5181, 0.1195, 0.2392, 0.6490, 0.2316]]], device='cuda:0')\n",
      "tensor([[[0.5128],\n",
      "         [0.5358],\n",
      "         [0.4494],\n",
      "         [0.5464],\n",
      "         [0.4613],\n",
      "         [0.5275],\n",
      "         [0.5343],\n",
      "         [0.5392]]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(x3)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2641, 0.4466, 0.0216, 0.3931, 0.1652],\n",
       "         [0.3530, 0.3197, 0.3505, 0.3932, 0.1869],\n",
       "         [0.2142, 0.0886, 0.0234, 0.3666, 0.3522],\n",
       "         [0.1420, 0.3263, 0.3068, 0.2395, 0.0289],\n",
       "         [0.1203, 0.2312, 0.1836, 0.2095, 0.1761],\n",
       "         [0.0196, 0.4021, 0.0178, 0.4719, 0.1155],\n",
       "         [0.2742, 0.3863, 0.4023, 0.1400, 0.4170],\n",
       "         [0.2794, 0.0644, 0.1290, 0.3499, 0.1249]]], device='cuda:0',\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s * x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2859, -0.0566,  2.4425],\n",
       "        [-0.5133, -1.8580,  2.0893]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = torch.randn((2,1))\n",
    "a2 = torch.randn((2,3))\n",
    "\n",
    "a1*a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecting ASP\n",
    "\n",
    "Here global_context = True\n",
    "\n",
    "lengths (in forward) = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_to_mask(length, max_len=None, dtype=None, device=None):\n",
    "    \"\"\"Creates a binary mask for each sequence.\n",
    "\n",
    "    Reference: https://discuss.pytorch.org/t/how-to-generate-variable-length-mask/23397/3\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    length : torch.LongTensor\n",
    "        Containing the length of each sequence in the batch. Must be 1D.\n",
    "    max_len : int\n",
    "        Max length for the mask, also the size of the second dimension.\n",
    "    dtype : torch.dtype, default: None\n",
    "        The dtype of the generated mask.\n",
    "    device: torch.device, default: None\n",
    "        The device to put the mask variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask : tensor\n",
    "        The binary mask.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> length=torch.Tensor([1,2,3])\n",
    "    >>> mask=length_to_mask(length)\n",
    "    >>> mask\n",
    "    tensor([[1., 0., 0.],\n",
    "            [1., 1., 0.],\n",
    "            [1., 1., 1.]])\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1\n",
    "\n",
    "    if max_len is None:\n",
    "        max_len = length.max().long().item()  # using arange to generate mask\n",
    "    mask = torch.arange(\n",
    "        max_len, device=length.device, dtype=length.dtype\n",
    "    ).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "\n",
    "    if dtype is None:\n",
    "        dtype = length.dtype\n",
    "\n",
    "    if device is None:\n",
    "        device = length.device\n",
    "\n",
    "    mask = torch.as_tensor(mask, dtype=dtype, device=device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_statistics(x, m, dim=2, eps=1e-12):\n",
    "            mean = (m * x).sum(dim)\n",
    "            std = torch.sqrt((m * (x - mean.unsqueeze(dim)).pow(2)).sum(dim).clamp(eps))\n",
    "            return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x4 -> torch.Size([10, 16, 64])\n",
    "\n",
    "L = x4.shape[-1]\n",
    "\n",
    "# Lengths is for batch no\n",
    "# so in this case it's 10\n",
    "lengths = torch.ones(x4.shape[0], device = x4.device)\n",
    "\n",
    "mask = length_to_mask(lengths * L, max_len=L, device=x4.device)\n",
    "mask = mask.unsqueeze(1)\n",
    "mask.shape # 10,1,64 of all ones\n",
    "\n",
    "# global context\n",
    "total = mask.sum(dim=2, keepdim=True).float()\n",
    "mean, std = _compute_statistics(x4, mask / total, eps = 1e-12)\n",
    "mean = mean.unsqueeze(2).repeat(1, 1, L)\n",
    "std = std.unsqueeze(2).repeat(1, 1, L)\n",
    "attn = torch.cat([x4, mean, std], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdnn = TDNNBlock(16*3, 128, 1,1).to(\"cuda\")\n",
    "tanh = nn.Tanh().to(\"cuda\")\n",
    "conv = Conv1d(in_channels=128, out_channels=16, kernel_size=1).to(\"cuda\")\n",
    "attn1 = conv(tanh(tdnn(attn)))\n",
    "attn1 = F.softmax(attn1, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = _compute_statistics(x4, attn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 16])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
