{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from python_lib.modules import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ECAPA_TDNN(input_size = 2, channels=[8,8,8,8,16], lin_neurons=6, device = \"cuda\").to(\"cuda\")\n",
    "input_feats = torch.rand([10,2,64]).to(\"cuda\")\n",
    "output = model(input_feats)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire ECAPA-TDNN Model overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial out:  torch.Size([10, 8, 64])\n",
      "SERes2_1 out:  torch.Size([10, 8, 64])\n",
      "SERes2_2 out:  torch.Size([10, 8, 64])\n",
      "SERes2_3 out:  torch.Size([10, 8, 64])\n",
      "mfa out:  torch.Size([10, 8, 64])\n",
      "asp out:  torch.Size([10, 32, 1])\n",
      "final out:  torch.Size([10, 6])\n"
     ]
    }
   ],
   "source": [
    "# Default Activation fn = Relu and group = 1\n",
    "\n",
    "initialblock = TDNNBlock(in_channels=2,\n",
    "                        out_channels=8,\n",
    "                        kernel_size=5,\n",
    "                        dilation= 1).to(\"cuda\")\n",
    "\n",
    "x0 = initialblock(input_feats)\n",
    "print(\"Initial out: \",x0.shape)\n",
    "\n",
    "seres2_1 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=2).to(\"cuda\")\n",
    "\n",
    "x1 = seres2_1(x0)\n",
    "print(\"SERes2_1 out: \",x1.shape)\n",
    "\n",
    "seres2_2 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=3).to(\"cuda\")\n",
    "\n",
    "x2 = seres2_2(x1)\n",
    "print(\"SERes2_2 out: \",x2.shape)\n",
    "\n",
    "seres2_3 = SERes2NetBlock(in_channels=8,\n",
    "                          out_channels=8, \n",
    "                          res2net_scale=8, \n",
    "                          se_channels=128, \n",
    "                          kernel_size=3, \n",
    "                          dilation=4).to(\"cuda\")\n",
    "\n",
    "x3 = seres2_3(x2)\n",
    "print(\"SERes2_3 out: \",x3.shape)\n",
    "\n",
    "mfa = TDNNBlock(in_channels=(8 * 3),\n",
    "                out_channels=16,\n",
    "                kernel_size=1,\n",
    "                dilation= 1).to(\"cuda\")\n",
    "\n",
    "x4 = mfa(torch.cat([x1,x2,x3], dim=1))\n",
    "print(\"mfa out: \",x3.shape)\n",
    "\n",
    "asp = AttentiveStatisticsPooling(16, 128, True).to(\"cuda\")\n",
    "x5 = asp(x4)\n",
    "x6 = nn.BatchNorm1d(16 * 2).to(\"cuda\")(x5)\n",
    "print(\"asp out: \",x6.shape)\n",
    "\n",
    "# Remember to x2 to account for the mean & std in asp\n",
    "final = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=16 * 2, out_features=6),\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "y = final(x6)\n",
    "print(\"final out: \",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disecting SERes2NetBlock\n",
    "\n",
    "Since in_channel == out_channel, shortcut is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n",
      "torch.Size([10, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "tdnn1 = TDNNBlock(in_channels=8, \n",
    "                  out_channels=8, \n",
    "                  kernel_size=1, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "z0 = tdnn1(x0)\n",
    "print(z0.shape)\n",
    "res2net = Res2NetBlock(in_channels=8, \n",
    "                       out_channels=8, \n",
    "                       scale=8, \n",
    "                       kernel_size=3, \n",
    "                       dilation=1).to(\"cuda\")\n",
    "\n",
    "z1 = res2net(z0)\n",
    "print(z1.shape)\n",
    "\n",
    "tdnn2 = TDNNBlock(in_channels=8, \n",
    "                  out_channels=8, \n",
    "                  kernel_size=1, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "z2 = tdnn2(z1)\n",
    "print(z2.shape)\n",
    "\n",
    "se_block = SEBlock(in_channels=8, \n",
    "                   se_channels=128, \n",
    "                   out_channels=8).to(\"cuda\")\n",
    "\n",
    "z3 = se_block(z2)\n",
    "print((z3 + x0).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disecting Res2NetBlock\n",
    "\n",
    "Here Scale = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64])\n",
      "torch.Size([10, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "scale = 8\n",
    "in_channel = 8//scale # 1\n",
    "hidden_channel = 8//scale # 1\n",
    "\n",
    "block1 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block2 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block3 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block4 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block5 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block6 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "block7 = TDNNBlock(in_channels=1, \n",
    "                  out_channels=1, \n",
    "                  kernel_size=3, \n",
    "                  dilation=1).to(\"cuda\")\n",
    "\n",
    "chunks = torch.chunk(z0, 8, 1)\n",
    "# for i in chunks:\n",
    "#     print(i.shape)\n",
    "\n",
    "b7 = block7(chunks[0])\n",
    "print(chunks[0].shape)\n",
    "print(b7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 64])\n",
      "torch.Size([10, 1, 62])\n"
     ]
    }
   ],
   "source": [
    "from speechbrain.nnet.CNN import Conv1d as _Conv1d\n",
    "\n",
    "class Conv1d(_Conv1d):\n",
    "    \"\"\"1D convolution. Skip transpose is used to improve efficiency.\"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(skip_transpose=True, *args, **kwargs)\n",
    "\n",
    "c1 = Conv1d(in_channels=1,\n",
    "            out_channels=1,\n",
    "            kernel_size=3,\n",
    "            dilation=1,\n",
    "            groups=1).to(\"cuda\")\n",
    "\n",
    "c2 = nn.Conv1d(1,1,3,1,0,1).to(\"cuda\")\n",
    "\n",
    "print(c1(chunks[0]).shape)\n",
    "print(c2(chunks[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.4432, -0.0911,  0.3460]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1.conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26740795 0.8178966  0.12961799 0.00493336 0.3306914  0.5511803\n",
      "  0.62650675 0.27641416 0.7658161  0.4181484  0.32229787 0.48441684\n",
      "  0.1843239  0.52775484 0.6218187  0.4034167  0.20479006 0.46894705\n",
      "  0.7366815  0.6694186  0.05417478 0.2161662  0.9805711  0.29606843\n",
      "  0.95383537 0.23102427 0.08317649 0.980294   0.82970244 0.6477569\n",
      "  0.581959   0.0185324  0.7994169  0.37473667 0.24644166 0.19074416\n",
      "  0.24360108 0.5712252  0.05087298 0.76147324 0.7151757  0.598813\n",
      "  0.2791242  0.71931446 0.29900938 0.37861872 0.17825103 0.0577479\n",
      "  0.6748667  0.23486334 0.6465089  0.1445471  0.3669144  0.7481721\n",
      "  0.9296756  0.04023647 0.45330197 0.7755589  0.52666116 0.6326515\n",
      "  0.9938532  0.01646823 0.10812438 0.52814806]]\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,1,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (1,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"inputseres2_1.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.2674, 0.8179, 0.1296, 0.0049, 0.3307, 0.5512,\n",
       "          0.6265, 0.2764, 0.7658, 0.4181, 0.3223, 0.4844, 0.1843, 0.5278,\n",
       "          0.6218, 0.4034, 0.2048, 0.4689, 0.7367, 0.6694, 0.0542, 0.2162,\n",
       "          0.9806, 0.2961, 0.9538, 0.2310, 0.0832, 0.9803, 0.8297, 0.6478,\n",
       "          0.5820, 0.0185, 0.7994, 0.3747, 0.2464, 0.1907, 0.2436, 0.5712,\n",
       "          0.0509, 0.7615, 0.7152, 0.5988, 0.2791, 0.7193, 0.2990, 0.3786,\n",
       "          0.1783, 0.0577, 0.6749, 0.2349, 0.6465, 0.1445, 0.3669, 0.7482,\n",
       "          0.9297, 0.0402, 0.4533, 0.7756, 0.5267, 0.6327, 0.9939, 0.0165,\n",
       "          0.1081, 0.5281]]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "input1 = F.pad(input_feats, (2,0))\n",
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_layer = torch.nn.Conv1d(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.1354, -0.0436,  0.3382]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3302], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(random_layer.weight)\n",
    "print(random_layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_lib.saveasfile import SaveAsByte\n",
    "\n",
    "_ = SaveAsByte(random_layer, \"test\", \"ECAPAweights\")\n",
    "_.saveBoth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def banana(x):\n",
    "    random_layer.to(\"cuda\")\n",
    "    y = random_layer(x)\n",
    "    y = torch.nn.ReLU().to(\"cuda\")(y)\n",
    "    return torch.nn.BatchNorm1d(1).to(\"cuda\")(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0534,  0.7279, -1.5240, -0.8870, -0.6580, -0.2143,  0.3978,\n",
      "          -0.5397,  1.4099, -0.4922,  0.0081,  0.1300, -1.1107,  0.4327,\n",
      "           0.1897, -0.1316, -0.5900,  0.1086,  0.6408,  0.6543, -1.0698,\n",
      "          -0.3294,  1.3872, -1.0926,  2.5396, -1.1948, -0.4742,  1.6899,\n",
      "           0.5660,  1.2448,  0.8905, -1.2767,  1.5792, -1.0134, -0.1880,\n",
      "          -0.9100, -0.8800,  0.1505, -1.7188,  1.4190,  0.2235,  0.8244,\n",
      "          -0.2914,  1.2099, -0.8791,  0.1914, -1.1167, -1.3334,  0.5739,\n",
      "          -1.3866,  1.0834, -1.4410,  0.1192,  0.6426,  1.4067, -1.2179,\n",
      "           0.8552,  0.5545,  0.1225,  1.0447,  1.9005, -1.4882, -0.2372,\n",
      "          -0.1787]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-1.0828,  0.7083, -1.0828, -0.5209, -1.0828, -0.6040,  0.0252,\n",
      "          -0.7913,  1.4626, -0.9990,  0.4866, -0.1987, -1.0828,  0.4788,\n",
      "          -0.4349, -0.1158, -0.6163, -0.0039,  0.2476,  0.4662, -1.0063,\n",
      "          -0.0638,  0.8423, -1.0828,  3.0171, -1.0828,  0.5455,  1.1064,\n",
      "           0.0214,  1.6664,  0.7985, -1.0021,  1.9120, -1.0828,  0.4271,\n",
      "          -1.0828, -0.9480, -0.2300, -1.0828,  1.5232, -0.7629,  1.1947,\n",
      "          -0.4326,  1.4030, -1.0828,  0.6356, -1.0828, -1.0828,  0.1585,\n",
      "          -1.0828,  1.3198, -1.0828,  0.5866, -0.0834,  1.2024, -1.0828,\n",
      "           1.4010, -0.1747,  0.2503,  1.0850,  1.6339, -1.0828,  0.5640,\n",
      "          -0.8565]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-9.6074e-01,  6.2555e-01, -9.6074e-01, -1.9669e-01, -9.6074e-01,\n",
      "          -6.9683e-01, -3.9906e-01, -9.6074e-01,  1.2574e+00, -9.6074e-01,\n",
      "           9.3238e-01, -6.8695e-01, -8.6169e-01,  3.5684e-01, -9.2064e-01,\n",
      "           2.9261e-03, -7.8615e-01, -8.6416e-02, -1.1060e-01,  2.6437e-01,\n",
      "          -9.5294e-01,  1.0788e-01,  2.7746e-01, -9.6074e-01,  2.9262e+00,\n",
      "          -9.6074e-01,  1.5341e+00,  4.1209e-01, -2.7541e-02,  1.7198e+00,\n",
      "           4.0290e-01, -4.9275e-01,  1.9410e+00, -9.6074e-01,  1.0465e+00,\n",
      "          -9.6074e-01, -6.6600e-01, -5.8235e-01, -9.6074e-01,  1.2541e+00,\n",
      "          -9.6074e-01,  1.5428e+00, -8.8764e-01,  1.5724e+00, -9.6074e-01,\n",
      "           1.0506e+00, -9.6074e-01, -7.1062e-01, -2.2944e-01, -9.6074e-01,\n",
      "           1.2123e+00, -9.6074e-01,  9.7905e-01, -6.2710e-01,  1.1472e+00,\n",
      "          -9.6074e-01,  1.6463e+00, -7.9784e-01,  6.1302e-01,  7.4267e-01,\n",
      "           1.2742e+00, -8.5902e-01,  1.0688e+00, -9.6074e-01]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-0.9046,  0.5146, -0.9175,  0.0401, -0.9175, -0.6480, -0.6830,\n",
      "          -0.9175,  0.9064, -0.9175,  1.1868, -0.9175, -0.4391,  0.0528,\n",
      "          -0.9175,  0.1122, -0.9175, -0.0939, -0.4510,  0.0951, -0.9175,\n",
      "           0.1720, -0.2052, -0.8984,  2.5158, -0.9175,  2.2404, -0.2488,\n",
      "           0.3352,  1.4595,  0.0336,  0.0119,  1.6898, -0.9175,  1.5086,\n",
      "          -0.9175, -0.2095, -0.8384, -0.9175,  0.8427, -0.9175,  1.6922,\n",
      "          -0.9175,  1.8049, -0.9175,  1.3896, -0.9175, -0.2452, -0.5408,\n",
      "          -0.9175,  0.9253, -0.9175,  1.2106, -0.9175,  1.2369, -0.9175,\n",
      "           1.7426, -0.9175,  1.0336,  0.1782,  1.0740, -0.7099,  1.2947,\n",
      "          -0.9175]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "tensor([[[-0.8238,  0.4100, -0.8814,  0.1956, -0.8814, -0.5097, -0.8736,\n",
      "          -0.8814,  0.5065, -0.8814,  1.2429, -0.8814,  0.0269, -0.3042,\n",
      "          -0.8814,  0.1051, -0.8814, -0.0414, -0.7447, -0.0041, -0.8814,\n",
      "           0.1668, -0.5748, -0.7423,  1.9510, -0.8814,  2.6068, -0.8243,\n",
      "           0.9184,  0.9606, -0.1136,  0.3782,  1.2699, -0.8814,  1.7533,\n",
      "          -0.8814,  0.3148, -0.8814, -0.8146,  0.4053, -0.8814,  1.6283,\n",
      "          -0.8814,  1.9920, -0.8814,  1.6946, -0.8814,  0.2479, -0.8011,\n",
      "          -0.8569,  0.5674, -0.8814,  1.2680, -0.8814,  1.3809, -0.8814,\n",
      "           1.7956, -0.8814,  1.3886, -0.3561,  1.0795, -0.7214,  1.3619,\n",
      "          -0.8814]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = banana(input1.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)\n",
    "y = F.pad(y, (2,0))\n",
    "y = banana(y.to(\"cuda\"))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5])\n",
      "tensor([[[0.2539, 0.5043, 0.8909, 0.5095, 0.1171],\n",
      "         [0.0512, 0.3143, 0.4812, 0.7679, 0.6774],\n",
      "         [0.9185, 0.1539, 0.9167, 0.9721, 0.0484]]], device='cuda:0')\n",
      "tensor([[[0.4552],\n",
      "         [0.4584],\n",
      "         [0.6019]]], device='cuda:0')\n",
      "torch.Size([1, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "x2 = torch.rand([1,3,5]).to(\"cuda\")\n",
    "print(x2.shape)\n",
    "print(x2)\n",
    "s = x2.mean(dim=2, keepdim=True)\n",
    "print(s)\n",
    "print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.016274999999999984"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.3841+0.6320+0.4254-0.7384)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 5])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_block1 = SEBlock(in_channels=8, \n",
    "                   se_channels=128, \n",
    "                   out_channels=8).to(\"cuda\")\n",
    "\n",
    "x3 = torch.rand([1,8,5]).to(\"cuda\")\n",
    "se_block1(x3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
