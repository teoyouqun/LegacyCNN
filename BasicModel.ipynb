{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from python_lib.BasicModel import BasicModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel(input_size = 2, input_length = 16, out_features = 6).to(\"cuda\")\n",
    "# summary(model, (2,16))\n",
    "\n",
    "# input_feats = torch.rand([10,2,16]).to(\"cuda\")\n",
    "# output = model(input_feats)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5250837  0.73876137 0.02586478 0.69667655 0.9010054  0.16148174\n",
      "  0.05709535 0.86704534 0.3937961  0.7966461  0.7111978  0.89118266\n",
      "  0.22711879 0.94800013 0.60269016 0.72342044]\n",
      " [0.11573368 0.9300387  0.94015527 0.0944708  0.983776   0.7164195\n",
      "  0.97746515 0.25156945 0.6112121  0.3106951  0.20829374 0.9994052\n",
      "  0.27469456 0.12491971 0.5240147  0.37950414]]\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,2,16]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (2,16))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"BasicModelWeights\", f\"input.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.261763  , -0.261763  , -0.261763  , -0.261763  ,\n",
       "         -0.261763  , -0.261763  , -0.261763  , -0.261763  ,\n",
       "         -0.261763  , -0.261763  , -0.261763  , -0.261763  ,\n",
       "         -0.261763  ,  3.402919  ],\n",
       "        [-0.2556397 , -0.2556397 , -0.2556397 , -0.2556397 ,\n",
       "          3.3233159 , -0.2556397 , -0.2556397 , -0.2556397 ,\n",
       "         -0.2556397 , -0.2556397 , -0.2556397 , -0.2556397 ,\n",
       "         -0.2556397 , -0.2556397 ],\n",
       "        [-1.074456  , -0.6625108 ,  2.0874026 , -1.074456  ,\n",
       "         -1.0160321 , -0.20012164, -0.18600944,  0.08975121,\n",
       "          0.05353802,  1.960633  , -1.074456  ,  0.859243  ,\n",
       "          0.15582895,  0.08164499],\n",
       "        [-1.3025054 , -0.2853931 , -1.4954153 , -0.6167996 ,\n",
       "          0.1824062 , -1.7288157 , -0.24249575,  0.6191411 ,\n",
       "          0.7942382 ,  0.32387277,  0.1897296 ,  1.9281856 ,\n",
       "          0.42595991,  1.2078894 ]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0(input_feats).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.3313,  0.0343, -0.0220],\n",
       "         [-0.2709, -0.2457, -0.2315]],\n",
       "\n",
       "        [[ 0.1394, -0.3578, -0.3096],\n",
       "         [ 0.2205,  0.2271, -0.0293]],\n",
       "\n",
       "        [[ 0.0485,  0.0600,  0.4062],\n",
       "         [ 0.0693, -0.0823,  0.2017]],\n",
       "\n",
       "        [[ 0.3365,  0.0685, -0.1733],\n",
       "         [ 0.0222, -0.3500, -0.2283]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0333, -0.3720, -0.2758,  0.3628], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"BasicModelWeights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer0 tensor([[[-0.2618, -0.2618, -0.2618, -0.2618, -0.2618, -0.2618, -0.2618,\n",
      "          -0.2618, -0.2618, -0.2618, -0.2618, -0.2618, -0.2618,  3.4029],\n",
      "         [-0.2556, -0.2556, -0.2556, -0.2556,  3.3233, -0.2556, -0.2556,\n",
      "          -0.2556, -0.2556, -0.2556, -0.2556, -0.2556, -0.2556, -0.2556],\n",
      "         [-1.0745, -0.6625,  2.0874, -1.0745, -1.0160, -0.2001, -0.1860,\n",
      "           0.0898,  0.0535,  1.9606, -1.0745,  0.8592,  0.1558,  0.0816],\n",
      "         [-1.3025, -0.2854, -1.4954, -0.6168,  0.1824, -1.7288, -0.2425,\n",
      "           0.6191,  0.7942,  0.3239,  0.1897,  1.9282,  0.4260,  1.2079]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "layer1 tensor([[[-0.5192, -0.5192, -0.4364,  3.0999,  0.0465, -0.3307,  0.0099,\n",
      "          -0.5192, -0.5192, -0.4959,  0.7027, -0.5192],\n",
      "         [ 0.0597, -0.4958, -0.4958,  3.0588,  0.8810, -0.3017, -0.4958,\n",
      "          -0.4958, -0.4958, -0.4958, -0.2272, -0.4958],\n",
      "         [-0.3955, -0.3955,  3.1793, -0.3955,  0.6433, -0.2630, -0.3955,\n",
      "          -0.3955, -0.3955, -0.3955, -0.3955, -0.3955],\n",
      "         [-0.5982, -0.5982, -0.5982, -0.5982,  2.0897, -0.5982, -0.3023,\n",
      "          -0.5982, -0.5982,  1.8015, -0.5982,  1.1966]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward0>)\n",
      "layer2 tensor([[[-0.9616,  0.4363, -0.9616, -0.9616,  2.1320,  0.0674, -0.3339,\n",
      "          -0.9616,  0.4159,  1.1286],\n",
      "         [-0.7258,  0.8920,  2.2911, -0.7258, -0.6860, -0.6440, -0.6799,\n",
      "          -0.0090, -0.7258,  1.0132],\n",
      "         [-0.5751,  1.1983, -0.5751,  2.5545, -0.0873, -0.5751, -0.5751,\n",
      "          -0.5751, -0.2147, -0.5751],\n",
      "         [-0.6799,  2.3200,  0.3985,  1.2962, -0.6799, -0.6799, -0.6799,\n",
      "          -0.6799,  0.0647, -0.6799]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward0>)\n",
      "layer3 tensor([[[-0.1660,  0.2558,  1.8763,  0.9804, -1.0600, -1.0600, -1.0600,\n",
      "           0.2334],\n",
      "         [ 2.6454, -0.3779, -0.3779, -0.3779, -0.3779, -0.3779, -0.3779,\n",
      "          -0.3779],\n",
      "         [-0.7653,  0.7845, -0.7653, -0.4912, -0.7653,  0.6882,  2.0799,\n",
      "          -0.7653],\n",
      "         [ 2.1541,  0.3969, -0.9012,  0.7251, -0.8501, -0.5714, -0.9012,\n",
      "          -0.0522]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "layer4 tensor([[[-0.8292,  1.9612,  0.5624, -0.6413, -0.8292, -0.2239],\n",
      "         [-0.8420,  1.3935, -0.2367, -0.8420, -0.8420,  1.3691],\n",
      "         [ 1.0365, -0.0358,  1.4345, -0.0416, -1.1968, -1.1968],\n",
      "         [ 0.0571, -1.2048, -1.2650,  0.9097,  1.4541,  0.0489]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "fc tensor([[ 0.0162, -0.3767, -0.5246, -0.0051,  0.3563,  0.1256]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chiny\\OneDrive - Nanyang Technological University\\Internships\\AY24 DSO Summer\\LegacyCNN\\python_lib\\BasicModel.py:77: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  z = F.softmax(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1737, 0.1173, 0.1011, 0.1700, 0.2441, 0.1938]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.2385,  0.2430,  0.0093],\n",
      "         [ 0.2713, -0.1681, -0.0315],\n",
      "         [-0.0668, -0.1337,  0.1041],\n",
      "         [ 0.2388,  0.2851, -0.0823]],\n",
      "\n",
      "        [[-0.1117, -0.1278,  0.0092],\n",
      "         [-0.1055, -0.0316,  0.0143],\n",
      "         [-0.2109, -0.1395, -0.2807],\n",
      "         [ 0.1741,  0.2768,  0.1269]],\n",
      "\n",
      "        [[-0.2697, -0.2338, -0.1891],\n",
      "         [-0.2268,  0.2445, -0.2594],\n",
      "         [ 0.0892, -0.2686, -0.2359],\n",
      "         [-0.0948, -0.0993,  0.1968]],\n",
      "\n",
      "        [[-0.0365, -0.0223, -0.0142],\n",
      "         [-0.1873,  0.2537,  0.2415],\n",
      "         [ 0.2334, -0.1484, -0.0827],\n",
      "         [ 0.0470,  0.2390, -0.2096]]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1570, -0.2493, -0.0283,  0.2360], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layer3[0].weight)\n",
    "print(model.layer3[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(2, 4, kernel_size=(3,), stride=(1,))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
