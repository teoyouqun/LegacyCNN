{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from python_lib.BasicModel import BasicModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel(input_size = 2, input_length = 16, out_features = 6).to(\"cuda\")\n",
    "# summary(model, (2,16))\n",
    "\n",
    "# input_feats = torch.rand([10,2,16]).to(\"cuda\")\n",
    "# output = model(input_feats)\n",
    "# output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36116892 0.97199637 0.12340093 0.9194393  0.39304084 0.8277006\n",
      "  0.5037204  0.22252554 0.0496543  0.6274032  0.7627669  0.16854572\n",
      "  0.02383888 0.3918898  0.4734081  0.8415596 ]\n",
      " [0.6984848  0.88315094 0.20246547 0.9639936  0.3829733  0.9199399\n",
      "  0.20050651 0.8582331  0.5207251  0.6750164  0.8634124  0.687095\n",
      "  0.54691285 0.72526723 0.32679993 0.69680685]]\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,2,16]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (2,16))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"BasicModelWeights\", f\"input.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"BasicModelWeights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer0 tensor([[[-0.8671,  0.0539, -0.2658, -0.2929, -0.9227, -0.1262, -1.1866,\n",
      "           1.3479,  1.4074, -1.2795, -1.2375,  1.2374,  0.9331,  1.1986],\n",
      "         [-0.3747, -0.3747,  3.1981, -0.3747, -0.3747, -0.3747, -0.3747,\n",
      "          -0.3747,  1.2980, -0.3747, -0.3747, -0.3747, -0.3747, -0.3747],\n",
      "         [-0.2750,  3.5745, -0.2750, -0.2750, -0.2750, -0.2750, -0.2750,\n",
      "          -0.2750, -0.2750, -0.2750, -0.2750, -0.2750, -0.2750, -0.2750],\n",
      "         [-0.2294, -0.2294, -0.2294, -0.2294, -0.2294, -0.2294, -0.2294,\n",
      "          -0.2294,  2.9828, -0.2294, -0.2294, -0.2294, -0.2294, -0.2294]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "layer1 tensor([[[-1.0905e+00, -1.0905e+00,  1.5498e+00, -3.4352e-01, -8.2475e-01,\n",
      "           5.8173e-01,  1.6765e+00, -1.0905e+00, -7.4101e-01,  1.0291e+00,\n",
      "           6.2735e-01, -2.8363e-01],\n",
      "         [ 2.0433e+00, -6.5909e-01,  2.9850e-01, -7.6984e-01, -7.6984e-01,\n",
      "          -5.2271e-01,  1.9863e+00, -7.6984e-01, -2.0572e-01, -7.6984e-01,\n",
      "          -5.0503e-01,  6.4383e-01],\n",
      "         [ 8.1805e-02,  2.8903e+00,  7.4747e-01, -1.2087e-01, -7.1565e-01,\n",
      "           9.3686e-02, -7.1565e-01, -7.1565e-01, -5.5002e-01,  4.3584e-01,\n",
      "          -7.1565e-01, -7.1565e-01],\n",
      "         [-6.5107e-01,  4.3037e-01,  1.0721e+00, -6.5107e-01,  2.7549e-01,\n",
      "          -6.5107e-01, -6.5107e-01,  2.7638e+00, -6.5107e-01, -6.5107e-01,\n",
      "           2.4680e-03, -6.3778e-01]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward0>)\n",
      "layer2 tensor([[[ 2.5712, -0.5819, -0.5819, -0.5819,  1.0815, -0.5819, -0.5819,\n",
      "           0.2146, -0.3760, -0.5819],\n",
      "         [-0.3266, -1.0400, -0.6051,  2.1678,  0.5221, -1.0400, -1.0400,\n",
      "           0.0320,  1.1239,  0.2057],\n",
      "         [-0.4199, -0.5102, -0.5102, -0.5102, -0.5102, -0.5102,  1.8668,\n",
      "           2.1247, -0.5102, -0.5102],\n",
      "         [ 1.1670, -0.7592, -0.7592,  0.1253,  2.3950, -0.7592, -0.7592,\n",
      "           0.3070, -0.3610, -0.5963]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward0>)\n",
      "layer3 tensor([[[ 0.7647, -1.0073,  1.6679, -1.0073, -0.2635, -1.0073, -0.3334,\n",
      "           1.1863],\n",
      "         [ 2.1395,  0.0520, -0.6607, -0.6607,  1.1121, -0.6607, -0.6607,\n",
      "          -0.6607],\n",
      "         [-0.4790, -0.4790,  2.5535,  0.3203, -0.4790, -0.4790, -0.4790,\n",
      "          -0.4790],\n",
      "         [ 0.3265,  0.5435, -1.0728, -1.0728,  2.1752, -0.1521, -0.7351,\n",
      "          -0.0123]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "layer4 tensor([[[ 0.2637, -1.3613, -1.3613,  0.6881,  0.5847,  1.1860],\n",
      "         [ 1.4740,  0.8325, -1.0417, -1.0417,  0.5736, -0.7966],\n",
      "         [ 1.8378, -0.3109, -0.7836,  0.8241, -0.7836, -0.7836],\n",
      "         [-0.5108, -0.5108, -0.5108,  2.2189, -0.5108, -0.1758]]],\n",
      "       device='cuda:0', grad_fn=<CudnnBatchNormBackward0>)\n",
      "fc tensor([[-1.1223, -0.9055, -0.3922, -0.0775,  0.0783,  0.3292]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0678, 0.0842, 0.1407, 0.1927, 0.2252, 0.2894]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[-0.3991, -0.0366,  0.0883],\n",
      "         [ 0.0728, -0.2744,  0.0778]],\n",
      "\n",
      "        [[-0.3005,  0.1056, -0.1360],\n",
      "         [-0.0025,  0.3324,  0.2506]],\n",
      "\n",
      "        [[ 0.3298, -0.3972, -0.0508],\n",
      "         [-0.1937, -0.3503, -0.0351]],\n",
      "\n",
      "        [[-0.2671,  0.0069,  0.2288],\n",
      "         [-0.3560, -0.1769,  0.3855]]], device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3970, -0.3558,  0.1439, -0.1756], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layer0[0].weight)\n",
    "print(model.layer0[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(2, 4, kernel_size=(3,), stride=(1,))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
