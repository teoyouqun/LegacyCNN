{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\chiny\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n",
      "SpeechBrain could not find any working torchaudio backend. Audio files may fail to load. Follow this link for instructions and troubleshooting: https://pytorch.org/audio/stable/index.html\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from python_lib.modules import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from python_lib.saveasfile import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48793715 0.03895187 0.5718016  0.12249893 0.38095903 0.57180667\n",
      "  0.6064527  0.6119571  0.06414747 0.76479465 0.45228392 0.29536617\n",
      "  0.07002324 0.4701903  0.27933836 0.12131184 0.71218824 0.09092271\n",
      "  0.8129148  0.29598218 0.46104175 0.7006878  0.40521938 0.27590483\n",
      "  0.27556282 0.53625596 0.9908802  0.8078377  0.20478153 0.9662656\n",
      "  0.71368986 0.92577356 0.8016781  0.00675195 0.03217447 0.08390254\n",
      "  0.60445607 0.31654936 0.3509106  0.22730839 0.9643708  0.3126679\n",
      "  0.2621218  0.00258678 0.9726101  0.10385472 0.1740588  0.15319914\n",
      "  0.4173507  0.81994754 0.89946204 0.18791324 0.40089375 0.5389032\n",
      "  0.16250598 0.55830073 0.18466216 0.32261306 0.06586313 0.3657987\n",
      "  0.8261475  0.36473054 0.5412028  0.12367254]\n",
      " [0.09935516 0.69415635 0.5582605  0.41461217 0.2789762  0.86553675\n",
      "  0.8209544  0.6945344  0.77635235 0.09968209 0.31738305 0.99634093\n",
      "  0.44244152 0.01629257 0.33295602 0.1899671  0.8490492  0.7557361\n",
      "  0.02923572 0.91277575 0.77060086 0.27032113 0.71409255 0.9110145\n",
      "  0.85336226 0.46685058 0.22799248 0.06638795 0.4936204  0.31177115\n",
      "  0.55558515 0.15613854 0.11314267 0.03029257 0.579133   0.12210363\n",
      "  0.07220644 0.8576218  0.48962033 0.9212818  0.24760431 0.13898134\n",
      "  0.04778409 0.5620675  0.540472   0.6456738  0.01297122 0.43024683\n",
      "  0.21568763 0.87059397 0.07438284 0.7141623  0.6966875  0.33315802\n",
      "  0.08868623 0.1287899  0.6969569  0.49604088 0.9647032  0.6889068\n",
      "  0.5559967  0.70132005 0.264408   0.4823246 ]]\n"
     ]
    }
   ],
   "source": [
    "input_feats = torch.rand([1,2,64]).to(\"cuda\")\n",
    "input_feats_np = input_feats.cpu().detach().numpy()\n",
    "input_feats_np = np.reshape(input_feats_np, (2,64))\n",
    "print(input_feats_np)\n",
    "dim = input_feats_np.shape\n",
    "\n",
    "flatten_inputs = input_feats_np.flatten()\n",
    "with open(os.path.join(\"ECAPAweights\", f\"initialinput.bin\"), \"wb\") as f:\n",
    "            # Write the dimensions down\n",
    "            f.write(np.array(dim, dtype=np.int32).tobytes())\n",
    "            # Write the flatten bias down\n",
    "            f.write(flatten_inputs.tobytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECAPA_TDNN(input_size = 2, channels=[8,8,8,8,16], lin_neurons=6, device = \"cuda\").to(\"cuda\")\n",
    "\n",
    "initialblock = BlockSave(model.blocks[0].return_layers(), \"initialblock\", \"ECAPAweights\")\n",
    "initialblock.save()\n",
    "\n",
    "seres2_1 = BlockSave(model.blocks[1].return_layers(), \"seres2_1\", \"ECAPAweights\")\n",
    "seres2_1.save()\n",
    "seres2_2 = BlockSave(model.blocks[2].return_layers(), \"seres2_2\", \"ECAPAweights\")\n",
    "seres2_2.save()\n",
    "seres2_3 = BlockSave(model.blocks[3].return_layers(), \"seres2_3\", \"ECAPAweights\")\n",
    "seres2_3.save()\n",
    "\n",
    "mfa = BlockSave(model.mfa.return_layers(), \"mfa\", \"ECAPAweights\")\n",
    "mfa.save()\n",
    "\n",
    "asp = BlockSave(model.asp.return_layers(), \"asp\", \"ECAPAweights\")\n",
    "asp.save()\n",
    "\n",
    "asp_bn = BlockSave(model.asp_bn.return_layers(), \"asp_bn\", \"ECAPAweights\")\n",
    "asp_bn.save()\n",
    "\n",
    "fc = BlockSave([model.final[1]], \"fc\", \"ECAPAweights\")\n",
    "fc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv1d(2, 8, kernel_size=(5,), stride=(1,)),\n",
       " BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[0].return_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ECAPA_weights = BlockSave(model.return_layers(), \"ECAPA_TDNN\", \"ECAPAweights\")\n",
    "ECAPA_weights.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.9648e-01, -3.9648e-01,  3.4967e-01,  ..., -3.9648e-01,\n",
       "          -3.9648e-01, -3.9648e-01],\n",
       "         [ 5.2983e-01, -1.5384e+00, -9.3842e-01,  ..., -1.1564e-01,\n",
       "           3.5418e-01,  1.2137e-01],\n",
       "         [-1.0124e+00, -8.4545e-02,  3.4077e-01,  ..., -8.7633e-01,\n",
       "           2.0481e+00, -1.0124e+00],\n",
       "         ...,\n",
       "         [-6.1792e-02, -6.1792e-02, -6.1792e-02,  ..., -6.1792e-02,\n",
       "          -6.1792e-02, -6.1792e-02],\n",
       "         [-1.5780e-01, -1.5780e-01, -1.5780e-01,  ..., -1.5780e-01,\n",
       "          -1.5780e-01, -1.5780e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-3.9648e-01, -3.9648e-01,  3.8759e-01,  ..., -3.9648e-01,\n",
       "          -3.9648e-01, -3.9648e-01],\n",
       "         [ 2.6586e+00, -2.6063e-01, -1.5384e+00,  ...,  4.8656e-01,\n",
       "           7.4734e-01,  2.8400e-01],\n",
       "         [ 1.3009e-01,  3.0361e+00, -1.0124e+00,  ...,  2.5610e-01,\n",
       "           1.7261e+00, -6.7679e-01],\n",
       "         ...,\n",
       "         [ 7.4382e+00, -6.1792e-02, -6.1792e-02,  ..., -6.1792e-02,\n",
       "          -6.1792e-02, -6.1792e-02],\n",
       "         [-1.5780e-01, -1.5780e-01,  9.2339e+00,  ..., -1.5780e-01,\n",
       "          -1.5780e-01, -1.5780e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-3.9648e-01, -3.9648e-01, -3.9648e-01,  ...,  1.4788e-01,\n",
       "          -3.9648e-01, -3.9648e-01],\n",
       "         [-5.2450e-01, -2.9229e-01,  1.5623e+00,  ...,  3.3389e-01,\n",
       "           4.6577e-01, -8.1436e-01],\n",
       "         [-1.0124e+00,  9.3708e-02, -8.1302e-01,  ..., -1.0124e+00,\n",
       "          -8.9968e-01,  6.0217e-01],\n",
       "         ...,\n",
       "         [-6.1792e-02, -6.1792e-02, -6.1792e-02,  ..., -6.1792e-02,\n",
       "          -6.1792e-02, -6.1792e-02],\n",
       "         [ 3.6450e+00, -1.5780e-01, -1.5780e-01,  ..., -1.5780e-01,\n",
       "          -1.5780e-01, -1.5780e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-3.9648e-01,  2.6254e-01, -3.9648e-01,  ..., -3.9648e-01,\n",
       "          -3.9648e-01, -3.9648e-01],\n",
       "         [-1.5384e+00, -9.7986e-01,  6.0347e-01,  ..., -8.1902e-01,\n",
       "          -9.3682e-01, -6.9738e-01],\n",
       "         [-1.0124e+00, -1.0124e+00,  1.2560e+00,  ..., -1.0124e+00,\n",
       "          -1.0124e+00, -1.0124e+00],\n",
       "         ...,\n",
       "         [-6.1792e-02, -6.1792e-02, -6.1792e-02,  ..., -6.1792e-02,\n",
       "          -6.1792e-02, -6.1792e-02],\n",
       "         [-1.5780e-01, -1.5780e-01, -1.5780e-01,  ..., -1.5780e-01,\n",
       "          -1.5780e-01, -1.5780e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-3.9648e-01,  2.6031e+00, -3.9648e-01,  ..., -3.9648e-01,\n",
       "          -3.9648e-01, -3.9648e-01],\n",
       "         [-1.5384e+00,  5.3061e-02,  1.1413e+00,  ..., -2.4198e-01,\n",
       "           1.4252e+00,  3.0390e+00],\n",
       "         [-1.0124e+00, -1.0124e+00,  2.2289e-01,  ..., -1.0124e+00,\n",
       "           1.0817e+00, -4.5313e-01],\n",
       "         ...,\n",
       "         [-6.1792e-02, -6.1792e-02, -6.1792e-02,  ..., -6.1792e-02,\n",
       "          -6.1792e-02, -6.1792e-02],\n",
       "         [-1.5780e-01, -1.5780e-01, -1.5780e-01,  ...,  1.0068e+00,\n",
       "          -1.5780e-01, -1.5780e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.6672e-01,  3.9071e-01, -3.9648e-01,  ..., -3.9648e-01,\n",
       "          -3.9648e-01, -3.9648e-01],\n",
       "         [-4.0065e-01,  4.3281e-01,  6.0232e-01,  ...,  9.7971e-02,\n",
       "           1.2360e+00,  1.8732e-01],\n",
       "         [ 2.2138e-01,  1.6160e-03,  2.7239e-01,  ..., -2.9550e-02,\n",
       "           2.5651e-01,  6.5212e-01],\n",
       "         ...,\n",
       "         [-6.1792e-02, -6.1792e-02, -6.1792e-02,  ..., -6.1792e-02,\n",
       "          -6.1792e-02, -6.1792e-02],\n",
       "         [-1.5780e-01, -1.5780e-01, -1.5780e-01,  ..., -1.5780e-01,\n",
       "          -1.5780e-01, -1.5780e-01],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]], device='cuda:0',\n",
       "       grad_fn=<CudnnBatchNormBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[0](input_feats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
