{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def length_to_mask(length, max_len=None, dtype=None, device=None):\n",
    "    \"\"\"Creates a binary mask for each sequence.\n",
    "\n",
    "    Reference: https://discuss.pytorch.org/t/how-to-generate-variable-length-mask/23397/3\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    length : torch.LongTensor\n",
    "        Containing the length of each sequence in the batch. Must be 1D.\n",
    "    max_len : int\n",
    "        Max length for the mask, also the size of the second dimension.\n",
    "    dtype : torch.dtype, default: None\n",
    "        The dtype of the generated mask.\n",
    "    device: torch.device, default: None\n",
    "        The device to put the mask variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask : tensor\n",
    "        The binary mask.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> length=torch.Tensor([1,2,3])\n",
    "    >>> mask=length_to_mask(length)\n",
    "    >>> mask\n",
    "    tensor([[1., 0., 0.],\n",
    "            [1., 1., 0.],\n",
    "            [1., 1., 1.]])\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1\n",
    "\n",
    "    if max_len is None:\n",
    "        max_len = length.max().long().item()  # using arange to generate mask\n",
    "    mask = torch.arange(\n",
    "        max_len, device=length.device, dtype=length.dtype\n",
    "    ).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "\n",
    "    if dtype is None:\n",
    "        dtype = length.dtype\n",
    "\n",
    "    if device is None:\n",
    "        device = length.device\n",
    "\n",
    "    mask = torch.as_tensor(mask, dtype=dtype, device=device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = length_to_mask(torch.ones((1)) * 0.5 * 8, max_len=8)\n",
    "mask = mask.unsqueeze(1)\n",
    "mask.shape\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8])\n",
      "tensor([[[0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "total = mask.sum(dim=2, keepdim=True).float()\n",
    "temp = (mask / total)\n",
    "print(temp.shape)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "    \"\"\"This class implements the cosine similarity on the top of features.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    input_size : int\n",
    "        Expected size of input dimension.\n",
    "    device : str\n",
    "        Device used, e.g., \"cpu\" or \"cuda\".\n",
    "    lin_blocks : int\n",
    "        Number of linear layers.\n",
    "    lin_neurons : int\n",
    "        Number of neurons in linear layers.\n",
    "    out_neurons : int\n",
    "        Number of classes.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> classify = Classifier(input_size=2, lin_neurons=2, out_neurons=2)\n",
    "    >>> outputs = torch.tensor([ [1., -1.], [-9., 1.], [0.9, 0.1], [0.1, 0.9] ])\n",
    "    >>> outputs = outputs.unsqueeze(1)\n",
    "    >>> cos = classify(outputs)\n",
    "    >>> (cos < -1.0).long().sum()\n",
    "    tensor(0)\n",
    "    >>> (cos > 1.0).long().sum()\n",
    "    tensor(0)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        device=\"cpu\",\n",
    "        out_neurons=1211,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Final Layer\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.FloatTensor(out_neurons, input_size, device=device)\n",
    "        )\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Returns the output probabilities over speakers.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        x : torch.Tensor\n",
    "            Torch tensor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : torch.Tensor\n",
    "            Output probabilities over speakers.\n",
    "        \"\"\"\n",
    "\n",
    "        # Need to be normalized\n",
    "        x = F.linear(F.normalize(x.squeeze(1)), F.normalize(self.weight))\n",
    "        return x.unsqueeze(1)\n",
    "    \n",
    "    def return_layers(self):\n",
    "        return [self]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
