{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def length_to_mask(length, max_len=None, dtype=None, device=None):\n",
    "    \"\"\"Creates a binary mask for each sequence.\n",
    "\n",
    "    Reference: https://discuss.pytorch.org/t/how-to-generate-variable-length-mask/23397/3\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    length : torch.LongTensor\n",
    "        Containing the length of each sequence in the batch. Must be 1D.\n",
    "    max_len : int\n",
    "        Max length for the mask, also the size of the second dimension.\n",
    "    dtype : torch.dtype, default: None\n",
    "        The dtype of the generated mask.\n",
    "    device: torch.device, default: None\n",
    "        The device to put the mask variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mask : tensor\n",
    "        The binary mask.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> length=torch.Tensor([1,2,3])\n",
    "    >>> mask=length_to_mask(length)\n",
    "    >>> mask\n",
    "    tensor([[1., 0., 0.],\n",
    "            [1., 1., 0.],\n",
    "            [1., 1., 1.]])\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1\n",
    "\n",
    "    if max_len is None:\n",
    "        max_len = length.max().long().item()  # using arange to generate mask\n",
    "    mask = torch.arange(\n",
    "        max_len, device=length.device, dtype=length.dtype\n",
    "    ).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "\n",
    "    if dtype is None:\n",
    "        dtype = length.dtype\n",
    "\n",
    "    if device is None:\n",
    "        device = length.device\n",
    "\n",
    "    mask = torch.as_tensor(mask, dtype=dtype, device=device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = torch.Tensor([4])\n",
    "mask = length_to_mask(length, max_len = 4)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = mask.unsqueeze(1)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2500, 0.2500, 0.2500, 0.2500]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = mask.sum(dim=2, keepdim=True).float()\n",
    "mask/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((1,2,4))\n",
    "a = torch.randn((1,1,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
